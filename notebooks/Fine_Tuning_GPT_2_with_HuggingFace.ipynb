{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-Tuning-GPT-2-with-HuggingFace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNB5J3XbALJR3u33ZcYr4ko",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/gpt-experiments/blob/main/notebooks/Fine_Tuning_GPT_2_with_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lq-qHwDRba4"
      },
      "source": [
        "# Introduction to GPT\n",
        "\n",
        "GPT stands for \"Generative Pre-Trained Transformer.\"\n",
        "\n",
        "* Generative because it is used to generate text.\n",
        "* Pre-trained because it was trained on a large corpus of unstructured text to make its weights learn things from text like structure, syntax, and general knowledge.\n",
        "* Transformer because it uses the `decoder` part of the transformer architecture. In other words, you can give it text and it will decode what it needs to output in response (by guessing the next words that follow the input text).\n",
        "\n",
        "GPT-3 is a massive model. Much too massive to fit in a puny Google Colab GPU and its RAM. Therefore, here we'll use its predecessor, GPT-2, since we can actually fit in on our Colab machine.\n",
        "\n",
        "GPT models are particular cool because they are able to be applied to many downstream NLP tasks without having to fine-tune the model. Through, few-shot learning, the model can predict what should come next. However, the only current limitation is that the model is limited by its window size. In other words, a model like GPT-J can only fit 2048 tokens as input. That means that in some cases, we might not be able to fit in enough examples to get fantastic results. And when we're in a production environment, it can often be worth it to fine-tune a GPT model to your type of data so that it can perform better.\n",
        "\n",
        "Models like GPT-3 have been show to show a lot of great results across many different tasks without fine-tuning, even when we compare them to a model like BERT that was specifically fine-tuned on the data. However, it is still often recommended to fine-tune the model to get even better performance. And, in cases like medical data, GPT-3 doesn't necessarily perform well compared to a model like BioBERT.\n",
        "\n",
        "Perhaps a good rule of thumb is to start by doing creative prompt engineering with your GPT model first to try to get great results, and then you can decide afterwards if you'd like to fine-tune the model for even better accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap-rQ1P1Y058"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr14u8fcYR4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a90280c-d0e2-4b02-af9d-5a3844516dc8"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers pytorch-lightning beautifulsoup4 datasets --quiet"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84TRkXXhY2U5"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvxQKSqQY3Fa"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import seed_everything\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5tY6KPsgUFQ"
      },
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        "Here we will mount our Google Drive so that we can grab data and save the HuggingFace scripts, and save the model once we've fine-tuned it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNeXrm1qgWRp",
        "outputId": "74228d7a-8055-4a81-fbe4-904ab372f55e"
      },
      "source": [
        "# For saving the data locally\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIMELLTfg76e",
        "outputId": "3ac42918-209e-419d-9f0c-33575cfc49b5"
      },
      "source": [
        "%cd drive/MyDrive/code-projects/fine-tune-gpt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/code-projects/fine-tune-gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-AVhqkVeluk"
      },
      "source": [
        "# Getting the Data\n",
        "\n",
        "We'll be fine-tuning GPT-2 on Elon Musk tweets to see if we can start taking the first steps towards an Elon AI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3h0UWoLep_O"
      },
      "source": [
        "directory = 'data/elon-musk/tweets-2010-2021/'\n",
        "musk_tweets = pd.read_csv(f'{directory}' + '2010.csv')\n",
        "\n",
        "list_of_years = ['2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
        "\n",
        "for year in list_of_years:\n",
        "    temp_df = pd.read_csv(f'{directory}' + year + '.csv')\n",
        "    musk_tweets = musk_tweets.append(temp_df, ignore_index=True)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "TyskPpaMrtgA",
        "outputId": "bad6ee7c-c485-4a6d-dcea-79f284a80d64"
      },
      "source": [
        "musk_tweets.head(3)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>timezone</th>\n",
              "      <th>place</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>cashtags</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_id_str</th>\n",
              "      <th>username</th>\n",
              "      <th>name</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>link</th>\n",
              "      <th>urls</th>\n",
              "      <th>photos</th>\n",
              "      <th>video</th>\n",
              "      <th>thumbnail</th>\n",
              "      <th>retweet</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>quote_url</th>\n",
              "      <th>search</th>\n",
              "      <th>near</th>\n",
              "      <th>geo</th>\n",
              "      <th>source</th>\n",
              "      <th>user_rt_id</th>\n",
              "      <th>user_rt</th>\n",
              "      <th>retweet_id</th>\n",
              "      <th>reply_to</th>\n",
              "      <th>retweet_date</th>\n",
              "      <th>translate</th>\n",
              "      <th>trans_src</th>\n",
              "      <th>trans_dest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>15434727182</td>\n",
              "      <td>15434727182</td>\n",
              "      <td>1.275676e+12</td>\n",
              "      <td>2010-06-04 18:31:57</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Please ignore prior tweets, as that was someone pretending to be me :)  This is actually me.</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>44196397</td>\n",
              "      <td>44196397</td>\n",
              "      <td>elonmusk</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>https://twitter.com/elonmusk/status/15434727182</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>4652</td>\n",
              "      <td>391</td>\n",
              "      <td>348</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>152153637639028736</td>\n",
              "      <td>152151847614943233</td>\n",
              "      <td>1.325111e+12</td>\n",
              "      <td>2011-12-28 22:27:08</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@TheOnion So true :)</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>44196397</td>\n",
              "      <td>44196397</td>\n",
              "      <td>elonmusk</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>https://twitter.com/elonmusk/status/152153637639028736</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>151809315026636800</td>\n",
              "      <td>151809315026636800</td>\n",
              "      <td>1.325029e+12</td>\n",
              "      <td>2011-12-27 23:38:55</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>If you ever wanted to know the *real* truth about the moon landings ...(best Onion article ever)  http://t.co/pgNEJsjI</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>44196397</td>\n",
              "      <td>44196397</td>\n",
              "      <td>elonmusk</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>https://twitter.com/elonmusk/status/151809315026636800</td>\n",
              "      <td>['http://j.mp/vLhhov']</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                  id  ...  trans_src  trans_dest\n",
              "0           0         15434727182  ...        NaN         NaN\n",
              "1           0  152153637639028736  ...        NaN         NaN\n",
              "2           1  151809315026636800  ...        NaN         NaN\n",
              "\n",
              "[3 rows x 39 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H79ADkFnsrcP",
        "outputId": "37c58d72-efb6-442d-f0ac-db57cd59e68b"
      },
      "source": [
        "musk_tweets = musk_tweets['tweet']\n",
        "musk_tweets.head(2)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Please ignore prior tweets, as that was someone pretending to be me :)  This is actually me.\n",
              "1                                                                            @TheOnion So true :)\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7veNZgJPs0RL"
      },
      "source": [
        "import re\n",
        "musk_tweets.replace(to_replace=\"@[A-Za-z0-9]+\", value=\"\", regex=True, inplace=True)\n",
        "musk_tweets.replace(to_replace=r'http\\S+', value=\"\", regex=True, inplace=True)\n",
        "musk_tweets.replace(to_replace=r'#[A-Za-z0-9]+', value=\"\", regex=True, inplace=True)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1osSu0xot9eY",
        "outputId": "1ca92191-6d8f-425f-c590-097750797fdb"
      },
      "source": [
        "musk_tweets.head(20)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                 Please ignore prior tweets, as that was someone pretending to be me :)  This is actually me.\n",
              "1                                                                                                                                   So true :)\n",
              "2                                           If you ever wanted to know the *real* truth about the moon landings ...(best Onion article ever)  \n",
              "3                                                                Walked around a neighborhood recently rebuilt with help from APJ and others  \n",
              "4                                            It was Xmas, so we brought presents for the kids at the orphanage. They don't usually get much.  \n",
              "5                  Met with UNICEF, Doctors Without Borders and Artists for Peace & Justice. I support them and would recommend others do too.\n",
              "6                          Just returned from a trip to Haiti. Covered a lot of ground and saw many tough situations. They need a lot of help.\n",
              "7                                                                        Single character Tweets are the ulitmate extension of the Twitmeme...\n",
              "8                                                                                                                                            I\n",
              "9                     The Russians are having some challenges with their rockets. Too many of the engineers that designed them have retired:  \n",
              "10         We had a long and interesting conversation on many subjects. He has exciting ideas for extending his creative talents beyond music.\n",
              "11                                                                                         Kanye stopped by the SpaceX rocket factory today.  \n",
              "12                                        Model S options are out! Performance in red and black for me.  I will deliver my car in June/July.  \n",
              "13                                        Hi, I'm Art Garfunkel. Have you heard the sound of silence? Because, you know, it makes a sound...  \n",
              "14                                   Raul Campos invited me to do a guest DJ gig on KCRW.  Hear my random holiday season music selections at  \n",
              "15                                                                                                  Yum! Even better than deep fried butter:  \n",
              "16         Yeah, this really is me, as my Mom  will attest. Not sure I can handle just doing 140 char missives. Will put longer thoughts on G+\n",
              "17    Got called randomly by Kanye West today and received a download of his thoughts, ranging from shoes to Moses. He was polite, but opaque.\n",
              "18                                                    His singing and acting talent will be sorely missed:    South Park sequel coming soon...\n",
              "19                                Why does the crowd cry over the glorious leader Kim Il Sung's death?  Fear of being shot may play a role:   \n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2CsHkXf1Z8b",
        "outputId": "fca7b1ac-866b-4367-8b1f-f0248768dc96"
      },
      "source": [
        "len(musk_tweets)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43074"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60UIFTAY1N2l"
      },
      "source": [
        "## Training Splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T54RFVmS1NRv"
      },
      "source": [
        "train, val = train_test_split(musk_tweets, test_size=0.1)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCoTxXg81quI"
      },
      "source": [
        "train_path = f'{directory}' + 'train.csv'\n",
        "val_path = f'{directory}' + 'val.csv'\n",
        "\n",
        "train.to_csv(train_path)\n",
        "val.to_csv(val_path)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ZvyvZyerDT"
      },
      "source": [
        "# Fine-Tuning GPT-2\n",
        "\n",
        "If we're looking to fine-tune models which are found on the HuggingFace model hub, then it becomes much easier to fine-tune the models since HuggingFace provides us with scripts.\n",
        "\n",
        "From the `transformers` repo:\n",
        "\n",
        "> There are two sets of scripts provided. The first set leverages the Trainer API. The second set with no_trainer in the suffix uses a custom training loop and leverages the ðŸ¤— Accelerate library. Both sets use the ðŸ¤— Datasets library. You can easily customize them to your needs if you need extra processing on your datasets.\n",
        "\n",
        "You can learn more about it here: https://github.com/huggingface/transformers/tree/master/examples/pytorch/language-modeling\n",
        "\n",
        "We will be using the script that leveraged the Trainer API. We can download the script by running:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty4g9WUhfMz0"
      },
      "source": [
        "if os.path.exists('/gpt-2/run_clm.py'):\n",
        "    !wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/language-modeling/run_clm.py -P gpt-2/"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXvm0wpQxS10"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTQ8nlBo5NOD"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/code-projects/fine-tune-gpt/data/elon-musk/tweets-2010-2021/train.csv'\n",
        "val_path = '/content/drive/MyDrive/code-projects/fine-tune-gpt/data/elon-musk/tweets-2010-2021/val.csv'"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOtpCx8KfVYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c61cea-0787-4865-a460-0881993770a1"
      },
      "source": [
        "!python gpt-2/run_clm.py \\\n",
        "    --model_name_or_path gpt2 \\\n",
        "    --train_file train_path \\\n",
        "    --validation_file val_path \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --output_dir gpt-2/tmp/elon-test-clm"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"gpt-2/run_clm.py\", line 526, in <module>\n",
            "    main()\n",
            "  File \"gpt-2/run_clm.py\", line 203, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/hf_argparser.py\", line 206, in parse_args_into_dataclasses\n",
            "    obj = dtype(**inputs)\n",
            "  File \"<string>\", line 14, in __init__\n",
            "  File \"gpt-2/run_clm.py\", line 186, in __post_init__\n",
            "    assert extension in [\"csv\", \"json\", \"txt\"], \"`train_file` should be a csv, a json or a txt file.\"\n",
            "AssertionError: `train_file` should be a csv, a json or a txt file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdIAGG1a27xX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}