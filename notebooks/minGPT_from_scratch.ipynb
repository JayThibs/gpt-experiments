{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minGPT-from-scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO+tXdZjNgz08WHl5fQqiWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/gpt-experiments/blob/main/notebooks/minGPT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End minGPT\n",
        "\n",
        "This is an implementation of minGPT in order to quickly get a feel for the end-to-end training of a GPT model."
      ],
      "metadata": {
        "id": "UkI5QrUhQCGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "wnqQm_HHQWB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZpKxu0fyPZBY"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model configuration\n",
        "\n",
        "We are now going to create a class where we can initialize all the parameters of the model. This is where we include all the hyperparameters for the model. Since we are doing an implementation of minGPT, we don't have the same model as GPT-2 or GPT-3. However, to get those models, we can simple add more layers, increase maximum sequence length, and embedding dimension.\n",
        "\n",
        "Those bigger models have some additional tricks for training, but the general idea is just a bigger model and more data."
      ],
      "metadata": {
        "id": "bg-M2ufVQX8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTConfig:\n",
        "    attn_dropout = 0.1\n",
        "    embed_dropout = 0.1\n",
        "    ff_dropout = 0.1\n",
        "\n",
        "    def __init__(self, vocab_size, max_len, **kwargs):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        for key, value in kwargs.items():\n",
        "            setattr(self, key, value)\n",
        "\n",
        "class GPT1Config(GPTConfig):\n",
        "    num_heads = 12\n",
        "    num_blocks = 12\n",
        "    embed_dim = 768"
      ],
      "metadata": {
        "id": "J30QUiJVRd9V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.embed_dim\n",
        "        self.max_len = config.max_len\n",
        "        self.tok_embed = nn.Embedding(\n",
        "            config.vocab_size, embed_dim\n",
        "        )\n",
        "        self.pos_embed = nn.Parameter(\n",
        "            torch.zeros(1, self.max_len, embed_dim)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(config.embed_dropout)\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[Decoder(config) for _ in range(config.num_blocks)]\n",
        "        ) # Decoder() is the transformer decoder block, we are stacking blocks\n",
        "        self.ln = nn.LayerNorm(embed_dim)\n",
        "        self.fc = nn.Linear(embed_dim, config.vocab_size)\n",
        "\n",
        "    def forward(self, x, target=None):\n",
        "        # batch_size = x.size(0) # (batch_size, sequence_length, embedding_dimension)\n",
        "        seq_len = x.size(1)\n",
        "        assert seq_len <= self.max_len, \"sequence longer than model capacity\"\n",
        "\n",
        "        tok_embedding = self.tok_embed(x)\n",
        "        # tok_embedding.shape == (batch_size, seq_len, embed_dim)\n",
        "        pos_embedding = self.pos_embed[:, :seq_len, :] # cuts pos_embed shorter based on seq_len passed (no trainable positional embedding layer)\n",
        "        # pos_embedding.shape == (1, seq_len, embed_dim)\n",
        "        # more elegant than calling torch.range() on each forward pass\n",
        "        x = self.dropout(tok_embedding + pos_embedding)\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln(x)\n",
        "        x = self.fc(x) # logits\n",
        "        # x.shape == (batch_size, seq_len, vocab_size)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RmwzhOmJn7wO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Transformer Decoder Block\n",
        "# Includes multi-head attention, layer normalization, \n",
        "# and a point-wise feedforward network\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.embed_dim\n",
        "        self.ln1 = nn.LayerNorm(embed_dim)\n",
        "        self.ln2 = nn.LayerNorm(embed_dim)\n",
        "        self.attn = MultiHeadAttention(config)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim * 4, embed_dim),\n",
        "            nn.Dropout(config.ff_dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is the residual connection in between each component\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.ff(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "eV62TQ5H8eH4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.embed_dim\n",
        "        self.num_heads = config.num_heads\n",
        "        assert embed_dim % self.num_heads == 0, \"invalid heads and embedding dimension configuration, embed_dim must be divisible by num_heads with no remainder\"\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.attn_dropout = nn.Dropout(config.attn_dropout)\n",
        "        self.proj_dropout = nn.Dropout(config.ff_dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.tril(torch.ones(config.max_len, config.max_len)).unsqueeze(0).unsqueeze(0)\n",
        "        ) # torch.tril gives us a triangle matrix so each row masks the next tokens\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        seq_len = x.size(1)\n",
        "        # x.shape == (batch_size, seq_len, embed_dim)\n",
        "        # k_t == transposed key\n",
        "        # reshape splits the data across each attention head\n",
        "        k_t = self.key(x).reshape(batch_size, seq_len, self.num_heads, -1).permute(0, 2, 3, 1)\n",
        "        v = self.value(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n",
        "        q = self.query(x).reshape(batch_size, seq_len, self.num_heads, -1).transpose(1, 2)\n",
        "        # shape == (batch_size, num_heads, seq_len, head_dim)\n",
        "\n",
        "        attn = torch.matmul(q, k_t) / math.sqrt(q.size(-1)) # Q * K^T / âˆšd\n",
        "        # attn.shape == (batch_size, num_heads, seq_len, seq_len)\n",
        "        mask = self.mask[:, :, :seq_len, :seq_len] # across batch, select all words yet to be generated\n",
        "        attn = attn.masked_fill(mask == 0, float(\"-inf\")) # put -inf to mask tokens\n",
        "        attn = self.attn_dropout(attn)\n",
        "        # attn.shape == (batch_size, num_heads, seq_len, seq_len)\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "        y = torch.matmul(attn, v) # second matmul, (seq_len, seq_len) x (seq_len, heads_dim)\n",
        "        # y.shape == (batch_size, num_heads, seq_len, heads_dim)\n",
        "        y = y.transpose(1, 2)\n",
        "        # y.shape == (batch_size, seq_len, num_heads, heads_dim)\n",
        "        y = y.reshape(batch_size, seq_len, -1) # reconnecting data passed through each head\n",
        "        # y.shape == (batch_size, seq_len, embed_dim)\n",
        "        y = self.proj_dropout(self.proj(y))\n",
        "        return y"
      ],
      "metadata": {
        "id": "M0SoClqD8_AE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a concrete example of the mask matrix, assuming that we have a decoder whose maximum sequence length is 5."
      ],
      "metadata": {
        "id": "CpzTwjPjDf-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 5\n",
        "\n",
        "mask = torch.tril(torch.ones(max_len, max_len)).unsqueeze(0).unsqueeze(0)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOnGUqJrDgIr",
        "outputId": "ecf3b8cc-734d-4980-d7df-cfea79e20fc4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 0., 0., 0., 0.],\n",
              "          [1., 1., 0., 0., 0.],\n",
              "          [1., 1., 1., 0., 0.],\n",
              "          [1., 1., 1., 1., 0.],\n",
              "          [1., 1., 1., 1., 1.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, to mask each example in the batch, we mask in the following way:"
      ],
      "metadata": {
        "id": "78Xve9L0JbNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 3\n",
        "\n",
        "mask = mask[:, :, :seq_len, :seq_len]\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eNtjO1iKGW7",
        "outputId": "69b1155d-fa43-4fc5-e09d-5a29266219e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 0., 0.],\n",
              "          [1., 1., 0.],\n",
              "          [1., 1., 1.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# attn.shape == (batch_size, num_heads, seq_len, seq_len)\n",
        "batch_size = 3\n",
        "num_heads = 2\n",
        "\n",
        "attn = torch.randn(batch_size, num_heads, seq_len, seq_len)\n",
        "attn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTUkq1DoD0n_",
        "outputId": "58d5d69d-ec02-487c-ed9d-1ccfb57cef81"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see below, we have 3 batches that are separated into 2 attention heads, where the matrix is (seq_len, seq_len) where each row adds a new token."
      ],
      "metadata": {
        "id": "_BLfQtNUKcUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn = attn.masked_fill(mask == 0, float(\"-inf\"))\n",
        "attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWRhznhDKAZQ",
        "outputId": "c5239aea-2542-4399-d2f6-3c2071c91bef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-1.4991,    -inf,    -inf],\n",
              "          [-0.6522, -0.2875,    -inf],\n",
              "          [-0.3859, -0.2676,  0.3449]],\n",
              "\n",
              "         [[-0.5417,    -inf,    -inf],\n",
              "          [ 0.4578,  1.1385,    -inf],\n",
              "          [-0.1292,  0.3617,  1.6502]]],\n",
              "\n",
              "\n",
              "        [[[-0.5823,    -inf,    -inf],\n",
              "          [ 1.6902, -1.3269,    -inf],\n",
              "          [ 0.3759,  0.7223,  1.1238]],\n",
              "\n",
              "         [[-0.2738,    -inf,    -inf],\n",
              "          [-0.7617, -0.7891,    -inf],\n",
              "          [ 0.1969,  1.7865,  0.6715]]],\n",
              "\n",
              "\n",
              "        [[[-1.0717,    -inf,    -inf],\n",
              "          [ 1.7455,  0.4107,    -inf],\n",
              "          [-1.5003,  2.2838, -0.3378]],\n",
              "\n",
              "         [[-1.7366,    -inf,    -inf],\n",
              "          [-0.2629,  1.0714,    -inf],\n",
              "          [-0.4392,  0.3253,  0.5141]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we apply a softmax:"
      ],
      "metadata": {
        "id": "0vVfLIB-K9Nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(attn, dim=-1) # applies the softmax over each row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bL6LaN_KVbK",
        "outputId": "c8e1aa5a-6daf-4839-89ae-4a37c9adc978"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1.0000, 0.0000, 0.0000],\n",
              "          [0.4098, 0.5902, 0.0000],\n",
              "          [0.2380, 0.2678, 0.4942]],\n",
              "\n",
              "         [[1.0000, 0.0000, 0.0000],\n",
              "          [0.3361, 0.6639, 0.0000],\n",
              "          [0.1168, 0.1909, 0.6923]]],\n",
              "\n",
              "\n",
              "        [[[1.0000, 0.0000, 0.0000],\n",
              "          [0.9533, 0.0467, 0.0000],\n",
              "          [0.2209, 0.3124, 0.4667]],\n",
              "\n",
              "         [[1.0000, 0.0000, 0.0000],\n",
              "          [0.5069, 0.4931, 0.0000],\n",
              "          [0.1332, 0.6528, 0.2141]]],\n",
              "\n",
              "\n",
              "        [[[1.0000, 0.0000, 0.0000],\n",
              "          [0.7916, 0.2084, 0.0000],\n",
              "          [0.0207, 0.9129, 0.0664]],\n",
              "\n",
              "         [[1.0000, 0.0000, 0.0000],\n",
              "          [0.2084, 0.7916, 0.0000],\n",
              "          [0.1742, 0.3741, 0.4518]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "We can now put everything together and create a basic model."
      ],
      "metadata": {
        "id": "kEQfoxSTLZLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10\n",
        "max_len = 12\n",
        "\n",
        "config = GPT1Config(vocab_size, max_len)\n",
        "model = GPT(config)"
      ],
      "metadata": {
        "id": "Y1KLe0U-LKgy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple 12-layer decoder network."
      ],
      "metadata": {
        "id": "MQnRiyhLL9ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuKiQN1yL8ss",
        "outputId": "c478156d-a530-40c2-e786-c43e1db5d63f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (tok_embed): Embedding(10, 768)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (blocks): Sequential(\n",
              "    (0): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (1): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (2): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (3): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (4): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (5): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (6): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (7): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (8): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (9): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (10): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (11): Decoder(\n",
              "      (ln1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (1): GELU(approximate=none)\n",
              "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc): Linear(in_features=768, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test a dummy input and see if the model successfully acts the way we expect to. First, let's try passing in a degenerate input whose length is beyond model capacity."
      ],
      "metadata": {
        "id": "YcmHG2aEMPTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 15\n",
        "\n",
        "test_input = torch.randint(high=vocab_size, size=(batch_size, seq_len))\n",
        "try:\n",
        "    model(test_input).shape\n",
        "except AssertionError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJphABVlLqkF",
        "outputId": "e7994d66-4dfa-441f-8761-80435e2640e8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence longer than model capacity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get an appropriate assertion error, saying that the sequence is longer than the maximum sequence length that the model can process. Letâ€™s see what happens if we pass in a valid input."
      ],
      "metadata": {
        "id": "6n8Odu-SM_Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model(test_input[:, :max_len]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6qJPhPAM1ok",
        "outputId": "5aa72628-ce0b-4e62-ef05-d02943a79cd7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 12, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, we get a valid output of shape (batch_size, seq_len, vocab_size)."
      ],
      "metadata": {
        "id": "SZ0nF8q2OyRS"
      }
    }
  ]
}