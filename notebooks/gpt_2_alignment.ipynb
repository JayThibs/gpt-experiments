{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2-alignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jUCZYOMp49Vy",
        "C9ZvyvZyerDT",
        "ZXvm0wpQxS10"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/gpt-experiments/blob/main/notebooks/gpt_2_alignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lq-qHwDRba4"
      },
      "source": [
        "# Fine-Tuning GPT-2 on Alignment Texts Dataset\n",
        "\n",
        "This notebook is meant for initial experimentation of fine-tuning on the alignment text dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjSP3oGNHyJd",
        "outputId": "2f500025-6575-45dc-908f-07f96009af38"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  6 01:00:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap-rQ1P1Y058"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr14u8fcYR4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ef53a3-0855-4ecd-c889-c15bcba38634"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers jsonlines ftfy lm_dataformat wandb --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 32.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 22.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 47.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 62.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 54.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84TRkXXhY2U5"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvxQKSqQY3Fa"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import random\n",
        "import jsonlines\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import GPT2Tokenizer, GPT2TokenizerFast, AutoTokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n",
        "import ftfy\n",
        "from lm_dataformat import Reader\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vzBUVxTvfETA",
        "outputId": "06478701-75be-4cc6-a797-f03db9e876db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.11.0+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5tY6KPsgUFQ"
      },
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        "Here we will mount our Google Drive so that we can grab data and save the HuggingFace scripts, and save the model once we've fine-tuned it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNeXrm1qgWRp",
        "outputId": "506be403-892c-4f3e-d815-07d305cc6420"
      },
      "source": [
        "# For saving the data locally\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIMELLTfg76e",
        "outputId": "b667fa1b-b4fe-414f-9ca2-9ffd8d9e58fa"
      },
      "source": [
        "%cd drive/MyDrive/data/ai-alignment-dataset/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/ai-alignment-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/JayThibs/gpt-experiments"
      ],
      "metadata": {
        "id": "UK0_tMPMwPOg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-AVhqkVeluk"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Sub-Datasets"
      ],
      "metadata": {
        "id": "dWooQtxRtJar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open(\"af_lw_q_reply.jsonl\", \"w\") as writer:\n",
        "    with jsonlines.open(\"alignment_texts.jsonl\") as reader:\n",
        "        for line in reader:\n",
        "            try:\n",
        "                if (line[\"source\"] == \"alignment forum\" or line[\"source\"] == \"lesswrong\") and line[\"comments\"] != []:\n",
        "                    comm = \"\"\n",
        "                    rep = \"\"\n",
        "                    comments = line[\"comments\"]\n",
        "                    # print(comments)\n",
        "                    # break\n",
        "                    for comment in comments:\n",
        "                        text = comment['text']\n",
        "                        tokens = tokenizer.encode(text)\n",
        "                        # print('test')\n",
        "                        # break\n",
        "                        if len(tokens) <= 100 and \"?\" in text:\n",
        "                            comm = text\n",
        "                            # writer.write(line)\n",
        "                            # print(text)\n",
        "                    try:\n",
        "                        if comments[\"comments\"] != []:\n",
        "                            replies = comments[\"comments\"]\n",
        "                            replies = list(replies[0])\n",
        "                            for reply in replies:\n",
        "                                text = reply[\"text\"]\n",
        "                                tokens = tokenizer.encode(text)\n",
        "                                if len(tokens) <= 100:\n",
        "                                    rep = text\n",
        "                                    # writer.write(line)\n",
        "                                    # print(text)\n",
        "                    except:\n",
        "                        pass\n",
        "                    if comm != \"\" and rep != \"\":\n",
        "                        comment_reply = f\"Comment: {comm}\\n\\nReply: {rep}\"\n",
        "                        writer.write(comment_reply)\n",
        "            except:\n",
        "                pass"
      ],
      "metadata": {
        "id": "azR0JvPe8MhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aflw_list = []\n",
        "with jsonlines.open(\"af_lw_q_reply.jsonl\") as reader:\n",
        "    for line in reader:\n",
        "        aflw_list.append(line)"
      ],
      "metadata": {
        "id": "BL9AZTJx9knH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aflw_list[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYrGxwIAiDv8",
        "outputId": "bcacb6a5-3963-4b3e-851c-88cd8d2571e1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'authors': 'sortega',\n",
              "  'comments': [{'authors': 'Vaniver',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-30T21:43',\n",
              "    'id': '9Nwi6cQECahCtM7je',\n",
              "    'omega_karma': '',\n",
              "    'score': '6',\n",
              "    'text': 'See also past discussion of Zettelkasten on LW.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/pGhWW6cn2uRMuAR5J/a-bicycle-for-your-memory-1?commentId=9Nwi6cQECahCtM7je',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'JenniferRM',\n",
              "    'comments': [{'authors': 'sortega',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-11T06:49',\n",
              "      'id': 'Godhx2rN29BA7tAfz',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': 'Miller work was insightful on discarding bits of information in favor of chunks but it was written in a very informal tone. That stymied further research for a long time but when restarted, researchers realized that you can get very rich set of features but about a small number of chunks. See this summary of the story.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/pGhWW6cn2uRMuAR5J/a-bicycle-for-your-memory-1?commentId=Godhx2rN29BA7tAfz',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-31T19:04',\n",
              "    'id': 'ZWBKYiXTbEWFhq7R3',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'This claim seems super super important in terms of fundamental modeling of fundamental cognitive constraints:\\n> Early George A. Miller work estimated that the typical mind was able to hold 5 ± 2 chunks, **but more recent work suggests we are limited at about 4 chunks**.\\nWhy do you think this is true? (Here I cross my fingers and hope for a long explanation, with many links, and discussion of replication failures or a lack thereof <3)\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/pGhWW6cn2uRMuAR5J/a-bicycle-for-your-memory-1?commentId=ZWBKYiXTbEWFhq7R3',\n",
              "    'votes': '1'},\n",
              "   {'authors': 'TLW',\n",
              "    'comments': [{'authors': 'nim',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-31T17:14',\n",
              "      'id': 'Mj799uAEexrtehDCP',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Insight is hard to talk about, even harder to sound sane and logical while discussing. We could perhaps model \"having an insight\" as 2 stages: Asking an interesting new question, and producing a useful answer to that question. These 2 steps can often be at odds with each other: Improving the skill of making your answers more useful risks falling into habits of thought where you don’t ask certain possibly-interesting questions because you erroneously assume that you already know their whole answers. Improving the skill of asking wild questions risks forming too strong a habit of ignoring the kind of common sense that rules out questions with \"that shouldn’t work\", and yet is essential to formulating a useful answer once an interesting question is reached.\\n\\nThe benefits of erring toward the \"produce useful answers\" skillset are obvious, as are the drawbacks of losing touch with reality if one fails to develop it. I think it’s easy to underestimate the benefits of learning the skills which one can use to temporarily boost the \"ask interesting questions\" side, though. Sadly most of the teachable skills that I’m aware of for briefly letting \"ask interesting questions\" override \"produce useful answers\" come packaged in several layers of woo. Those trappings make them more palatable to many people, but less palatable to the sorts of thinkers I typically encounter around here. The lowest-woo technique in that category which comes to mind is oblique strategies.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/pGhWW6cn2uRMuAR5J/a-bicycle-for-your-memory-1?commentId=Mj799uAEexrtehDCP',\n",
              "      'votes': '2'},\n",
              "     {'authors': 'lise',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-31T12:52',\n",
              "      'id': '5BHBcvBXbiYqyyXwW',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'I don’t know whether this is exactly what you meant by \"missing insights\", but I’ve noticed that I use search way less than I should, in my own notes & resources as well as in web search engines.\\nIn the case of my own notes, adding more SRS cards usually fixes this: if I’ve been actively learning cards on some concept, I often do remember that I have resources related to that concept I can check when it comes up.\\nIn the case of the web… well, this is an ongoing process. There have been whole subdomains of my life where it hadn’t occurred to me that those are *also* things you can simply look up if you want. I’ve been trying to notice the moment where I realize I don’t know something, in order to trigger the \"so I should Google it\" action, but it takes time.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/pGhWW6cn2uRMuAR5J/a-bicycle-for-your-memory-1?commentId=5BHBcvBXbiYqyyXwW',\n",
              "      'votes': '2'},\n",
              "     {'authors': 'sortega',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-31T07:05',\n",
              "      'id': 'yoPLytcjJYFk8Hurm',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Usually, the central set of ideas or concepts of a field or the main points of insights of a book are a small subset of all the information out there. I think it’s realistic to target those to be memorized with the benefit that it’s easier to go from those to the rest of details either in your notes or searching.\\nFor that reason I have a specialized note type in Anki just for definitions.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/pGhWW6cn2uRMuAR5J/a-bicycle-for-your-memory-1?commentId=yoPLytcjJYFk8Hurm',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-31T02:40',\n",
              "    'id': 'tcSuQE5CNTfh55Cdy',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'There are (at least) two main issues with offloading things from memory. You talked about one of them; I think the other is also worth mentioning.\\nAs you mention, speed/\\u200bease of lookup is an issue.\\nThe other issue—and personally I find this to be *more* of a limiting factor—is missing insights. Cases where you *could* have looked it up had you known, but you didn’t know enough to know that you should have looked that particular thing up in the first place. (This is hard to provide an example for due to hindsight bias.)\\nIndexing can mitigate this to an extent, but is nowhere near a full solution.\\nAny ideas?\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/pGhWW6cn2uRMuAR5J/a-bicycle-for-your-memory-1?commentId=tcSuQE5CNTfh55Cdy',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Troof',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-31T15:21',\n",
              "    'id': 'ceAAy7upqgHjqufse',\n",
              "    'omega_karma': '',\n",
              "    'score': '1',\n",
              "    'text': 'You might be interested in this blog post, which develops similar ideas and use the same cache analogy.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/pGhWW6cn2uRMuAR5J/a-bicycle-for-your-memory-1?commentId=ceAAy7upqgHjqufse',\n",
              "    'votes': '1'}],\n",
              "  'date_published': '2022-03-30T21:41',\n",
              "  'id': 'pGhWW6cn2uRMuAR5J',\n",
              "  'omega_karma': '',\n",
              "  'score': '38',\n",
              "  'source': 'lesswrong',\n",
              "  'tags': 'Memory and Mnemonics/Scholarship & Learning',\n",
              "  'text': 'Contents\\n - The Cyborg Memory Hierarchy\\n - Level 0. Working memory\\n - Level 1. Long-term memory\\n - Level 2. Personal notes and annotations\\n - Level 3. Selected sources and everything else\\n - Does it make sense a partial implementation of this Cyborg Memory Hierarchy?\\n - How Neuralink or some other technology will change this?\\n - Your personal cyborg memory hierarchy\\n*Cross posted from **sortega.github.io*\\nComputers have the need to store huge amounts of information and, at the same time, being able to access that memory at blazingly fast rates. This poses the problem of how to get a fast and large memory when hardware memories are either fast, like registers or L1 cache lines; or big, like hard-drives or solid state drives.\\n**Memory****Size****Speed****Comment**CPU registerA few bytesOne CPU cycle (200-300 picoseconds)A register holds the data the CPU can operate onRAM memoryA few gigabytes100 nanosecondsApplications need their data to be here to be responsiveHard driveMany gigabytes150 microsecondsAll your applications and data being kept locally have a copy hereInternetInfinite (for all purposes)10-40 millisecondsTechnically *other people’s hard drives*This is solved in computer architecture by the interplay of two ideas: a **memory hierarchy** and **virtual memory**. The memory hierarchy consists of a pyramid with the fastest and smallest memories on the tip and slower but bigger ones at the base. This arrangement allows you to have a complete copy of the information at the base, which is the biggest. Then, you can keep copies of the actively used information closer to the pyramid apex for better performance. Virtual memory is the illusion of having a single memory space which is the result of the collaboration of specific hardware (MMU, CPU features) with the operative system to transparently move data across the levels of the pyramid. The result is that, for most purposes and most of the time, programs running in your computer get to use a single memory space that feels as big as the base of the pyramid and almost as fast as its top.\\nSimplified memory hierarchyApart from computers, humans are rich information processors[1] and memory plays a paramount role in what it means to be a human. On one hand it’s an important element of personal identity. Imagine a movie villain using technology or black magic[2]* *to swap the memories of two twin brothers. In some philosophical sense we are what we remember, and we will have a hard time deciding who is who in this contrived situation.\\nOn the other hand, memories are needed for our minds to work because without them, we will have only the raw input of our senses and no other concept or idea to work with. The extent to which we can understand the world, communicate with others and act depends on using those mental building blocks or chunks.\\nAnother aspect of being human not so directly related to information processing is tool making and tool use. Thanks to these, we have come a long way since we harnessed the power of fire and stone. Steve Jobs eloquently explained in this talk how humans will lose in almost all categories[3] of an Olympic Games in which other animals were allowed to take part. We are not the fastest, we cannot travel the furthest, nor in the most efficient way. However, any cyclist is more efficient in energy per distance than a Condor, the most efficient animal. Then, he declared computers to be like *a bicycle for the mind*. Back then, personal computing was being rolled out, and we were oblivious to the directions these new machines would cybernetically extend us.\\n## The Cyborg Memory Hierarchy\\nAt this point we have all the ingredients to define what I call the **cyborg memory hierarchy**: extending human capabilities with technology (cyborg)* *so we can enhance in-brain memory and extend it with external information (memory hierarchy).\\nCyborg memory hierarchy### Level 0. Working memory\\nOur working memory is composed of a phonological loop, where you can keep repeating a phone number while you search for pen and paper; the visuo-spatial sketchpad, where you can mentally manipulate shapes; and some very limited number of slots that can hold ideas, or chunks, for manipulation. Early George A. Miller work estimated that the typical mind was able to hold 5 ± 2 chunks[4], but more recent work suggests we are limited to about 4 chunks.\\nI doubt we will cybernetically extend our working memory until brain-computer interfaces become a reality, but I have some good news in the methodology front. The reason Miller got initially confused with the amount of mental slots is that we can do more with less by having more elaborate and high level chunks. For example, I might be able to work in my mind with only three digits (e.g. 7, 1, 4) but if they are dates, then I can hold many more digits (e.g. 1492, 2001, 1991).\\nIn fact, you can see expertise in any field as the slow and effortful learning of ever higher-level chunks and mental models (read Peak by Anders Ericsson). My advice: hunt all the important concepts in your field of interest and commit them to long-term memory (see next section).\\n### Level 1. Long-term memory\\nThese are memories that we can use fluently, regardless of our smartphone batteries being dead. These are critical for anything we do with fluency like speaking a language, being expert at anything, or being creative, which implies recombination of ideas that should be at the same time in our minds.\\nSome of these memories are *declarative* and can be expressed as answers to explicit questions. \"What’s the capital of Georgia? Tbilisi or Atlanta\". We can extend our declarative memories by reading and studying for which there is a wealth of technologies and channels but the main enemy to beat is how fast those new memories fade away from us.\\nWe know thanks to Hermann Ebbinghaus and his tedious self-experimentation with memorizing long sequences of nonsense words that facts decay exponentially in our minds unless reviewed and inter-related to other memories. His work was published in the XIX century, but no specific software was created to optimize when to review which piece of knowledge until Piotr Wozniak wrote the first spaced repetition software (SRS) in 1987. The underlying idea of this kind of software is that you encode what you have already understood and learned and want to keep in you memory as flash cards (short questions and answers) and the system keeps track of when to do reviews. Due to Ebbinghaus forgetting curve, the interval between reviews grows exponentially, so you see the typical card again after months or years. This means that you can keep many tens of thousands of cards in your level-zero memory at the cost of a few minutes of daily review.\\nFor a nice explanation of how to implement this with Anki, one of the most popular SRS nowadays, I recommend reading Augmenting Long-term Memory by Michael Nielsen. He is also experimenting with articles that embed an SRS like this one about quantum computing.\\nIf you want to read more about good practices with SRS, Wozniak’s Twenty Rules of Formulating Knowledge is the most authoritative source and Soren Bjornstad’s Rules for Designing Precise Anki Cards is a great complement.\\nParaphrasing Nielsen, *SRS makes declarative memory a choice*. If we ever think that keeping a fact or a concept available in our mind is more valuable than 5 minutes of our time[5] we can do it[6].\\nWhat about non-declarative memory? Muscle memory cannot be reduced to declarative facts, no one is able to learn how to bike by reading *How to ride a bike*. However, some creative thinking can help us to bridge the gap in some cases. For example, I use Anki to learn application shortcuts declaratively and then, as opportunity to use them in the day to day happens I build the muscle memory.\\n### Level 2. Personal notes and annotations\\nWhen we process information we tend to take notes or perform annotations in the medium itself, so we can come back to them without needing long-term memorization. Note that technically, pen and notebook are already cybernetic extensions for this purpose.\\nThese notes are indeed very useful for us to solidify our understanding and organization of ideas, specially if we do a write-up like a blog post. The mere act of writing, even at book marginalia, also improves our initial memorization.\\nHowever, the value of these notes is limited unless they are connected and easily searchable. To get that extra value we need to up both our methodological and technological games.\\nThe quintessential technology to fill this gap is the personal wiki in which you can seamlessly write notes, keep them inter-linked and securely access this second brain from all your devices. There is an inexhaustible offer of wikis out there (open source and SaaS). My recommendation is to pick one and try to use it unless blocked by a showstopper. A very common failure mode is to keep tuning your wiki configuration without really using it.\\nI personally use TiddlyWiki[7] with the amazing Soren’s TiddlyRemember plugin to define SRS cards directly from within my wiki notes. When reviewing them in Anki I get a valuable link to their original context.\\nOn the methodology front, I recommend the philosophy of Zettelkasten that was introduced by Niklas Luhmann, a very prolific German social scientist that implemented the logical equivalent to a wiki for his research notes using Victorian technology. Luhmann was carefully digesting other academics books and articles into chunks or ideas written in index cards that were linked, tagged and annotated to form a web of knowledge that he traversed in a myriad ways, leading to serendipitous connections bringing a deeper understanding—and many publications! By the way, *zettel* is German for note while *kasten* means box.\\nHow a personal wiki looks like in steampunk styleSoren Bjornstad adapted TiddlyWiki for Zettelkasten and he extensively explains the result in this video. The template is available for anyone to use.\\n### Level 3. Selected sources and everything else\\nAt this level, we have all the source material—books[8], articles—we collected and totally or partially read and quite likely you took notes and made flashcards about. At the mid-level of technology, you can picture cozy bookshelves at home but to give you more value, you need to get it organized and searchable.\\nFor this purpose I use Calibre, which was presented to me as *the iTunes of ebooks*. Any other ebook organizer will do as long as you have a nice desktop search engine, so you can easily get back to the tidbits of your books that are neither in you head nor your notes. The spotlight search of Mac OS X is a good starting point for this.\\nApart from these selected sources, we have ad-hoc information needs which we satisfy by using general search engines. Google, Bing, DuckDuckGo… choose your poison but once chosen, learn to use it properly (1, 2).\\n### Does it make sense a partial implementation of this Cyborg Memory Hierarchy?\\nI think that any missing piece is problematic.\\nIf you have SRS without a personal wiki you will tend to either create flashcards for things that are not really meant for that, and you might burn out; or otherwise, you might let go many valuable things.\\nIf you have a wiki without SRS you won’t be fluid enough to take advantage of many things. For example, you can have great coding design patterns documented in your notes and never remember to apply them when the right conditions apply.\\nIf you only have a search engine, you might not even know what to search about to solve a problem and your thinking will tend to be more shallow (related book: The Shallows: What the Internet is Doing to Out Brains).\\n### How Neuralink or some other technology will change this?\\nI have no idea. I can only speculate that tighter integration with our brains can collapse some levels or open new ones that we do not even understand today. Maybe the Neuralink-enabled Anki feels exactly like Neo’s learning Kung Fu in The Matrix.\\n### Your personal cyborg memory hierarchy\\nIf you have some concept or implementation similar to the cyborg memory hierarchy or this post has inspired you to implement one for yourself I am very interested in knowing about your experiences. Please write a comment about it! \\n\\n - ^This used to be a false dichotomy as *computer* was a job title for humans! Until the invention of the modern electronic computer, a *computer* was a person—most likely a woman—skilled enough at mathematical computation to, for example, slowly tabulate a logarithm table.\\n\\n\\n - ^\"Any sufficiently advanced technology is indistinguishable from magic\" (Arthur C. Clarke)\\n\\n\\n - ^One exception is that we can keep walking and running sustainably way longer than other animals. When we were hunter-gatherers persistence hunting—hunting by exhausting your prey—was a thing. Another exception is our eye-to-hand coordination for throwing rocks and spears. I suppose people less apt at these things were wiped out from the gene pool by Mother Evolution. \\n\\n\\n - ^This is the origin of the *magic number 7* (5 + 2)* *that is used to prescribe no more than 7 levels or class inheritance, no more than 7 attributes per class, no more than...\\n\\n\\n - ^Gwern estimates in about 2 minutes the total time that it takes remember a fact *foreverish* with Anki. I am doubling that estimate to compensate form the rest of us not being as bright as him.\\n\\n\\n - ^What a great pity not having had SRS in my tool belt during my university years. I would now remember more of the original content, and I would not have needed re-learning it years after my graduation.\\n\\n\\n - ^One of the strong points of TiddlyWiki is how you can deeply customize it for your purposes without leaving its markup language and dropping to JavaScript. Its plugin mechanism is also based in the same customizations that a regular user can afford and that means the small community around it has published a huge amount of plugins that you can mix and match.\\n\\n\\n - ^A bookshelf was considered disruptive technology in times of Plato and Plato considered books will make people forgetful. We can forgive him because there was no SRS back them to compensate for this effect.\\n\\n',\n",
              "  'title': 'A bicycle for your memory\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/pGhWW6cn2uRMuAR5J/a-bicycle-for-your-memory-1',\n",
              "  'votes': '13'},\n",
              " {'authors': 'Yonatan Cale',\n",
              "  'comments': [{'authors': 'adamzerner',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-30T19:50',\n",
              "    'id': '7rp5murx5GTxokapM',\n",
              "    'omega_karma': '',\n",
              "    'score': '10',\n",
              "    'text': 'Yes! This! User test all the things! I never understood[1] why user testing wasn’t more popular in fields other than tech, and for things where the stakes are lower, like blog posts.\\n\\nI previously took a brief stab at making a similar point in the context of writing readable code.\\n\\n\\n\\n\\n - Well, I do have some hypotheses related to biases, incentives, and trivial inconveniences. ↩︎\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/8BGexmqqAx5Z2KFjW/how-to-make-your-article-change-people-s-minds-or-actions?commentId=7rp5murx5GTxokapM',\n",
              "    'votes': '8'},\n",
              "   {'authors': 'mbrooks',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-30T19:58',\n",
              "    'id': 'e2A6fm4odCLvf7Lbd',\n",
              "    'omega_karma': '',\n",
              "    'score': '6',\n",
              "    'text': 'It’s weird that I have my own startup, completely understand using real users for user testing, and also barely ever \"user-test\" any of my writing with actual audience members.\\nOnce you shared with me your document it became super clear I should, so thank you!\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/8BGexmqqAx5Z2KFjW/how-to-make-your-article-change-people-s-minds-or-actions?commentId=e2A6fm4odCLvf7Lbd',\n",
              "    'votes': '5'},\n",
              "   {'authors': 'Phil Scadden',\n",
              "    'comments': [{'authors': 'Yonatan Cale',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-01T17:48',\n",
              "      'id': 'p9TiphHDP6wRBa7sb',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'I agree with everything\\nFor most posts here (such as hiring posts), I do think the author can/\\u200bshould aim to a changed mind \"immediately\", mainly because (1) it is possible and not too hard, and (2) not aiming for that can be an easy enough \"excuse\" to avoid admitting that the post failed at what it’s supposed to do. (Almost every post will get an encouraging review response of at least \"nice post!\", so having that as a bar seems too low, I think).\\nI’ll add that another thing that influences my opinion is (3) I think lots of people fill their post with counter-arguments to arguments that nobody would really make and I think this really lowers posts’ quality.\\nFor very hard posts such as \"convince about evolution\"—perhaps a goal of \"change someone’s mind immediately\" is too high, but I assume you’d still agree that doing user testing would be very valuable. (?)\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/8BGexmqqAx5Z2KFjW/how-to-make-your-article-change-people-s-minds-or-actions?commentId=p9TiphHDP6wRBa7sb',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-31T19:31',\n",
              "    'id': 'KbJAhKPu4FrSczzzP',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'I am not sure you can read too much by immediate reaction. If the article amounts to an attack on beliefs they are vested in, then initial reactions can be strongly defensive (lawyer mode—defend a position), but a week of thinking about it can result in change. The positive sign there is coming back to you with more questions. (a shift to science mode—curiosity about truth).\\nI read an interesting book defending and explaining the truth of evolution written primarily for a Christian audience. The author explained the process whereby he changed from being 6-day creationist to conventional science position. It wasnt quick, it involved multiple arguments, and it also needed time for him to think without being pressured about it by evolutionists. \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/8BGexmqqAx5Z2KFjW/how-to-make-your-article-change-people-s-minds-or-actions?commentId=KbJAhKPu4FrSczzzP',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'Ben Pace',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-30T23:55',\n",
              "    'id': 'Fbmo8taDvfqW5Kuq8',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'Strong plus 1 to this.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/8BGexmqqAx5Z2KFjW/how-to-make-your-article-change-people-s-minds-or-actions?commentId=Fbmo8taDvfqW5Kuq8',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'brook',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-31T09:17',\n",
              "    'id': 'rNwLCFw4oJxLBzRji',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'Good post! Stop assuming things are/\\u200baren’t good and go and look. Is it worth making live-call-reviews a feature request for the LW feedback system? (Possibly limited to higher karma than the 100 required for text feedback, as I imagine this would have a smaller bottleneck with timezones etc.?). I imagine this would encourage a lot more people to say \"I’ve got to do this now!\". \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/8BGexmqqAx5Z2KFjW/how-to-make-your-article-change-people-s-minds-or-actions?commentId=rNwLCFw4oJxLBzRji',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'axiomAdministrator',\n",
              "    'comments': [{'authors': 'Raemon',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-30T23:41',\n",
              "      'id': 'vrLTHhG8YKJDS8x3B',\n",
              "      'omega_karma': '',\n",
              "      'score': '13',\n",
              "      'text': 'I think there’s a version on this that is \"adversarially try to generate exactly the right text to change people’s minds, regardless of truth value\", which I’d consider dishonest/\\u200banti-epistemic. But I think there’s a perfectly reasonable approach here that is \"make sure your writing actually engages with the worldview and reasoning of the people you’re trying to engage with\".\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/8BGexmqqAx5Z2KFjW/how-to-make-your-article-change-people-s-minds-or-actions?commentId=vrLTHhG8YKJDS8x3B',\n",
              "      'votes': '8'}],\n",
              "    'date_published': '2022-03-30T23:34',\n",
              "    'id': 'MncpBLJtmmjC54zkm',\n",
              "    'omega_karma': '',\n",
              "    'score': '−13',\n",
              "    'text': 'TL; DR No longer LW. Good bye.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/8BGexmqqAx5Z2KFjW/how-to-make-your-article-change-people-s-minds-or-actions?commentId=MncpBLJtmmjC54zkm',\n",
              "    'votes': '5'}],\n",
              "  'date_published': '2022-03-30T17:39',\n",
              "  'id': '8BGexmqqAx5Z2KFjW',\n",
              "  'omega_karma': '',\n",
              "  'score': '54',\n",
              "  'source': 'lesswrong',\n",
              "  'tags': 'Practical/Writing (communication method)/Feedback & Criticism (topic)',\n",
              "  'text': 'Contents\\n - I specifically recommend:\\n - (1) Watch them read it, don’t just ask for Google Doc comments\\n - (2) Show it to your target audience, don’t just ask others what your target audience would think\\n - (3) Check if they changed their mind, not just if they like your writing\\n - The general intuition:\\n - How to start?\\nAre you writing an article that’s supposed to change people’s minds and/\\u200bor actions? For example, an article about career advice, productivity, or getting people to apply for a job? Then this post is for you!\\nTL;DR: For important articles I recommend doing real user testing (even with just one person!). Try it and you’ll never go back.\\n# I specifically recommend:\\n## (1) Watch them read it, don’t just ask for Google Doc comments\\nOpen a zoom, share screen, and ask them to share their thoughts live as they read.\\n## (2) Show it to your target audience, don’t just ask others what your target audience would think\\nIf your article is supposed to change developers’ career plans, ask a dev who might change their career plan. Don’t ask a biologist what a dev might think.\\n## (3) Check if they changed their mind, not just if they like your writing\\nIf they end with \"I’ve got to do this now!\": That’s a good sign. \\nIf they say \"sounds interesting, I’ll think about it\", that’s not as good.\\nI personally like to first ask the other person for their opinion (for example, \"what’s your current career plan?\"), then let them read the article, and then ask again.\\n# The general intuition:\\nIf you want to adopt my frame of mind, ask yourself: Would your idea of how to improve [the article’s persuasiveness] also improve [how engaging a startup’s app] is?\\nHere are some exercises, do you think these would work?\\n\\n - Let GPT-3 look at the app (or article) and tell you how engaging the app (or how persuasive the article) is\\n\\n - Try to guess in advance all the reasons why your target audience won’t agree with the article, or won’t be engaged with the app\\nHint: Is the test [checking if a real user from your target audience changes their mind] or [using some proxy to guess whether a real user would change their mind] ?\\n# How to start?\\nEasiest: post in Bountied Rationality, or in another group that has your target audience.\\nA draft post you can copy & paste: \"Hey, I’ll pay $10 for someone in [describe your target audience here] to review a post of mine for the EA/\\u200blesswrong forum. I want to do it live, over a video call. The call is capped at 30 minutes (and expected to be less). Comment or message me if you’re interested. Tagging or referring relevant people is also appreciated.\"\\nThanks to Matt Brooks and Daniel Reeves for helping make this article better <3\\n',\n",
              "  'title': 'How to Make Your Article Change People’s Minds or Actions? (Spoiler: Do User Testing Like a Startup Would)\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/8BGexmqqAx5Z2KFjW/how-to-make-your-article-change-people-s-minds-or-actions',\n",
              "  'votes': '31'},\n",
              " {'authors': 'AllAmericanBreakfast',\n",
              "  'comments': [{'authors': 'Randomized, Controlled',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T01:48',\n",
              "    'id': 'tGfeH3WFsyHrxArer',\n",
              "    'omega_karma': '',\n",
              "    'score': '10',\n",
              "    'text': 'As a kid I developed something that basically is a body scan. I worried about monsters while I was lying in bed. At some point I started imagining a field of green energy starting at the very bottom of my feet and working its way very slowly up each leg, then my torso, down my arms, and finally to the very top of my head. Once I was cloaked in this protective green shield I was safe, as long as I didn’t move. It broke if I moved. But if I stayed still I could then inflate it outwards, enveloping my house, neighborhood, city, and eventually the entire world in a protective shield.\\n\\nI’m skeptical of the idea of a collective unconscious, but still find it an interesting/\\u200bodd coincidence (and/\\u200bor weak evidence in favor of a collective unconscious) that I basically developed a body scan practice 35 years before I ever learned anything about meditation, and that it also included a universalist component, enveloping the entire world in protection.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=tGfeH3WFsyHrxArer',\n",
              "    'votes': '5'},\n",
              "   {'authors': 'mingyuan',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T06:29',\n",
              "    'id': 'emBrmjdnqDDAJmaKG',\n",
              "    'omega_karma': '',\n",
              "    'score': '7',\n",
              "    'text': 'Something similar works for me! Basically purposely dropping into the state of unfocused nonsense that generates dreams\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=emBrmjdnqDDAJmaKG',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'shminux',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-28T23:38',\n",
              "    'id': '6Kmxq885bBJcCmG9y',\n",
              "    'omega_karma': '',\n",
              "    'score': '7',\n",
              "    'text': 'I assume this stuff is highly personal. I have discovered during grad school that trying to do mental research-level calculations in bed makes my brain turn off within a few minutes. YMMV.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=6Kmxq885bBJcCmG9y',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'GuySrinivasan',\n",
              "    'comments': [{'authors': '9eB1',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T23:52',\n",
              "      'id': 'DDownj2phTwwrHz5q',\n",
              "      'omega_karma': '',\n",
              "      'score': '4',\n",
              "      'text': 'I learned a similar trick from an old LW post. You focus on the static in your visual field. If it starts to resolve into random seeming images, that is the beginning of hypnogagia, and if it starts to resolve into even more concrete imagery you are very close to sleep. Try to keep focusing on it, eventually you will fall asleep. This generally works for me.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=DDownj2phTwwrHz5q',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-29T01:50',\n",
              "    'id': 'G6Wur5rNXSK73D6vW',\n",
              "    'omega_karma': '',\n",
              "    'score': '6',\n",
              "    'text': '> At the same time, I let myself visualize nonsense images. My visual imagination isn’t very vivid, and I don’t try to create any specific images. It’s nothing more than a patchy and low-res mental screensaver.\\nI also don’t visualize. To reliably put myself to sleep assuming I’m not wide awake, I do my best to focus on the static and try to see images.\\nI visualize during dreams; or at least my waking memory says I was visualizing during dreams.\\nDuring hypnagogia, I *can* visualize, a bit. Trying to visualize moves me into hypnagogia, continuing puts me to sleep.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=G6Wur5rNXSK73D6vW',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'xepo',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T00:44',\n",
              "    'id': 'JbcHehNiYAeioArBd',\n",
              "    'omega_karma': '',\n",
              "    'score': '6',\n",
              "    'text': 'Thanks for posting this! will try it.\\nThe trick that works for me when I have too many things in my head and it’s keeping me from sleeping is to pull out my phone/\\u200blaptop, and write them all down. Just stream-of-consciousness. Write everything you can think of, until you run out of things to write. Pause for a second looking for more things to write and if nothing comes to you, then turn off the phone and go to sleep.\\nIt just clears my head and lets me stop circling.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=JbcHehNiYAeioArBd',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'Gunnar_Zarncke',\n",
              "    'comments': [{'authors': 'chaosmage',\n",
              "      'comments': [{'authors': 'Gunnar_Zarncke',\n",
              "        'comments': [{'authors': 'chaosmage',\n",
              "          'comments': [],\n",
              "          'date_published': '2022-04-09T12:16',\n",
              "          'id': 'yrZvc3zRpfn2it6Gi',\n",
              "          'omega_karma': '',\n",
              "          'score': '2',\n",
              "          'text': 'I find it too hard to keep things unrelated over time, so I prefer to keep thinking up new objects at what passes for random to my sleepy mind.\\n',\n",
              "          'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=yrZvc3zRpfn2it6Gi',\n",
              "          'votes': '1'}],\n",
              "        'date_published': '2022-03-29T09:45',\n",
              "        'id': 'tNdDFv9o45HKQmGes',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'I let my mind wander quickly from visuals to forms to patterns to speech to persons or some such—all unrelated to each other. It doesn’t work reliably but better than nothing.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=tNdDFv9o45HKQmGes',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-03-29T07:23',\n",
              "      'id': 'xvWjXA85jcyFxCqeb',\n",
              "      'omega_karma': '',\n",
              "      'score': '5',\n",
              "      'text': 'Yes, my method is to visualize a large collection of many small things that have no relation to each other, like a big shelf of random stuff. Sometimes I throw them in all directions. This is the best method I have found.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=xvWjXA85jcyFxCqeb',\n",
              "      'votes': '3'}],\n",
              "    'date_published': '2022-03-29T00:32',\n",
              "    'id': 'eoZocqWuBfxyyu9DK',\n",
              "    'omega_karma': '',\n",
              "    'score': '6',\n",
              "    'text': 'I learned from chaosmage that focusing on a single topic tends to make you awake while diluting your awareness with many different topics makes you sleepy. Or something like that. I have tried that and can tentatively confirm it. Your method sounds make like the latter.  \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=eoZocqWuBfxyyu9DK',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'abramdemski',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-31T21:13',\n",
              "    'id': '3pb9zKea2qyrr5hTf',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'For me, I *notice* that my thoughts go in the direction of visual and linguistic nonsense *as *I drift to sleep. I will think thoughts that (if I wake up a bit more to evaluate them) do not make sense, or make sense but do not correspond to reality. (I have not yet been able to recall examples when fully awake.) Noticing that my thoughts have become nonsense has a tendency to bring me closer to awakeness, but (it seems to me) bending my thoughts in the direction of nonsense on purpose does help me to fall asleep somewhat.\\nI do wonder if noticing my thoughts shift towards dream-logic might help me to notice rationalization and other cognitive errors while awake.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=3pb9zKea2qyrr5hTf',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Dr_Manhattan',\n",
              "    'comments': [{'authors': 'Alex Vermillion',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-30T17:36',\n",
              "      'id': 'LDvCKLoXQtzu5NFFf',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'In case you don’t know, your specific show pick has been noted as a favorite for this: https://\\u200b\\u200bwww.reddit.com/\\u200b\\u200br/\\u200b\\u200bFuturama_Sleepers/\\u200b\\u200b\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=LDvCKLoXQtzu5NFFf',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-29T18:19',\n",
              "    'id': 'fiEqgZoECpFFKWJwQ',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'Sharing a personal weird trick why not. I like falling asleep to light TV (via iPad). I watch short shows that a) I like and don’t think are boring b) I have seen before. Usually 10 minutes into a 20 min show I’m ready (Futurama is my favorite for this + my meme game is much improved by this)\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=fiEqgZoECpFFKWJwQ',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Tornus',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T14:08',\n",
              "    'id': 'ZZSyDK4KfbkkXHEdf',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'When I had an acute bout of insomnia, one of the things I found most helpful was listening to sleep-focused bedtime stories. The key part wasn’t the sleepy imagery, but rather just having something boring and inconsequential that my mind could latch onto, to replace the busy inner dialog.\\n\\nI particularly like the stories from the Headspace app—they’re slightly randomized each night, which prevents you from using the story progress as a timer (\"Oh no, we’re up to the skunk already and I’m still not asleep!\")\\n\\nRelated: I also found it extremely helpful to get rid of my bedside clock and to use a smart watch for sleep tracking rather than keeping track of my sleep manually. Worrying about sleep makes your sleep worse, and keeping track of how you’re doing tends to feed the sleep anxiety.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=ZZSyDK4KfbkkXHEdf',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'BleenBlegg',\n",
              "    'comments': [{'authors': 'AllAmericanBreakfast',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T14:27',\n",
              "      'id': 'XsHgWFkaJsWptvEKo',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': '10-15 years ago, I occasionally would grab a sleeping bag and sleep outside in the yard.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=XsHgWFkaJsWptvEKo',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-29T07:07',\n",
              "    'id': 'igdFg3Eb7nomxD2Dw',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'I try sleeping on the floor when bed isn’t working. It often works. When I inevitability wake up from discomfort, I switch back to bed and fall asleep properly.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=igdFg3Eb7nomxD2Dw',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'Phil Scadden',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-30T20:20',\n",
              "    'id': 'KdC67zAgJXnfuiSfg',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'I battled pretty major insomnia and beat it with \"bog-standard\" CBT-I. Reflecting, i think there are key useful tricks.1/\\u200b Never toss and turn. Get up and read for 20min. Seriously.2/\\u200b Learn some kind of mindfulness/\\u200bmeditation exercises that you practise when not in bed. Particularly body-scan. I didn’t understand why CPT-I pushed this as it seemed counterintuitive, but it trains your brain NOT to notice discomfort/\\u200bbody position. \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=KdC67zAgJXnfuiSfg',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'MichaelD',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-30T15:28',\n",
              "    'id': 'SyGnZLQubinJtR4DP',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'I’m on a self-improvement binge (for about 15 years at this point) and though I don’t call myself Christian, to sleep I recite The Lord’s Prayer phrase by phrase, meditating on the meaning of each phrase—why it’s there, what the intended effect is, whether I agree, and how I might do that thing if I agree. Stressing here that I am not praying: I am considering the meaning of one of the most widespread human mantras in my corner of the world.\\nIf that doesn’t work, my next step is to pray (again, I am not Christian—that’s not what this is about) that everyone will do the right thing, whatever that is. Sometimes I direct it at current events, sometimes generally.\\nI think that it’s the concentration that puts me to sleep, and the effects on my behavior and attitude are bonus points.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=SyGnZLQubinJtR4DP',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'matto',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T00:42',\n",
              "    'id': 'xC272b7fe7Q3rXBoR',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'My trick is to focus on bodily sensations and move this focus around.\\nFor example, I will focus on how my arm feels again the pillow. Then I’ll start probing details, like how does my palm feel? How does my elbow feel? How does the skin on my knuckles feel? And then I’ll zoom out and shift to another major body part. It’s kind of like shining a flashlight and refocusing the beam. \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick?commentId=xC272b7fe7Q3rXBoR',\n",
              "    'votes': '2'}],\n",
              "  'date_published': '2022-03-28T22:47',\n",
              "  'id': 'JK7KF9AWBpjbZqTDn',\n",
              "  'omega_karma': '',\n",
              "  'score': '34',\n",
              "  'source': 'lesswrong',\n",
              "  'tags': 'Practical/Sleep',\n",
              "  'text': 'My dad used to suffer from insomnia, holding imaginary meetings in his head late into the night. I’m the same way.\\nOne stress-relief technique from Johns Hopkins is a breathing + mantra exercise. I find their mantra recommendation cringey:\\n> Breathing in I am calm, breathing out I am coping.\\nMantras, guided imagery, and autogenic training are generally hard for me, because I feel pressure to \"stay focused on the mantra.\"\\n*BREATHING IN I AM CALM, BREATHING OUT I AM COPING***My weird trick** is to replace the mantra with free-form inner-monologue nonsense syllables. Here’s an example:\\n> Nimbla doobla deeble dee… simba dimba lima nooble doo...\\nI let the pacing and \"mental voice\" vary, but mainly aim for a sleepy-sounding tone.\\nAt the same time, I let myself visualize nonsense images. My visual imagination isn’t very vivid, and I don’t try to create any specific images. It’s nothing more than a patchy and low-res mental screensaver. Not even this exciting:\\nThis puts me right to sleep.\\nIf you have refinements of anti-insomnia tricks that aren’t on bog-standard lists like this one, go ahead and add them in the comments!\\n',\n",
              "  'title': 'Mental nonsense: my anti-insomnia trick\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/JK7KF9AWBpjbZqTDn/mental-nonsense-my-anti-insomnia-trick',\n",
              "  'votes': '22'},\n",
              " {'authors': 'leogao',\n",
              "  'comments': [{'authors': 'TLW',\n",
              "    'comments': [{'authors': 'jsd',\n",
              "      'comments': [{'authors': 'Quintin Pope',\n",
              "        'comments': [{'authors': 'leogao',\n",
              "          'comments': [],\n",
              "          'date_published': '2022-03-29T14:54',\n",
              "          'id': 'Fy2i3CqfKPQgn2Bqd',\n",
              "          'omega_karma': '',\n",
              "          'score': '2',\n",
              "          'text': 'Detecting the bad circuit might be possible in practice, but there does exist a case where this doesn’t work. Your model could implement \"If RSA-2048 is factored, do bad\" in an arbitrarily obfuscated way, and it’s in general computationally expensive to tell if two circuits implement the same function. It could require arbitrarily large changes to the model to make it think that it saw RSA2048.\\n',\n",
              "          'url': 'https://www.lesswrong.com/posts/oijJc8Mu2jPNgpuvy/asot-some-thoughts-about-deceptive-mesaoptimization?commentId=Fy2i3CqfKPQgn2Bqd',\n",
              "          'votes': '2'}],\n",
              "        'date_published': '2022-03-29T05:23',\n",
              "        'id': 'R2qw9FteS9Tm4drrY',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'Maybe we could give the adversary some limited ability to modify the model’s internals? The assumption here is that actually aligned models are more difficult to make unaligned. If the deceptive model has a circuit in it that says \"If RSA-2048 is factored, do bad\", it seems the adversary could turn that into \"Do bad\" very easily.\\n\\nThis risks incorrectly flagging some useful capabilities of an aligned model, such as a circuit that predicts the actions of a misaligned opponent. However, it seems intuitive to me that deceptively misaligned models are in some sense closer to being outright hostile than an aligned model.\\n\\nWe could even imagine some sort of meta adversarial training where the model learns not to have any small modifications that cause it to behave badly, using either RL or meta gradient descent over the modifications made by the adversary.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/oijJc8Mu2jPNgpuvy/asot-some-thoughts-about-deceptive-mesaoptimization?commentId=R2qw9FteS9Tm4drrY',\n",
              "        'votes': '2'},\n",
              "       {'authors': 'TLW',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-30T03:58',\n",
              "        'id': 'D4F2BxatfNuu37Nk9',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': 'Right. And it’s not even sufficient to set up an adversary that goes ‘the model behaves badly if you satisfy X condition’, because there’s no guarantee that X condition is actually satisfiable.\\nYou could ask the adversary to come up with an existence proof… but then the agent could do e.g. ‘do X if you see something with SHA512 hash of all zeroes’, which is strongly conjectured to exist but isn’t proven.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/oijJc8Mu2jPNgpuvy/asot-some-thoughts-about-deceptive-mesaoptimization?commentId=D4F2BxatfNuu37Nk9',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-03-29T04:21',\n",
              "      'id': 'MCriJ8i4i3ehTPDhK',\n",
              "      'omega_karma': '',\n",
              "      'score': '6',\n",
              "      'text': 'It’s an example first written about by Paul Christiano here (at the beginning of Part III).\\nThe idea is this: suppose we want to ensure that our model has acceptable behavior even in worst-case situations. One idea would be to do adversarial training: at every step during training, train an adversary model to find inputs on which the model behaves unacceptably, and penalize the model accordingly. \\nIf the adversary is able to uncover all the worst-case inputs, this penalization ensures we end up with a model that behaves acceptably on all inputs.\\nRSA-2048 is a somewhat contrived but illustrative example of how this strategy could fail:\\n> As a simple but silly example, suppose our model works as follows:\\n\\n - Pick a cryptographic puzzle (e.g. \"factor RSA-2048\").\\n\\n - When it sees a solution to that puzzle, it behaves badly.\\n\\n - Otherwise, it behaves well.\\nEven the adversary understands perfectly what this model is doing, they can’t find an input on which it will behave badly unless they can factor RSA-2048. But if deployed in the world, this model will eventually behave badly.\\nIn particular:\\n> Even the adversary understands perfectly what this model is doing, they can’t find an input on which it will behave badly unless they can factor RSA-2048\\nThis is because during training, as is the case now, we and the adversary we build are unable to factor RSA-2048.\\n> But if deployed in the world, this model will eventually behave badly.\\nThis is because (or assumes that) at some point in the future, a factorization of RSA-2048 will exist and become available.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/oijJc8Mu2jPNgpuvy/asot-some-thoughts-about-deceptive-mesaoptimization?commentId=MCriJ8i4i3ehTPDhK',\n",
              "      'votes': '5'}],\n",
              "    'date_published': '2022-03-29T02:18',\n",
              "    'id': 'tcnrhxpicQhcfAq2b',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'I am confused about your use of ‘RSA2048’.\\nIs there a piece of jargon that I’m missing? I know about the cryptographic system.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/oijJc8Mu2jPNgpuvy/asot-some-thoughts-about-deceptive-mesaoptimization?commentId=tcnrhxpicQhcfAq2b',\n",
              "    'votes': '2'}],\n",
              "  'date_published': '2022-03-28T21:14',\n",
              "  'id': 'oijJc8Mu2jPNgpuvy',\n",
              "  'omega_karma': '11',\n",
              "  'score': '24',\n",
              "  'source': 'alignment forum',\n",
              "  'tags': 'Mesa-Optimization/AI',\n",
              "  'text': '*Editor’s note: I’m experimenting with having a lower quality threshold for just posting things even while I’m still confused and unconfident about my conclusions, but with this disclaimer at the top. Thanks to AI_WAIFU for discussions.*\\nI think of mesaoptimization as being split into different types: aligned (which is fine), misaligned (which is bad), and deceptively aligned (which is really bad—I draw the line for deceptively aligned when it actually tries to hide from us instead of us just not noticing it by accident). I mostly think about deceptive mesaoptimization, and I think of regular misaligned optimization as basically an easier case because at least it’s not trying to hide from us (what it means for it to actually be \"trying to hide\" is kinda fraught anyways so this sidesteps that). In particular, I think of mesaoptimizers as being dangerous because they fail in a malign way (I don’t think mesaoptimization itself is necessarily bad, and preventing it doesn’t seem obviously good).\\n## OOD-focused framework of deception\\nOne framework for thinking about deceptive mesaoptimizers that I used to use a lot was that they would be good on the training distribution, but then do bad things out of distribution. In this framework, what we would do is then to try to somehow tell during training whether a model is going to do bad things out of distribution, and only keep the ones that don’t, or something along those lines. The intuition is that the mesaoptimizer cares about something in the real world, but it knows that if we catch it then it will not be able to achieve its goals in the real world, so it behaves normally on the training distribution when we’re looking at it but then in deployment it goes and does evil things to satisfy its mesaobjective. Importantly, pursuing the mesaobjective hurts the base objective (since we’re only focusing on inner alignment here we can assume that the base objective is accurate), so deployment is the only time where it can do evil things without getting itself removed. \\nThe main reason here that deception happens is that your base objective isn’t being integrated over the set of all possible states. In theory, if we could enumerate the entire (huge) input space, we could eliminate deceptive behavior entirely. We’d just simply test every single input and see how whether there are any regions where the model does a treacherous turn and consequently tanks the base objective (for now I’m trying to isolate inner alignment so I’m assuming we’ve solved outer alignment and have a value function that we can just query). If there is nowhere in the entire input source where the model does a treacherous turn, then congratulations, your model is, for all intents and purposes, indistinguishable from being not deceptively aligned. (Non-deceptive inner misalignment is very similar except the mesaoptimizer won’t be trying to hide from you.)\\nIn practice, the input space is absolutely enormous, and it’s completely and utterly infeasible to enumerate it. Still, we might think to approximate that \"perfect\" red teaming by doing a really good approximation with loads of input instances sampled from a broad distribution, possibly with the help of other NNs. Unfortunately, I think this approach is fundamentally doomed, no matter how good the red ranking distribution is made. For this to work, the entire distribution of possible inputs in the real world would have to be covered by the red teaming distribution, and any small imperfections are potential points of leverage for the mesaoptimizer. Aside from some contrived existence proofs like the RSA2048 example (which are admittedly very useful for thinking about these things so I use them a lot despite the contrivedness), there are simply many things that could pop up in the real world (and especially the future) that we simply cannot predict/\\u200bsimulate, and that would be a giveaway signal of being in the real world. \\nGiven an imperfect red teaming distribution, penalties for discovered deceptive behavior incentivizes the mesaoptimizer to shift probability mass from those regions into regions of the input space that are not covered by the red teaming; essentially, the model could learn just as well learn to not be caught deceptively mesaoptimizing, rather than not to mesaoptimize. Two possible ways this could swing towards the former are if either a) the mesaoptimizer is able to convergently gradient hack to ensure that between the two equal-training-loss options the training process goes into the one that preserves the mesaoptimizer, or b) mesaobjectives that imply deceptive behavior are easier to learn than those that imply honest behaviors (this one is especially likely to happen if the base objective is weird and complicated, as human values probably are, since all the simpler, easy to learn approximations are misaligned). I think both of these have a pretty good chance of being true, and would result, in effect, in models learning to hide from oversight. \\nSo, we can’t possibly cover the entire space of possible inputs that could be encountered in deployment, and if the mesaoptimizer retreats into one of the states we didn’t think of then we’re done for, and it has a pretty big incentive to do so. This means that black box approaches, where we try various inputs while assuming no knowledge about the model itself, are kind of hopeless. \\nSo actually although we care about the model’s behavior in situations we might encounter in the future, we can’t specify that yet in our training loss. So, if we optimize for this loss function, if it turns out that deception is favored by the prior defined by our learning process (which seems plausible), then even if we reach an optimum of this training loss our thing still might be deceptive outside of the training distribution. The other way things could go wrong is if our optimizer is not good enough. Then, we might just settle with a suboptimal deceptive model because our optimizer is unable to find the global min. This connects to the frame of inner alignment as a problem of imperfect optimization. In practice we get a combination of both of these problems at once: we can’t find the optimum of the training loss defined by our training distribution, which would allow for deception, and even if we could it might still be deceptive.\\n## Unforeseen consequences framework of deception\\n*(Update: I no longer think of the failure introduced in this section as purely an inner alignment failure, but rather as a more general problem with training consequentialist systems.)*\\nHowever, I think there’s a completely different frame from the whole out of distribution /\\u200b \"it only becomes evil in deployment\" frame that I’ve been thinking a lot about. So one thing we might think is that maybe we can just do whatever oversight we did during training but during deployment as well, and it might have some competitiveness problems, but it seems like it would at least be a good starting point. Unfortunately, I think there are some subtle problems with this that totally break it and analyzing those problems brings us to the other framing of deception. I think these problems show up in the previous frame too.\\nSo let’s say the model proposes some action, and we want to know whether the action would be safe to implement. Then, assuming we have some world model, we can simulate the model’s action out, and see whether something bad happens (I’m assuming for now that we know something is bad when we see it, because we’re focusing on inner alignment. This is definitely not trivial or remotely solved and is a big part of outer alignment.) This is also roughly what we’d do for the training procedure in the previous frame. The problem is that this world model is completely impossible. Aside from the fact that it’s smaller than the world and therefore can’t fit the world, it’s also susceptible to RSA2048-like problems, where there are certain states of the world where we know we can be in, but can’t actually produce without enormous cost. Another example would be simulating a future where more powerful computers exist; we can’t do that on current computers obviously. And of course, RSA2048 is again just a particularly sharp example of the class of things that could happen but that we can’t think of. In practice, there are many other distributional shifts, but RSA2048 is essentially the worst possible case of distributional shift, and I expect the solution to transfer pretty well.\\nThis means that we can’t consider plans in which RSA2048 suddenly appears at some intermediate point. Note that this actually does still allow us to catch cases where the model merely does something bad the moment it sees RSA2048, because after we see RSA2048 in the real world during deployment, then we can actually just use that and plan through the consequences, and we’ll catch the treacherous turn there. So our failure case has to be subtler than that: the failures happen when there’s some action the agent can take that would make it *such that our deploy time world model simulation thing breaks*. Some examples:\\n\\n - The model self modifies to remove the world model simulator. This looks like a really good action, because removing this safeguard makes the model a lot more efficient, and because we can’t simulate worlds where RSA2048 happens, we don’t see it explode.\\n\\n - The model improves itself without removing the simulator but also in the process introduces some exploitable bugs (either intentionally or unintentionally).\\n\\n - If we prevent it from self modifying: The model creates a copy of itself that doesn’t have the safeguard. \\n\\n - If we also try to somehow prevent it from making new agents, there are a whole bunch of ways to goodhart whatever definition of agent we pick that could still put the world into a state where RSA2048 is bad\\nIn general I don’t think we can make the model not take actions which would make it such that seeing RSA2048 would then cause bad things, though I admit to not having thought too much about it so I could be wrong. \\nThe more general problem is that due to our world model being inaccurate, we can’t predict the consequences of the model’s actions accurately, and the model can exploit this to do things that are bad in ways we can’t think of. One corollary is the problem of always rejecting actions which do something bad that you can’t even understand—I also talked about this subproblem here. If you can do that, then you can reject everything that could potentially cause the world to enter into a state without the safeguards in ways you can’t understand, and of the remaining ones you should be able to understand them.\\nThis problem actually applies to on-training-distribution things too. In the OOD frame, we kind of assume that on the training distribution we can simply tell on the training distribution whether it is indeed what we want, but in fact we can’t because to know whether we actually want it we would need to know the consequences of the action. In that sense, this frame is kind of orthogonal to the OOD one: OOD-only stuff is one problem, and the inability to see consequences is another orthogonal problem, but I think the latter is somewhat more fundamental because if we solve it then we can get (uncompetitive) OOD safety.\\nThis also kind of ties into ELK: if we can solve ELK, then we can ask the model whether it thinks the action will lead to the safeguards being removed. The main problem here is that an action could still lead to the safeguards being removed even if the model doesn’t think so. An interesting avenue here would be how often this would happen—I don’t have much of a prior on even what order of magnitude problem this is. ELK might also simply not be solvable too, which makes this much more of a headache.\\nFuture Directions: what do we do about actions that look good but are actually evil in ways that we can’t detect/\\u200bcomprehend; does ELK prevent safeguard removal in practice?\\nUPDATE: I made a followup post that dives into a bit more detail into the imperfect world modelling problem.\\n',\n",
              "  'title': '[ASoT] Some thoughts about deceptive mesaoptimization\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/oijJc8Mu2jPNgpuvy/asot-some-thoughts-about-deceptive-mesaoptimization',\n",
              "  'votes': '8'},\n",
              " {'authors': 'TurnTrout',\n",
              "  'comments': [{'authors': 'Space L Clottey',\n",
              "    'comments': [{'authors': 'Space L Clottey',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-02T09:30',\n",
              "      'id': 'axWHpFKjemHP8WaSk',\n",
              "      'omega_karma': '',\n",
              "      'score': '10',\n",
              "      'text': 'Actually, I want to walk back on this a bit. I was on a plane since this comment and the ten hours of no wifi was really nice and really unique and really focused, and I had absolutely no reason to check my phone because there was absolutely zero chance of their being a notification… I realised that I appreciated digital minimalism at the time because I had just come out of having no wifi forced apon me for a week and finding it really nice and really wanting to maintain it. I think I’ve just forgotten how nice it actually is\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=axWHpFKjemHP8WaSk',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'Tom Lieberum',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-31T09:27',\n",
              "      'id': 'CNuQEK84kCC793Fmr',\n",
              "      'omega_karma': '',\n",
              "      'score': '6',\n",
              "      'text': 'I want to second your first point. Texting frequently with significant others lets me feel be part of their life and vice versa which a weekly call does not accomplish, partly because it is weekly and partly because I am pretty averse to calls. \\nIn one relationship I had, this led to significant misery on my part because my partner was pretty strict on their phone usage, batching messages for the mornings and evenings. For my current primary relationship, I’m convinced that the frequent texting is what kept it alive while being long-distance. \\nTo reconcile the two viewpoints, I think it is still true that superficial relationships via social media likes or retweets are not worth that much if they are all there is to the relationship. But direct text messages are a significant improvement on that. \\nRe your blog post:Maybe that’s me being introverted but there are probably significant differences in whether people feel comfortable/\\u200blike texting or calling. For me, the instantaneousness of calling makes it much more stressful, and I do have a problem with people generalizing either way that one way to interact over distances is superior *in general*. I do cede the point that calling is of course much higher bandwidth, but it also requires more time commitment and coordination. \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CNuQEK84kCC793Fmr',\n",
              "      'votes': '5'},\n",
              "     {'authors': 'TurnTrout',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-03T16:49',\n",
              "      'id': 'ybvZBPx37dCv9k563',\n",
              "      'omega_karma': '',\n",
              "      'score': '4',\n",
              "      'text': 'I don’t remember at this point what digital minimalism advocates, but *I *advocate doing cost-benefit analyses, which are naturally sensitive to the specifics of your situation. The question may become: How can I draw most of the benefits of texting, without checking my phone 40 times a day? \\nAnd I think this question has meaningful answers, from batching responses eg thrice daily, to dedicated synchronous texting periods (like text-based phone calls!).\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=ybvZBPx37dCv9k563',\n",
              "      'votes': '3'}],\n",
              "    'date_published': '2022-03-28T11:13',\n",
              "    'id': 'EfjznyXLDTPyaqTQj',\n",
              "    'omega_karma': '',\n",
              "    'score': '22',\n",
              "    'text': 'I really really enjoyed digital minimalism when I read it, but think it was somewhat harmful to my relationships, given how hard it says that only text-relationships are basically worthless. It took like a year but I happened to meet someone really cool who strongly didn’t like calling and since the only way I could talk to them was texting, I sucked it up and actually found out that it’s not so bad.\\nI think it did help me firm up the things I dislike about texting, and with some agreed about norms I think they can be mitigated. Wrote about it here: Why call? | Space L Clottey (spacelutt.com)\\nThis post did A LOT for me in terms of my phone usage:\\nDistractions are a Nuisance, but Infinity Pools are the Real Problem | by John Zeratsky | Make Time | Medium\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=EfjznyXLDTPyaqTQj',\n",
              "    'votes': '13'},\n",
              "   {'authors': 'aphyer',\n",
              "    'comments': [{'authors': 'Rana Dexsin',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-30T06:00',\n",
              "      'id': 'gZzovr2FojRr8dnLt',\n",
              "      'omega_karma': '',\n",
              "      'score': '8',\n",
              "      'text': 'That in turn is actually dependent on whether having your ambient thoughts occupied by YouTube is better *overall* than having them occupied by nothing for a while. There’s a lot of valuable background processing that I suspect gets starved by constant stimulation. Of course, carving out explicit time for reflection or for a meditation practice or similar is also something one can do.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=gZzovr2FojRr8dnLt',\n",
              "      'votes': '6'},\n",
              "     {'authors': 'TurnTrout',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-03T16:57',\n",
              "      'id': 'F4axmENXiqpp7sfdN',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Pushback against (what seems to me like) an implicit assumption: In all probability, you are not evenly and strategically trading off \"bored time\" for \"entertained time.\" You are trading off huge chunks of your non-bored time, not because you lack virtue, but because Youtube \"wants\" to waste your time. So this is, I think, a dangerous trade to try to make, at least without analyzing it first.\\n> But if this time trades off against *staring at the ceiling being bored*, then Youtube is making my unproductive relaxation time more enjoyable and entertaining, and there is no problem.\\nIs there no problem? Sometimes being \"bored\" lets me focus on what it feels like to be a person, or feel grateful about my life, or just let my thoughts drift. This is pleasant, just like the quoted memory of staring at the ceiling. The sentiment was not \"FML, my boring life sucks\", but rather \"-------- [relaxation].\"\\nI also used to have thoughts race through my head when I turned in for the night, as if some great dam had broken, now that no distractions were occupying my attention. That *seems* to happen less now. Which, in turn, seems good.\\nAnyways—empirically, I have not spend much time bored. So the point seems moot, in that I am not advocating increased \"bored\" time, but reallocation. \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=F4axmENXiqpp7sfdN',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T17:00',\n",
              "    'id': 't8sdiWQbqfdc6jquG',\n",
              "    'omega_karma': '',\n",
              "    'score': '15',\n",
              "    'text': '> I remember lazy summer childhoods, staring at the ceiling after I ran out of video game time. \\nI think this argument points in the opposite direction from your main post. The most salient question for ‘spend less time messing around on the Internet’ is ‘what will that saved time end up being spent on?’\\nSometimes I watch cute Youtube video compilations of pets doing silly things.  \\nIf this time trades off against writing a novel, or learning an interesting skill, or making friends, or exercising, then Youtube is wasting my time on unproductive things and I should try to waste less time.\\nBut if this time trades off against *staring at the ceiling being bored*, then Youtube is making my unproductive relaxation time more enjoyable and entertaining, and there is no problem.\\n(Relevant xkcd).\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=t8sdiWQbqfdc6jquG',\n",
              "    'votes': '14'},\n",
              "   {'authors': 'DanielFilan',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'DanielFilan',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-05-03T18:35',\n",
              "        'id': 'LdzxNwzpmQwqKgQuX',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'Have PM-ed.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=LdzxNwzpmQwqKgQuX',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-05-03T02:21',\n",
              "      'id': 'CZ7LDxP923HRdaHfw',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': 'Strong-upvoted, even though I disagree on the overall argument strength (I think there were some weak arguments but in total the evidence seemed pretty good to me). I look forward to paying out if you want to collect on that.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CZ7LDxP923HRdaHfw',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-04-25T21:59',\n",
              "    'id': 'f5p9eHcTE5LrmWPQv',\n",
              "    'omega_karma': '',\n",
              "    'score': '13',\n",
              "    'text': 'For what it’s worth, I have met TurnTrout in real life, use social media, and was initially skeptical about the Digital Minimalism thesis. After reading this post, and having had it recommended to me by another friend, I read the first half of Digital Minimalism. I found it basically unconvincing. In particular, it seemed like chapter 1 was supposed to provide motivation for why social media was bad for me, but didn’t really deliver—I didn’t think the evidence given distiguished \"social media is designed to be addictive\" with \"social media is designed to be valuable and usable\". For instance, it seems to interpret social media tools that let you interact with your friends in ways that have significance for your relationship (e.g. tagging them in pictures) as a way to addict people, but it seems to me that that’s just a nice feature. In some places it seemed sort of obtuse—the author talks about how the ostensive benefit of FB is letting you see things like friends’ baby pictures, and claims that the like button increases addictiveness but doesn’t help deliver the ostensive benefit. But it seems obvious to me that seeing which posts are ‘liked’ would help FB distinguish between pictures that people want to see (babies, engagement photos) and pictures that they don’t (poorly-lit food photos, boring party pictures).\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=f5p9eHcTE5LrmWPQv',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'Logan Riggs',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'Logan Riggs',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-04T18:32',\n",
              "        'id': 'BrMDCgkbqLTBrZpLX',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'I’m unsure about this now. I think there may generally be way better ways to cope (eg sleeping, walks, reading a book, hanging with friends). \\nA different thought: Clarifying the core thing you don’t like about having media always on (maybe the compulsion that leads to distractedness) may make your idea easier to communicate and look different in actions/\\u200bplans produced. Like I’m fine with watching a movie with a friend or playing a video game with my roommate for an hour. \\nA slightly different thought: setting alarms on my phone if I’m looking at my phone for the time because I have a meeting, or I’m waiting on someone to message me timely information has been helpful. I can set a timer for an hour and check my phone then in case they’ve messaged. Or set the timer 5 minutes before my meeting, so I don’t have to think about it.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=BrMDCgkbqLTBrZpLX',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T17:18',\n",
              "      'id': 'gvpG4DS6yu75KiXQc',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': '(I think everyone should have well-defined exception handling, because some of you *will *have crazy shit happen, like \"someone died\", and that *can *make it hard if you’re pondering \"do I let myself have an allowance now?\". Failing to plan is planning to fail (in not-wholly-improbable worlds).)\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=gvpG4DS6yu75KiXQc',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-29T02:48',\n",
              "    'id': 'AdAndSGrXv963uEyd',\n",
              "    'omega_karma': '',\n",
              "    'score': '10',\n",
              "    'text': 'Sure, I’ll do it as well. For me: \\n\\n - 1pm—Check snaps, messages, emails, discord team messages and accelerating alignment channel, & EAGx messages. Hard limit at 1:30pm (just set two alarms on my phone)\\n\\n - Whitelist—Roam/\\u200b research related searches. Phone calls/\\u200b texts are unblocked from a certain set of people, who I’ve told can reach me there. (I set them in the emergency contact list), but besides that, my iPhone is in \"focus mode\" with all notifications hidden. \\n\\n - Exception handling: I don’t think I’ll need one, but I can let my roommate know and ask for his social support. (Specifically call me out if he sees me on my phone at other times, haha)\\n\\n - I normally journal, so that’ll help with logging. \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=AdAndSGrXv963uEyd',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Heron',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-31T19:19',\n",
              "    'id': 'F3Ho4ukj2nEmxwnDB',\n",
              "    'omega_karma': '',\n",
              "    'score': '9',\n",
              "    'text': 'Thanks for reminding me of my small concern: time-wasting, specifically doom-scrolling on Twitter. I will listen to the book!\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=F3Ho4ukj2nEmxwnDB',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'niplav',\n",
              "    'comments': [{'authors': 'Ben Pace',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T19:48',\n",
              "      'id': '7giz4ArjW7X23PqQ7',\n",
              "      'omega_karma': '',\n",
              "      'score': '5',\n",
              "      'text': '> I have an additional pet peeve about this post: It has the words \"cost-benefit analysis\" in the title, but doesn’t have a cost-benefit analysis in the body (at least not of the juicy expected-value variety)!\\nOh yeah, I feel like a more natural title would be \"PLEASE DO SOME ACTUAL EMPIRICISM\".\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=7giz4ArjW7X23PqQ7',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'niplav',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-06T13:20',\n",
              "        'id': 'SxJqf8mzZPAworJY2',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': '> I have noticed increased anxiety in myself. I think it quite possible I already had most of it before the declutter, and instead wrapped myself in comforting mind-numbing internet usage which obscured it from me. Another person who has done the declutter, reported similar suspicions about themselves.\\n\\n\\nA psyche might start\\ncutting itself, if it is\\nnot dulled each fortnight',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=SxJqf8mzZPAworJY2',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T17:09',\n",
              "      'id': 'SgBPffRmTxKN4cd6j',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': '> I also have experienced increased anxiety, which has persisted (and become slightly stronger) 7.5 months after moving.\\nI have noticed increased anxiety in myself. I think it quite possible I already had most of it before the declutter, and instead wrapped myself in comforting mind-numbing internet usage which obscured it from me. Another person who has done the declutter, reported similar suspicions about themselves.\\n> This has some interesting implications: The worse the problem of wasting time on the internet is for you, the harsher your measures will need to be, and the less you will want to carry them out (except in lucid moments).\\nThis doesn’t ring to my experience. Everything became easier when I said \"*No *reddit\", as opposed to ~\"Reddit if I can find a good enough reason.\" \\n> I have an additional pet peeve about this post: It has the words \"cost-benefit analysis\" in the title, but doesn’t have a cost-benefit analysis in the body (at least not of the juicy expected-value variety)!\\nPlease don’t use those words if you’re not going to deliver ;-)\\nI included eg the Facebook usage meme (which is the real output of a CB analysis), and described the results of other analyses I did. I think the analyses were so lopsided, and the solutions so clean, that assigning numbers would be a distraction. Also, the point of assigning numbers to personal-utility-estimates is, I think, to throw them out after you do the estimate, and do what your updated gut feeling says.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=SgBPffRmTxKN4cd6j',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-29T08:45',\n",
              "    'id': 'dyHjRsrF9BaaFFeoY',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': 'So, I haven’t read Digital Minimalism, but I have been becoming increasingly worried about attention-grabbing systems over the last ~2 years, culminating in me choosing not to have internet at my apartment when I moved last May (getting internet at a local library, with a ~15 minute walk there by foot), after having iterated through many versions of locks & blocks & deleted elements, all pretty much fruitless in the end.\\n\\nSo, yeah, I think already pretty good about my internet usage.\\n\\nThis has resulted in interesting dynamics: I often procrastinate by reading through my downloaded copy of wikipedia, or by weightlifting (!), when I don’t want to do work. I am also much more vulnerable to overindulging when I’m at a place with internet, e.g. when I’m visiting my parents.\\n\\nI have some predictions about your experiment:\\n\\n\\n - You will continue in your current decluttered mode (70%)\\n\\n - You will temporarily fall back into bad habits (50%)\\n\\n - You will make it stricter after some while (60%)\\n\\n\\n\\n - Your initial productivity benefits will experience a regression toward the mean (80%)\\n\\n - The (perceived) benefits will continue outweighting the (perceived) costs (90%)\\n\\n\\n\\n - You will find yourself procrastinating in odd and novel ways, such as reading a lot of fiction, or exercising, or snacking a lot, or reading Wikipedia a lot (40%)\\n\\nI also have experienced increased anxiety, which has persisted (and become slightly stronger) 7.5 months after moving.\\n\\nI don’t necessarily recommend such extreme measures to everyone, but I have the lurking suspicion that people tend to underreact to time & attention lost.\\n\\nI’m unhappy that picoeconomics hasn’t been further investigated on LessWrong, because, aside from the term being very cute, trying to balance the costs of accessing different resources that may be harmful in too large or small quantities seems pretty central to the endeavour of managing (if not defeating) akrasia.\\n\\nA hypothesis could be that while human System 2 does exponential discounting, System 1 performs hyperbolic discounting, and we’d like to increase the cost of accessing e.g. internet services so that for that cost, our hyperbolically discounted value is smaller than the exponentially discounted value (ideas like this being central to picoecon).\\n\\nUnder this model, for myself, the time to remove ublock from my browser addons (or simply install another browser, etc.), which would take around half a minute, the hyperbolically discounted present value was not less than the exponentially discounted value, but the 15 minutes of going to the nearest library (or buying a router and installing it, or paying an additional 10€ for more mobile data (so here, expensive mobile data plans are *better*) *would be*, so I don’t do it.\\n\\nThis has some interesting implications: The worse the problem of wasting time on the internet is for you, the harsher your measures will need to be, and the less you will want to carry them out (except in lucid moments).\\n\\nI have an additional pet peeve about this post: It has the words \"cost-benefit analysis\" in the title, but doesn’t have a cost-benefit analysis in the body (at least not of the juicy expected-value variety)!\\n\\nPlease don’t use those words if you’re not going to deliver ;-)\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=dyHjRsrF9BaaFFeoY',\n",
              "    'votes': '5'},\n",
              "   {'authors': 'noggin-scratcher',\n",
              "    'comments': [{'authors': 'Yitz',\n",
              "      'comments': [{'authors': 'Elizabeth',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-29T01:46',\n",
              "        'id': 'P5AyoJKCBDd2CzqPB',\n",
              "        'omega_karma': '',\n",
              "        'score': '11',\n",
              "        'text': 'I checked out a bunch and chose inoreader, although I needed to pay to get all the features I wanted.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=P5AyoJKCBDd2CzqPB',\n",
              "        'votes': '5'},\n",
              "       {'authors': 'noggin-scratcher',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-29T23:40',\n",
              "        'id': '4D8pGA5icQgDEcKMn',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'I’m using Inoreader, paying for the \"Pro\" tier of features.\\n\\nI’m getting particular use out of their duplicate filters, regex-based content filters, receiving newsletters as a feed, and automated scraping/\\u200bmonitoring of sites that don’t publish their own feed.\\n\\nHave also used the custom CSS option to productively disagree with some of the choices made when they re-designed the interface. But I think that’s available on the cheaper \"Supporter\" tier too.\\n\\nThere has in the past been a \"buy 18 months for the price of 12\" discount available at least annually (around Black Friday possibly; might have been New Years). Which I’ve used to keep the cost down.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=4D8pGA5icQgDEcKMn',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-03-29T01:44',\n",
              "      'id': 'AwTC5qWZG9CNAwd3n',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'May I ask what software you use for your RSS aggregator?\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=AwTC5qWZG9CNAwd3n',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T10:51',\n",
              "    'id': 'bGxGzJ5KyqhJ7iHTP',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': 'My personal antidote to the \"check lesswrong. check mad investor chaos. work 5 mins. check mad investor chaos. check lesswrong\" problem has been to channel everything I possibly can into an RSS aggregator. No need for *me* to be twitchily refreshing and checking; I have a computer to do that for me.\\nAlso helps, I think, that I’m then removed from the algorithmically-mediated Skinner box of someone else deciding what my news feed is. I just get a simple chronological list of headlines from sites I’ve chosen—nothing that’s being shared or promoted or trending or whatever, and with my own defined rules/\\u200bfilters to remove categories of post I’m not interested in seeing. Also no fear of missing out, because my unread items will still be there later whenever I come back for them.\\nStill occasionally has the problem of turning into an attention-suck by way of being subscribed to too many things, or to sites that produce too many updates. Still need to be alert to whether individual sites are a true benefit to be subscribed to. Still need to keep a lid on feed-reading from consuming all of my time. \\nSo it’s not a solution to \"I read *too much* internet\", but I think it’s at least an improvement over other *ways* of reading the internet.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=bGxGzJ5KyqhJ7iHTP',\n",
              "    'votes': '6'},\n",
              "   {'authors': 'TekhneMakre',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'TekhneMakre',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-04T02:55',\n",
              "        'id': 'kRepe7Mk45Bh9qyPn',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': '\"participation in networks\"? IDK. Is \"social media\" too narrow? I intuitively include LW, blogs, forums, email, as social media. Youtube is a mix; I consider it social media when I’m using it as pica for talking to a person, and I endorse most of my other Youtube use (e.g. videos of natural phenomena, or documentaries, or clever inventions). But yeah I could imagine being seriously attention-sniped in some other unendorsed way.\\n\"attention service usage\"? \"consumption service usage\"? That’s not really clear, though it does have a precise meaning that I think is what you’re trying to point at: services (i.e. computer programs running somewhere else that do some computing task for you) which are attention /\\u200b consumption based (i.e. the thing you’re getting from the service is something you’re going to just directly experience, as opposed to running it through some more computation). Services which are attention-based seem like the central type of technology that induces attention-sniping incentives. (Though it’s not sufficient, e.g. Wikipedia.)\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=kRepe7Mk45Bh9qyPn',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T16:58',\n",
              "      'id': 'w7MYRmHT74vj462k4',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Originally titled \"Do a cost-benefit analysis of your internet usage\", but this makes it sounds like analyzing different internet service provider plans. \"Social media usage\" is too narrow. I’m open to suggestions.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=w7MYRmHT74vj462k4',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T10:32',\n",
              "    'id': 'M7ahy9G4PcT9gwEQG',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': 'Acknowledging that this is how people generally use the word \"technology\", I’d rather reserve that word for things that are involved in tekhne, i.e. tools, machines, devices, programs, components, factories, methods, etc.; things one uses to produce. I think you’re centrally talking about networks and services. Richard M Stallman calls them \"disservices\", as in \"Facebook provides an online social networking disservice\". That it’s even possible to seemingly unwillingly more or less ruin oneself using a thing, is evidence that one isn’t centrally relating to the thing as a technology at all.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=M7ahy9G4PcT9gwEQG',\n",
              "    'votes': '6'},\n",
              "   {'authors': 'Ben Pace',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T19:18',\n",
              "    'id': 'PSgCiQSiKEL9HqpS5',\n",
              "    'omega_karma': '',\n",
              "    'score': '7',\n",
              "    'text': '> When was the last time you were bored and in silence?\\nFor the record, it was 2 days ago.\\n> like blocking all recommendations on YouTube via the Unhook add-on [Chrome, Firefox]\\nWoah — you just gave me agency over YouTube! Thanks so much, this is looking like it will really change my relationship with the site to be much more intentional (e.g. I like how it makes it so I can default to only seeing my subscriptions).\\n> Here’s my main tip to add to the book: *Have well-defined exception handling which you never ever ever have to deviate from… *My procedure was \"If I need to use a forbidden functionality, then I have to write what I did down on a slip of paper and leave it on my girlfriend’s desk ASAP.\"\\nWhen I did 2 weeks of no devices, my procedure (which I remember telling you in a LW PM like 6 months ago) was \"you can do a thing on your device if you wrote it down on a piece of paper yesterday\". That worked well for me while I was in more of a vacation mode.\\n> I write blogposts before then, and I won’t check their reception until the next week (I used to nervously refresh).\\nVery cool to hear you that you do this! Congratulations. For me I don’t check until 24 hours have passed, and never do refreshes. I do like responding to comments faster than 1 week. But yeah, the repeated refresh while your post has no karma and one unhelpful comment is not worth it.\\n> For news, I purchased a digital+print subscription to *The Economist*. Once a month, I can choose to read the four issues for an hour or two.\\nThe one I’ve been meaning to move to is, once a month, check the top-voted stories on HN that month.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=PSgCiQSiKEL9HqpS5',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'Jack R',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'Jack R',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-04T06:52',\n",
              "        'id': 'CJZqhoPKuyLMHvkdM',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': 'Ah — sorry if I missed that in the post, only skimmed\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CJZqhoPKuyLMHvkdM',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T17:15',\n",
              "      'id': 'pBhAAsHvFinuShc8P',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Yup, this is what I did, but I just didn’t have the notebook. I like the bright line.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=pBhAAsHvFinuShc8P',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-29T08:39',\n",
              "    'id': 'PrFBSgKyaK68w6bot',\n",
              "    'omega_karma': '',\n",
              "    'score': '7',\n",
              "    'text': 'Random tip: If you want to restrict apps etc on your iPhone but not know the Screen Time pin, I recommend the following simple system which allows you to not know the password but unlock restrictions easily when needed:\\n\\n - Ask a friend to write a 4 digit pin in a small note book (which is dedicated only for this pin)\\n\\n - Ask them to punch in the pin to your phone when setting the Screen Time password\\n\\n - Keep the notebook in your backpack and never look inside of it, ever\\n\\n - If you ever need your phone unlocked, you can walk up to someone, even a stranger, show them the notebook and ask them to punch in the pin to your phone\\nThe system works because having a dedicated physical object that you commit to never look inside is surprisingly doable, for some reason.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=PrFBSgKyaK68w6bot',\n",
              "    'votes': '5'},\n",
              "   {'authors': 'Trevor1',\n",
              "    'comments': [{'authors': 'hath',\n",
              "      'comments': [{'authors': 'matto',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-29T12:59',\n",
              "        'id': 'YckCweuMjegiSgNrb',\n",
              "        'omega_karma': '',\n",
              "        'score': '3',\n",
              "        'text': 'Postman is a great writer and this is one my favorite books.\\nWhat’s changed between 1985 and today is that human attention has become the scarcest (ie. most valuable) resource. Because of this, the Web is under immense market pressure to turn into a perfected form of cable TV as described by Postman. This is what’s driving platform centralization (ie. Facebook, TikTok, etc.) as well as the one-to-many model where a handful of users (influencers) produce while a great majority merely consume.\\nWe’re not there yet, but we’ve swung strongly in that direction in just a decade with change. My hope is that counter-forces like *Digital Minimalism* as well as the inherent flexibility of the medium of the Web will arrest or even revert this change.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=YckCweuMjegiSgNrb',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-03-29T02:06',\n",
              "      'id': 'ajcqEaE6AJzC6Lsim',\n",
              "      'omega_karma': '',\n",
              "      'score': '9',\n",
              "      'text': 'A book I highly enjoyed on the topic was Neil Postman’s Amusing Ourselves to Death, which was Neil Postman mourning the death of rational discourse from TV in the year 1985. Very highly reccomend.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=ajcqEaE6AJzC6Lsim',\n",
              "      'votes': '4'},\n",
              "     {'authors': 'Logan Riggs',\n",
              "      'comments': [{'authors': 'TurnTrout',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-03T17:14',\n",
              "        'id': 'eGhxZAuXY7SonWiGx',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': ':)\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=eGhxZAuXY7SonWiGx',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-03-29T02:06',\n",
              "      'id': 'DGzNYC4i8xCBdc5MJ',\n",
              "      'omega_karma': '',\n",
              "      'score': '6',\n",
              "      'text': 'I think reading the book and/\\u200bor trying it yourself would be very informative. You have at least until next Sunday when he reads this comment or potentially writes more.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=DGzNYC4i8xCBdc5MJ',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'mingyuan',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T18:50',\n",
              "      'id': 'HZ6zvLCS98k7yL97B',\n",
              "      'omega_karma': '',\n",
              "      'score': '4',\n",
              "      'text': 'You should message Kurt, who’s mentioned in the post as TurnTrout’s inspiration for doing this in the first place. Sounds like TurnTrout isn’t going to be online/\\u200bmessaging much in the near future :)\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=HZ6zvLCS98k7yL97B',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-28T14:02',\n",
              "    'id': '4JEFwRkmZQhxgdB4o',\n",
              "    'omega_karma': '',\n",
              "    'score': '5',\n",
              "    'text': 'Please, please, please make more posts on this issue. I really like what I see here, I’ve found it very helpful, and I need to see more. \\nPlease message me on your thoughts if you ever have anything you’d like to share about this problem, e.g. what works, what doesn’t work, what seems to happen to people, etc.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=4JEFwRkmZQhxgdB4o',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'JonathanMoregard',\n",
              "    'comments': [{'authors': 'Valentine',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-31T15:29',\n",
              "      'id': 'rxFarMyfWdRuZdJwJ',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'That’s native to Facebook now, actually. I don’t remember where, but if you dig around in the settings you can turn off notifications for reactions/\\u200blikes.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=rxFarMyfWdRuZdJwJ',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T11:10',\n",
              "    'id': 'owrLHZ5moA3KN5KCM',\n",
              "    'omega_karma': '',\n",
              "    'score': '5',\n",
              "    'text': 'Does anyone know about an addon to filter facebook notifications? I want to know about comments, but not reactions/\\u200blikes\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=owrLHZ5moA3KN5KCM',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'TurnTrout',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-04-03T17:21',\n",
              "    'id': '7qub738wxkxHB3wZG',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'Update: I had a few relatively anxious days, and decided to relax my music policy slightly. Sometimes I’d be a little too anxious to do work without music. While I fix this problem, I’m going to listen to music more permissively.\\nI think there’s another trade-off to music while working, which is that it makes me more *excited *at the cost of making me *slightly dumber*. Sometimes this is worth it. Marking as something to analyze more later, as I currently (attempt to) refactor my internal systems so that they don’t produce these anxious signals.\\nAlso, added to main post: \"I *never ever use my phone on the toilet. Ever.* This has served me well and seems like a pure win.\"\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=7qub738wxkxHB3wZG',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'ike',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'ike',\n",
              "        'comments': [{'authors': 'TurnTrout',\n",
              "          'comments': [],\n",
              "          'date_published': '2022-04-17T17:27',\n",
              "          'id': 'XTRptRgA7RychPeKi',\n",
              "          'omega_karma': '',\n",
              "          'score': '2',\n",
              "          'text': 'Yay! Keep up the good work :) I bet there’s a way to stick to it better, I’d advise you to keep trying things on that front.\\n',\n",
              "          'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=XTRptRgA7RychPeKi',\n",
              "          'votes': '1'}],\n",
              "        'date_published': '2022-04-10T21:03',\n",
              "        'id': 'tJYzFTgjRSKHFTTn2',\n",
              "        'omega_karma': '',\n",
              "        'score': '10',\n",
              "        'text': 'It’s been hard keeping to it, but I do notice myself being more productive when I do. One thing that has stayed is not having an email tab always open. Hoping that over time I get better at following it strictly; it has such immediate positive effects that I’m not so worried I’ll gradually forget and stop, like happened with other productivity attempts (e.g. making to-do lists.)\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=tJYzFTgjRSKHFTTn2',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-04-03T17:18',\n",
              "      'id': '9JRpANRBaDNMaqhgp',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Interested to hear how this goes.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=9JRpANRBaDNMaqhgp',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-30T16:35',\n",
              "    'id': 'XnijshvYhpNcfHvcv',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'I really liked this post. As a result of reading it, I’m trialling the following:\\n\\nEvery time I go on my computer or phone, I need to specifically have a plan for one specific thing I am going to do. This can be \"check all notifications from X/\\u200bY/\\u200bZ), or \"write this one long email\", or even, \"15 minutes of unstructured time\", but it should always be intentional. If I get the urge to do something else, I need to save it for a future session, which can be immediately afterwards.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=XnijshvYhpNcfHvcv',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'supposedlyfun',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T03:21',\n",
              "    'id': 'CbvugZqy7GLgD5ujX',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'If you can get work done while having Wikipedia not-blocked, you are a better worker than I am. I will absolutely read about irrelevant, flagrantly not-even-wrong Medieval scholastic philosophers instead of doing chores.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CbvugZqy7GLgD5ujX',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'aarongertler',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-05-17T10:18',\n",
              "    'id': 'Ch9nc8ZqDAFnqJq4X',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'This post led me to remove Chrome from my phone, which gave me back a few productive minutes today. Hoping to keep it up and compound those minutes into a couple of solid workdays over the rest of the year. Thanks for the inspiration!\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=Ch9nc8ZqDAFnqJq4X',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Josephm',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-30T19:08',\n",
              "    'id': '6jnDBmBetZiEbLxrD',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': '> I even thought about some identity-politics tweet I saw last week, on my run this morning… why is that garbage in my head? Good riddance.\\nI noticed this when I did a similar ban on technology usage. It’s bizarre how I could still have some YouTube video frequently pop into my thoughts, weeks after I stopped watching YouTube entirely.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=6jnDBmBetZiEbLxrD',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'james.lucassen',\n",
              "    'comments': [{'authors': 'GeneSmith',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T04:45',\n",
              "      'id': '9HTmw9jsmvCdeLP2k',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': 'This post is at least one more data point that Cal Newport’s method worked for someone else.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=9HTmw9jsmvCdeLP2k',\n",
              "      'votes': '2'},\n",
              "     {'authors': 'mingyuan',\n",
              "      'comments': [{'authors': 'james.lucassen',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-30T15:15',\n",
              "        'id': 'GWyuxButNCFwhfj9i',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': 'this is great,thanks!\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=GWyuxButNCFwhfj9i',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-03-29T18:47',\n",
              "      'id': 'puiqvyu2uGEJ2tFv9',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Kurt Brown (mentioned in the post) did an experiment on this, helping residents of CEEALAR (formerly the EA Hotel) do their own Newport-style digital declutter; you can read his preliminary writeup here.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=puiqvyu2uGEJ2tFv9',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T05:23',\n",
              "    'id': 'F4AQaDriJdAkEhEjP',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'What do you think about the effectiveness of the particular method of digital decluttering recommended by Digital Minimalism? What modifications would you recommend? Ideal duration?\\nOne reason I have yet to do a month-long declutter is because I remember thinking something like \"this process sounds like something Cal Newport just kinda made up and didn’t particularly test, my own methods that I think of for me will probably better than Cal’s method he thought of for him\".\\nSo far my own methods have not worked.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=F4AQaDriJdAkEhEjP',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Vika',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-04-05T15:42',\n",
              "    'id': 'd7czHLaBK6SHAKcSM',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'Thanks Alex for the helpful recommendation! I got the book and read the first half. I’d like to do a declutter at some point, still figuring out how to handle non-optional technologies (e.g. work slack tends to be a major distraction for me, which is probably best coordinated with my team as a whole). \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=d7czHLaBK6SHAKcSM',\n",
              "    'votes': '1'},\n",
              "   {'authors': 'SeishinSennin',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-17T17:26',\n",
              "      'id': 'tnBpXMbJ5Fyx9r6dz',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'I just wouldn’t use most apps or websites. By adopting a bright-line whitelist approach with clear, universally applicable exception handling and scheduled eg email checks, I didn’t have constant temptations to rationalize breaking my own rules, like I did when I was *sometimes *allowed to use a service.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=tnBpXMbJ5Fyx9r6dz',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-04-13T00:05',\n",
              "    'id': 'kpgbabkn7fgPHCv4H',\n",
              "    'omega_karma': '',\n",
              "    'score': '1',\n",
              "    'text': 'What apps are you (and commenters) using to enforce declutter/\\u200breduce the System 1 instant refresh urges? I’m looking for phone and computer blockers/\\u200bfilters and other suggestions.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=kpgbabkn7fgPHCv4H',\n",
              "    'votes': '1'}],\n",
              "  'date_published': '2022-03-27T23:09',\n",
              "  'id': 'fri4HdDkwhayCYFaE',\n",
              "  'omega_karma': '',\n",
              "  'score': '172',\n",
              "  'source': 'lesswrong',\n",
              "  'tags': 'Social Media/Practical/Self Improvement/Self-Deception',\n",
              "  'text': 'Contents\\n - Mistake: Motivatedly avoiding thinking about the issue\\n - Digital Minimalism\\n - Time costs\\n - Attentional costs\\n - Implementing the declutter\\n - My declutter rules\\n - Benefits of the declutter\\n - Recommendations\\n - Appendix 1: Declutter advice\\n - Appendix 2: My post-declutter rules\\nIf an unaligned entity invests billions of dollars into an application which you use, where they benefit from wasting your time, and you haven’t at least done a cost-benefit analysis so that your usage minimizes your costs and maximizes your benefits—*You are probably getting fucked over*.\\n# Mistake: Motivatedly avoiding thinking about the issue\\nLast summer, my friend Kurt Brown told me about *Digital Minimalism**.* The modern world is mired in attention-sucking apps which compete to waste as much of your time as possible. The book’s remedy: stepping back from non-essential internet usage, so that you can evaluate what really matters to you. After a month has come and gone, you add back in those digital activities which are worth it to you.\\nUnfortunately, this is the part of the story where we all cringe at my past behavior. I gave Kurt some excuses, demurring from his implicit recommendation that I read the book. I asked more questions, but so that I could learn more about what he’d been up to. I wasn’t going to actually do it. I think it sounded monastic and uncomfortable and *I’m not one of those people who needs it, I already have lots of locks on my devices*.\\nAnd locks I had. I restricted my iPhone with a password only known by a friend, so that I was unable to access *eg* Reddit without wiping my device, or asking my friend for the code. My phone was in black and white to minimize how appealing it would be, I had an outdated model to make using my phone less enjoyable. I didn’t have notifications for anything but phone calls. I *still wasted several hours a day on my phone, although I was always (motivatedly) surprised by this.* I thought I was spending at least 70% of my phone-time productively, by reading LessWrong and Wikipedia, or engaging in work communication. In this scenario, I didn’t want to upend my life for a month in order to save less than an hour a day (even though it still would have been worth it in the long run).\\nThis school year, I’ve had problems focusing and relaxing. I tried exercise, different medication, but nothing hit the spot. I wasn’t reading textbooks like I wanted to, my attention was fractured, I often felt behind my schedule. I was still doing my job and making progress—just not as much as I wanted.\\nCould this have anything to do with my attention problems?This spring, I read a LessWrong post which mentioned *Digital Minimalism*. Luckily, this triggered my \"if several reasonably smart EAs swear by the benefits of X, investigate X\" trigger-action plan.\\n# Digital Minimalism\\nI listened to the first half of the book on Audible in one night. As I wrote above:\\n> If an unaligned entity invests billions of dollars into an application which you use, where they benefit from wasting your time, and you haven’t at least done a cost-benefit analysis so that your usage minimizes your costs and maximizes your benefits—*You are probably getting fucked over*.[1]\\nI was immediately convinced that this thesis is correct, and resolved to start my month-long \"digital declutter\" the next day.\\n## Time costs\\nConsider why you originally bought a cell phone. It was probably to call people, to text people, to take photos, to get GPS navigation. Would you have bought it if you foresaw how you would feel an urge to check it even during a dinner with a friend you hadn’t seen in a long time? Would you have bought it if you knew you would take impatiently take it out of your pocket dozens of times a day, staring at it 2+ hours daily?\\nThe point isn’t \"phone bad, never use phone, quit now.\" My phone provides me with enormous benefits. The point is *where was the cost-benefit analysis, what tf has happened to us?!*\\nNotice the middle stat: **one third of daily waking hours**. I am disgusted that some people try to make this number go up further. From AppAnnie.Readers of this forum are probably better about their usage. Let’s be (too) generous and cut that to a mere two hours wasted daily on your phone, and 0 hours wasted on your other devices. That’s only *one eighth of your waking year,* or 1.5 waking months each year.\\n## Attentional costs\\nBut lost time doesn’t capture everything sucked away by your apps, by your email tics, by YouTube, by Reddit, by Slack, by Discord, by everything else which is after you. *Digital Minimalism* asked:\\n> When was the last time you were bored and in silence?\\nI remember lazy summer childhoods, staring at the ceiling after I ran out of video game time. At my 2018 CFAR workshop, my phone dipped in a stream for several minutes and short-circuited. I was actually glad. I felt free. How strange, to feel *free* from a device I purchased! Perhaps I should have noticed the warning sign.\\nSince then, engagement has been a pocket-grasp away. I’d leave my phone in another room to work, only to find my way back half an hour later. Even now, I look down at my phone on my desk, and I feel it. I feel it calling to me from far away, whispering to me, urging me to check Slack or my email—just one more time.\\nThese compulsions kill deep work in the cradle. My attention was fractured and strewn. I would anxiously procrastinate by flitting through tabs: *Discord. Slack. LessWrong. Gmail.* Even when I cleared time to think, I would periodically check my phone.\\n## Implementing the declutter\\nAt this point, you might be thinking \"OK, but I can’t roam the mountains of Nepal for a month. I have work to do and that requires staying in touch with people.\" Sure. The point of this post is not \"no phone.\" The point of this post is to build a digital life purposefully and carefully, because you reflectively endorse each component. The point of this post is to get people to do *any cost-benefit analysis at all* of the way they spend 1/\\u200b8th–1/\\u200b3rd of their waking hours.\\nMy estimate of the daily costs and benefits for a better-than-average Facebook user (considering Messenger to be distinct from Facebook). In appendix 2, I detail how I extract all of these benefits for 40 minutes a month, instead of 40 minutes a day—a 30x improvement!The declutter goes as follows:\\n\\n - Identify the minimal set of digital affordances required to do your job and the other necessities of life (e.g. paying bills).\\n\\n - Cut out everything else for one month.\\nThe point is that these apps which are out to get you—they’re very good at what they do. It’s not enough to turn off notifications and enable app timers. *Digital Minimalism* argues (and I mostly agree) that you have to *get out of the pond entirely* and catch a breather. After the declutter, you can soberly analyze the costs and benefits of each digital activity you add back in.\\n### My declutter rules\\nI went by a whitelist[2] in order to ensure there wasn’t a way to weasel around the rules. Here’s what I let myself do:\\n\\n - Phone\\n - Voice & video calls\\n\\n - GPS\\n\\n - Audible\\n\\n - Uber/\\u200bLyft\\n\\n - Authenticators/\\u200balarms/\\u200bother boring utilities\\n\\n - Roam/\\u200bnote-taking\\n\\n\\n - iPad\\n - Note-taking\\n\\n - Reading\\n\\n - Drawing\\n\\n\\n - Computer\\n - Anything offline (except music or video games)\\n\\n - Textbooks and Wikipedia and arxiv/\\u200bgoogle scholar\\n\\n - Overleaf for writing papers\\n\\n - Amazon and Upwork (for managing contracted-out labor)\\n\\n - Zoom for weekly meetings\\n\\n - Anki and Roam\\n\\n - Check email at noon on Mondays and Thursdays\\n - I told people to call me if it was important. I didn’t get any calls.\\n\\n - I later let myself send emails without looking at my inbox. I recommend Inbox When Ready, which hides your inbox by default and prevents you from being attention-sniped.\\n\\n\\n - Groceries /\\u200b other mundane things\\n - No Wealthfront—no reason for me to see how my portfolio is doing.\\n\\n\\nThat’s it. No music (see appendix), no messaging, no Facebook, no Twitter, no Slack, no Discord, no anxious email checking, no Youtube, no nothing. I even bought a cheap watch so that I wouldn’t have to check my phone for the time. If I needed an exception, I’d first write a note explaining what I did, to be read by my girlfriend, Emma, who started her declutter soon after.\\nWhy did I choose these rules? I won’t get unhealthily sucked into any of these activities. They all make me stronger. They let me do my work.\\nThe world was not going to end because I stopped reading the news for a month—I understand there’s a war still going on in Ukraine, but that’s about all I know, and I’m not worse off for it. I resolved that if I wanted to build models of that part of the world, I’d do that on purpose. I won’t doomscroll through hyper-optimized interfaces designed to scam me out of my attention and make me anxious. I said to myself, my life is worth more to me than that.\\n**FAQ**\\n> But TurnTrout, my job needs email /\\u200b [other special reason why this doesn’t work for me].\\nI concede that my rules are probably not best for your situation. But have you thought about the issue for five minutes? Could you ask your boss if you can check email once a day and otherwise take phone calls? Maybe you don’t restrict email, but stop looking at websites like Reddit or Hacker News or Marginal Revolution or Facebook or Twitter? Are there other creative solutions waiting to be uncovered? Have you tried?\\nIf your team uses Slack for asynchronous communication, once- or twice-daily checks should be fine. If you use it for synchronous communication, perhaps establish a daily \"office hour\" when you’ll be on Slack, or even coordinate with your team to establish a daily \"Slack hour\" where people are expected to be online. Or something else. The point is to establish the main benefits you reap from each digital affordance, and then find a plan which minimizes the costs you pay for those benefits.\\n> I’m already good about my internet usage.\\nThis might be true! I know exactly one person for whom I’m quite confident this is true (Andrew Critch), and maybe there are more among my friends whom I don’t know about. This might be you if you already use services based on their costs and benefits, often using websites in unintended ways (like blocking all recommendations on YouTube via the Unhook add-on [Chrome, Firefox]), and spending far less time than average (eg only checking email very infrequently).\\nI’d still bet against it. I would have said I was good about my internet usage, and it *was* true—in a relative sense. I think people (motivatedly) underestimate how much time they waste, perhaps because it can feel bad and embarrassing to admit the problem.\\n> But how will I stay in touch with people? I’m already lonely.\\nExcellent question! Reallocate low-quality social time to high-quality social time. Instead of checking if some half-friends liked your FB status, call up a buddy and grab a beer, or go to a meetup, or join a club.\\n# Benefits of the declutter\\n*February 22nd: The First Day.* I went running, and got back to the house 10 minutes earlier than usual. Huh.\\nI called my parents and went on a leisurely walk. Even so, I got my morning routine done 60 minutes ahead of schedule. I read half of a book on ordinary differential equations while lounging in my sunlit room. I did some deep thinking for an hour, safe from my phone’s dopaminergic temptation. I switched contexts and read about electrostatics. Still hours ahead of schedule.\\nThe day yawned and stretched. I wondered if it would ever end. (It did.)\\n*February 23rd: The Second Day.* From my journal:\\n> It’s so relaxing not using my phone, and yet I can still feel my anxiety pulling me to my digital affairs.\\nDid my LW post get lots of upvotes? Are people criticizing me? Did I win a prize in the contest? Am I missing something on the EliezerFic server? I even thought about some identity-politics tweet I saw last week, on my run this morning… why is that garbage in my head? Good riddance.\\nAnd so unrolled the next day, and the next. Time laid itself out before me. With my reclaimed time, I went on walks, I read *The Character of Physical Law*, I read ~three physics textbooks, I tripled my daily Anki workload to 1.5 hours, and I *still had time left over*.\\nLife became leisurely. I wrote letters to my girlfriends—some of them were in French. I even had time to write *poems*. I talked to them more often than before, with nightly phone calls. I also called my family most mornings. *I still had time left over*.\\nInstead of trolling through Discord, I called some labmates at Oregon State and started a weekly dinner. If anything, I felt less lonely than before, when I had the world at my fingertips. I called people when I wanted to talk to them. *I still had time left over.*\\nI listened to a Stephen King book when I couldn’t sleep—I found it reassuring to worry about fortifying a grocery store against eldritch horrors, instead of worrying about fortifying our planet against artificial intelligence. I listened to Dune with Emma, clocking 21 hours over 2.5 weeks. I went on walks with her, and to a hot tub, and I *still had time left over*.\\nI did notice potential withdrawal symptoms (alarming!), mostly via increased baseline anxiety. Other explanations include \"defending my dissertation & moving soon\", so I’m not sure if it was from the declutter.\\nEven assuming this month gave me unusually large benefits, I wouldn’t ever, ever go back. So when the declutter ended, I wasn’t clamoring to check the highest-karma Reddit posts from last month. I still feel the urge, but I resent Reddit now that I see what it takes away from me. That makes it easier to stay away.\\n# Recommendations\\nThis short post may not be convincing enough to try out such a substantial life modification. I’m not asking that you do a declutter right away. I’m recommending that you read the first half of *Digital Minimalism**,* or listen on Audible (cost: a few hours and $14).\\nLet me sweeten the deal with a costly signal. If I’ve met you in real life, and you consume the first half of the book and find it unconvincing /\\u200b try the declutter and it wasn’t at all worth trying in hindsight, message me on LessWrong and I’ll pay you $30.[3]\\nI think many, many people are shooting themselves in the foot, so I will be blunt. *Please stop shooting yourself in the foot.* Please do a cost-benefit analysis. I think many people have serious, serious problems with their internet usage. I did. You might. If so, you are leaving a lot of your life on the table.\\n*Thanks to Meg Tong, Josh Turner, and Kurt Brown for feedback on this post.*\\n# Appendix 1: Declutter advice\\nHere’s my main tip to add to the book: *Have well-defined exception handling which you never ever ever have to deviate from.* When I read about how other people navigated the declutter, their main failure modes looked like \"my dog died and I got really stressed and gave in\" or \"a work emergency came up and I bent my rules and then broke my rules fragrantly.\"\\nPlan for these events. Plan for feeling withdrawal symptoms. Plan for it seeming *so so important* that you check your email* right now*. Plan for emergencies. Plan a way to handle surprising exceptions to your rules. Make the exception handling so good that you never have a legitimate reason to deviate from it.\\nMy procedure was \"If I need to use a forbidden functionality, then I have to write what I did down on a slip of paper and leave it on my girlfriend’s desk ASAP.\" This worked because Emma would understand legitimate exceptions, but would look askance at me if I started flooding her desk with \"and then I checked Reddit\" notes. It’s easier to hold promises to other people, than promises to yourself.\\n# Appendix 2: My post-declutter rules\\n\\n - I only listen to music when:\\n - Only listening to the music, to fully soak it in\\n\\n - Exercising\\n\\n - Reasoning on this point:\\n - I think music generally makes me subtly dumber but feel cooler while I’m listening to it, so I listen to it a lot.\\n\\n - Music imposes its own form on my thoughts. My thinking and mood becomes governed by the song which happens to be playing, and less by the substance of my own thoughts. I don’t want my reasoning to hinge on \"will Spotify shuffle to *Attack on Titan* or *Coldplay* next?\".\\n\\n - See also Gwern’s stub.\\n\\n - I do have Google Home, and often play nature sounds.\\n\\n\\n\\n - I only check LessWrong /\\u200b Discord /\\u200b Slack /\\u200b Messenger /\\u200b my text messages each Sunday at noon.\\n - I write blogposts before then, and I won’t check their reception until the next week (I used to nervously refresh).\\n\\n - I’ve also adblocked the karma elements of the website, because I worry too much about them.\\n\\n\\n - As I currently see it, I’m only logging in to the newsfeed part of Facebook two more times: To share this blog post, and after I receive my PhD.\\n - After that, I’ll check its event page weekly, while blocking the notifications /\\u200b other clutter FB tries to throw at me. This should take less than 10 minutes each week.\\n\\n - Here’s how to use FB more peacefully:\\n - Install FBPurity; you can save time by importing my settings here.\\n\\n - Use UBlock Origin to get rid of the rest; here is my element blocking list for Facebook.\\n - (I also hide the chat sidebar on the main page, which is a FB option)\\n\\n\\n\\n - I could also check a favorite page once a week (with the chat and comment elements blocked), if I need more memes in my bloodstream.\\n\\n - In combination with a monthly Messenger checkin, I’ve extracted my main benefits from Facebook, at a cost of at most 50 minutes each month, instead of 50 minutes each day!\\n - Again, I ***don’t recommend***** **doing small fixes like \"just hide some FB elements.\" These fixes **don’t work** for most people. This advice is aimed at post-declutter usage, which unfolds from your informed cost-benefit analysis.\\n\\n\\nHere’s what my FB news feed looks like now. 😌\\n - For news, I purchased a digital+print subscription to *The Economist*. Once a month, I can choose to read the four issues for an hour or two.\\n - I don’t need to read more than that. I can read about candidates before an election, and there isn’t much else that’s decision-relevant. If eg AI dynamics heat up and geopolitical understanding becomes more important, I’ll tackle that deliberately.\\n\\n - Looking back at my life, I see how often I’ve been hijacked by news websites. It makes me sick.\\n\\n\\n - I’m basically not going to text anymore. I used to check it so, so often.\\n - This was hard at first. One of my partners strongly prefers texting, and I liked texting her, and missed her a lot. With additional thought, we discovered that she really just wanted to asynchronously send me updates on how her day was going. I said she could text me as much as she wanted—but I’d read them during our next phone call.\\n\\n\\n - I can watch movies and play video games if I’ve planned it out at least a few hours in advance.\\n\\n - I can check Reddit for specific question/\\u200banswer threads.\\n\\n - I can check Twitter if I plan the session out in detail one day in advance.\\n - Twitter is toxic for me, even though I originally made an account to promote an alignment paper and only subscribed to AI/\\u200bmath accounts.\\n\\n\\n - My phone will still be in black and white and warm color temperature, to make it even less engaging compared to the rest of my world.\\n\\n - I *never ever use my phone on the toilet. Ever.* This has served me well and seems like a pure win.\\n\\n - ^This is only a sufficient condition; the app need not be the child of a billion-dollar company. For example, I oft ragebaited myself about the culture war via *Marginal Revolution* and *Hacker News*. I even tend to get anxious about *LessWrong* usage, and I know that the team deliberately refrained from attention-hacks like red notifications.\\nEven while using my Notion to edit this post and supervise research, I saw a red \"5 notifications\" marker, which gave me an overwhelming urge to *see what the notifications are*. With great effort, I ignored the impulse, and deleted the element with my adblocker.\\n\\n\\n - ^I just now picked up my phone and stared at it blankly. One month later. Yuck.\\n\\n\\n - ^Limit $300 total.\\n\\n',\n",
              "  'title': 'Do a cost-benefit analysis of your technology usage\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage',\n",
              "  'votes': '86'},\n",
              " {'authors': 'TurnTrout',\n",
              "  'comments': [{'authors': 'Space L Clottey',\n",
              "    'comments': [{'authors': 'Space L Clottey',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-02T09:30',\n",
              "      'id': 'axWHpFKjemHP8WaSk',\n",
              "      'omega_karma': '',\n",
              "      'score': '10',\n",
              "      'text': 'Actually, I want to walk back on this a bit. I was on a plane since this comment and the ten hours of no wifi was really nice and really unique and really focused, and I had absolutely no reason to check my phone because there was absolutely zero chance of their being a notification… I realised that I appreciated digital minimalism at the time because I had just come out of having no wifi forced apon me for a week and finding it really nice and really wanting to maintain it. I think I’ve just forgotten how nice it actually is\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=axWHpFKjemHP8WaSk',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'Tom Lieberum',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-31T09:27',\n",
              "      'id': 'CNuQEK84kCC793Fmr',\n",
              "      'omega_karma': '',\n",
              "      'score': '6',\n",
              "      'text': 'I want to second your first point. Texting frequently with significant others lets me feel be part of their life and vice versa which a weekly call does not accomplish, partly because it is weekly and partly because I am pretty averse to calls. \\nIn one relationship I had, this led to significant misery on my part because my partner was pretty strict on their phone usage, batching messages for the mornings and evenings. For my current primary relationship, I’m convinced that the frequent texting is what kept it alive while being long-distance. \\nTo reconcile the two viewpoints, I think it is still true that superficial relationships via social media likes or retweets are not worth that much if they are all there is to the relationship. But direct text messages are a significant improvement on that. \\nRe your blog post:Maybe that’s me being introverted but there are probably significant differences in whether people feel comfortable/\\u200blike texting or calling. For me, the instantaneousness of calling makes it much more stressful, and I do have a problem with people generalizing either way that one way to interact over distances is superior *in general*. I do cede the point that calling is of course much higher bandwidth, but it also requires more time commitment and coordination. \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CNuQEK84kCC793Fmr',\n",
              "      'votes': '5'},\n",
              "     {'authors': 'TurnTrout',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-03T16:49',\n",
              "      'id': 'ybvZBPx37dCv9k563',\n",
              "      'omega_karma': '',\n",
              "      'score': '4',\n",
              "      'text': 'I don’t remember at this point what digital minimalism advocates, but *I *advocate doing cost-benefit analyses, which are naturally sensitive to the specifics of your situation. The question may become: How can I draw most of the benefits of texting, without checking my phone 40 times a day? \\nAnd I think this question has meaningful answers, from batching responses eg thrice daily, to dedicated synchronous texting periods (like text-based phone calls!).\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=ybvZBPx37dCv9k563',\n",
              "      'votes': '3'}],\n",
              "    'date_published': '2022-03-28T11:13',\n",
              "    'id': 'EfjznyXLDTPyaqTQj',\n",
              "    'omega_karma': '',\n",
              "    'score': '22',\n",
              "    'text': 'I really really enjoyed digital minimalism when I read it, but think it was somewhat harmful to my relationships, given how hard it says that only text-relationships are basically worthless. It took like a year but I happened to meet someone really cool who strongly didn’t like calling and since the only way I could talk to them was texting, I sucked it up and actually found out that it’s not so bad.\\nI think it did help me firm up the things I dislike about texting, and with some agreed about norms I think they can be mitigated. Wrote about it here: Why call? | Space L Clottey (spacelutt.com)\\nThis post did A LOT for me in terms of my phone usage:\\nDistractions are a Nuisance, but Infinity Pools are the Real Problem | by John Zeratsky | Make Time | Medium\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=EfjznyXLDTPyaqTQj',\n",
              "    'votes': '13'},\n",
              "   {'authors': 'aphyer',\n",
              "    'comments': [{'authors': 'Rana Dexsin',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-30T06:00',\n",
              "      'id': 'gZzovr2FojRr8dnLt',\n",
              "      'omega_karma': '',\n",
              "      'score': '8',\n",
              "      'text': 'That in turn is actually dependent on whether having your ambient thoughts occupied by YouTube is better *overall* than having them occupied by nothing for a while. There’s a lot of valuable background processing that I suspect gets starved by constant stimulation. Of course, carving out explicit time for reflection or for a meditation practice or similar is also something one can do.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=gZzovr2FojRr8dnLt',\n",
              "      'votes': '6'},\n",
              "     {'authors': 'TurnTrout',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-03T16:57',\n",
              "      'id': 'F4axmENXiqpp7sfdN',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Pushback against (what seems to me like) an implicit assumption: In all probability, you are not evenly and strategically trading off \"bored time\" for \"entertained time.\" You are trading off huge chunks of your non-bored time, not because you lack virtue, but because Youtube \"wants\" to waste your time. So this is, I think, a dangerous trade to try to make, at least without analyzing it first.\\n> But if this time trades off against *staring at the ceiling being bored*, then Youtube is making my unproductive relaxation time more enjoyable and entertaining, and there is no problem.\\nIs there no problem? Sometimes being \"bored\" lets me focus on what it feels like to be a person, or feel grateful about my life, or just let my thoughts drift. This is pleasant, just like the quoted memory of staring at the ceiling. The sentiment was not \"FML, my boring life sucks\", but rather \"-------- [relaxation].\"\\nI also used to have thoughts race through my head when I turned in for the night, as if some great dam had broken, now that no distractions were occupying my attention. That *seems* to happen less now. Which, in turn, seems good.\\nAnyways—empirically, I have not spend much time bored. So the point seems moot, in that I am not advocating increased \"bored\" time, but reallocation. \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=F4axmENXiqpp7sfdN',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T17:00',\n",
              "    'id': 't8sdiWQbqfdc6jquG',\n",
              "    'omega_karma': '',\n",
              "    'score': '15',\n",
              "    'text': '> I remember lazy summer childhoods, staring at the ceiling after I ran out of video game time. \\nI think this argument points in the opposite direction from your main post. The most salient question for ‘spend less time messing around on the Internet’ is ‘what will that saved time end up being spent on?’\\nSometimes I watch cute Youtube video compilations of pets doing silly things.  \\nIf this time trades off against writing a novel, or learning an interesting skill, or making friends, or exercising, then Youtube is wasting my time on unproductive things and I should try to waste less time.\\nBut if this time trades off against *staring at the ceiling being bored*, then Youtube is making my unproductive relaxation time more enjoyable and entertaining, and there is no problem.\\n(Relevant xkcd).\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=t8sdiWQbqfdc6jquG',\n",
              "    'votes': '14'},\n",
              "   {'authors': 'DanielFilan',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'DanielFilan',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-05-03T18:35',\n",
              "        'id': 'LdzxNwzpmQwqKgQuX',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'Have PM-ed.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=LdzxNwzpmQwqKgQuX',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-05-03T02:21',\n",
              "      'id': 'CZ7LDxP923HRdaHfw',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': 'Strong-upvoted, even though I disagree on the overall argument strength (I think there were some weak arguments but in total the evidence seemed pretty good to me). I look forward to paying out if you want to collect on that.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CZ7LDxP923HRdaHfw',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-04-25T21:59',\n",
              "    'id': 'f5p9eHcTE5LrmWPQv',\n",
              "    'omega_karma': '',\n",
              "    'score': '13',\n",
              "    'text': 'For what it’s worth, I have met TurnTrout in real life, use social media, and was initially skeptical about the Digital Minimalism thesis. After reading this post, and having had it recommended to me by another friend, I read the first half of Digital Minimalism. I found it basically unconvincing. In particular, it seemed like chapter 1 was supposed to provide motivation for why social media was bad for me, but didn’t really deliver—I didn’t think the evidence given distiguished \"social media is designed to be addictive\" with \"social media is designed to be valuable and usable\". For instance, it seems to interpret social media tools that let you interact with your friends in ways that have significance for your relationship (e.g. tagging them in pictures) as a way to addict people, but it seems to me that that’s just a nice feature. In some places it seemed sort of obtuse—the author talks about how the ostensive benefit of FB is letting you see things like friends’ baby pictures, and claims that the like button increases addictiveness but doesn’t help deliver the ostensive benefit. But it seems obvious to me that seeing which posts are ‘liked’ would help FB distinguish between pictures that people want to see (babies, engagement photos) and pictures that they don’t (poorly-lit food photos, boring party pictures).\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=f5p9eHcTE5LrmWPQv',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'Logan Riggs',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'Logan Riggs',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-04T18:32',\n",
              "        'id': 'BrMDCgkbqLTBrZpLX',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'I’m unsure about this now. I think there may generally be way better ways to cope (eg sleeping, walks, reading a book, hanging with friends). \\nA different thought: Clarifying the core thing you don’t like about having media always on (maybe the compulsion that leads to distractedness) may make your idea easier to communicate and look different in actions/\\u200bplans produced. Like I’m fine with watching a movie with a friend or playing a video game with my roommate for an hour. \\nA slightly different thought: setting alarms on my phone if I’m looking at my phone for the time because I have a meeting, or I’m waiting on someone to message me timely information has been helpful. I can set a timer for an hour and check my phone then in case they’ve messaged. Or set the timer 5 minutes before my meeting, so I don’t have to think about it.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=BrMDCgkbqLTBrZpLX',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T17:18',\n",
              "      'id': 'gvpG4DS6yu75KiXQc',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': '(I think everyone should have well-defined exception handling, because some of you *will *have crazy shit happen, like \"someone died\", and that *can *make it hard if you’re pondering \"do I let myself have an allowance now?\". Failing to plan is planning to fail (in not-wholly-improbable worlds).)\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=gvpG4DS6yu75KiXQc',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-29T02:48',\n",
              "    'id': 'AdAndSGrXv963uEyd',\n",
              "    'omega_karma': '',\n",
              "    'score': '10',\n",
              "    'text': 'Sure, I’ll do it as well. For me: \\n\\n - 1pm—Check snaps, messages, emails, discord team messages and accelerating alignment channel, & EAGx messages. Hard limit at 1:30pm (just set two alarms on my phone)\\n\\n - Whitelist—Roam/\\u200b research related searches. Phone calls/\\u200b texts are unblocked from a certain set of people, who I’ve told can reach me there. (I set them in the emergency contact list), but besides that, my iPhone is in \"focus mode\" with all notifications hidden. \\n\\n - Exception handling: I don’t think I’ll need one, but I can let my roommate know and ask for his social support. (Specifically call me out if he sees me on my phone at other times, haha)\\n\\n - I normally journal, so that’ll help with logging. \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=AdAndSGrXv963uEyd',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Heron',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-31T19:19',\n",
              "    'id': 'F3Ho4ukj2nEmxwnDB',\n",
              "    'omega_karma': '',\n",
              "    'score': '9',\n",
              "    'text': 'Thanks for reminding me of my small concern: time-wasting, specifically doom-scrolling on Twitter. I will listen to the book!\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=F3Ho4ukj2nEmxwnDB',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'niplav',\n",
              "    'comments': [{'authors': 'Ben Pace',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T19:48',\n",
              "      'id': '7giz4ArjW7X23PqQ7',\n",
              "      'omega_karma': '',\n",
              "      'score': '5',\n",
              "      'text': '> I have an additional pet peeve about this post: It has the words \"cost-benefit analysis\" in the title, but doesn’t have a cost-benefit analysis in the body (at least not of the juicy expected-value variety)!\\nOh yeah, I feel like a more natural title would be \"PLEASE DO SOME ACTUAL EMPIRICISM\".\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=7giz4ArjW7X23PqQ7',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'niplav',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-06T13:20',\n",
              "        'id': 'SxJqf8mzZPAworJY2',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': '> I have noticed increased anxiety in myself. I think it quite possible I already had most of it before the declutter, and instead wrapped myself in comforting mind-numbing internet usage which obscured it from me. Another person who has done the declutter, reported similar suspicions about themselves.\\n\\n\\nA psyche might start\\ncutting itself, if it is\\nnot dulled each fortnight',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=SxJqf8mzZPAworJY2',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T17:09',\n",
              "      'id': 'SgBPffRmTxKN4cd6j',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': '> I also have experienced increased anxiety, which has persisted (and become slightly stronger) 7.5 months after moving.\\nI have noticed increased anxiety in myself. I think it quite possible I already had most of it before the declutter, and instead wrapped myself in comforting mind-numbing internet usage which obscured it from me. Another person who has done the declutter, reported similar suspicions about themselves.\\n> This has some interesting implications: The worse the problem of wasting time on the internet is for you, the harsher your measures will need to be, and the less you will want to carry them out (except in lucid moments).\\nThis doesn’t ring to my experience. Everything became easier when I said \"*No *reddit\", as opposed to ~\"Reddit if I can find a good enough reason.\" \\n> I have an additional pet peeve about this post: It has the words \"cost-benefit analysis\" in the title, but doesn’t have a cost-benefit analysis in the body (at least not of the juicy expected-value variety)!\\nPlease don’t use those words if you’re not going to deliver ;-)\\nI included eg the Facebook usage meme (which is the real output of a CB analysis), and described the results of other analyses I did. I think the analyses were so lopsided, and the solutions so clean, that assigning numbers would be a distraction. Also, the point of assigning numbers to personal-utility-estimates is, I think, to throw them out after you do the estimate, and do what your updated gut feeling says.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=SgBPffRmTxKN4cd6j',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-29T08:45',\n",
              "    'id': 'dyHjRsrF9BaaFFeoY',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': 'So, I haven’t read Digital Minimalism, but I have been becoming increasingly worried about attention-grabbing systems over the last ~2 years, culminating in me choosing not to have internet at my apartment when I moved last May (getting internet at a local library, with a ~15 minute walk there by foot), after having iterated through many versions of locks & blocks & deleted elements, all pretty much fruitless in the end.\\n\\nSo, yeah, I think already pretty good about my internet usage.\\n\\nThis has resulted in interesting dynamics: I often procrastinate by reading through my downloaded copy of wikipedia, or by weightlifting (!), when I don’t want to do work. I am also much more vulnerable to overindulging when I’m at a place with internet, e.g. when I’m visiting my parents.\\n\\nI have some predictions about your experiment:\\n\\n\\n - You will continue in your current decluttered mode (70%)\\n\\n - You will temporarily fall back into bad habits (50%)\\n\\n - You will make it stricter after some while (60%)\\n\\n\\n\\n - Your initial productivity benefits will experience a regression toward the mean (80%)\\n\\n - The (perceived) benefits will continue outweighting the (perceived) costs (90%)\\n\\n\\n\\n - You will find yourself procrastinating in odd and novel ways, such as reading a lot of fiction, or exercising, or snacking a lot, or reading Wikipedia a lot (40%)\\n\\nI also have experienced increased anxiety, which has persisted (and become slightly stronger) 7.5 months after moving.\\n\\nI don’t necessarily recommend such extreme measures to everyone, but I have the lurking suspicion that people tend to underreact to time & attention lost.\\n\\nI’m unhappy that picoeconomics hasn’t been further investigated on LessWrong, because, aside from the term being very cute, trying to balance the costs of accessing different resources that may be harmful in too large or small quantities seems pretty central to the endeavour of managing (if not defeating) akrasia.\\n\\nA hypothesis could be that while human System 2 does exponential discounting, System 1 performs hyperbolic discounting, and we’d like to increase the cost of accessing e.g. internet services so that for that cost, our hyperbolically discounted value is smaller than the exponentially discounted value (ideas like this being central to picoecon).\\n\\nUnder this model, for myself, the time to remove ublock from my browser addons (or simply install another browser, etc.), which would take around half a minute, the hyperbolically discounted present value was not less than the exponentially discounted value, but the 15 minutes of going to the nearest library (or buying a router and installing it, or paying an additional 10€ for more mobile data (so here, expensive mobile data plans are *better*) *would be*, so I don’t do it.\\n\\nThis has some interesting implications: The worse the problem of wasting time on the internet is for you, the harsher your measures will need to be, and the less you will want to carry them out (except in lucid moments).\\n\\nI have an additional pet peeve about this post: It has the words \"cost-benefit analysis\" in the title, but doesn’t have a cost-benefit analysis in the body (at least not of the juicy expected-value variety)!\\n\\nPlease don’t use those words if you’re not going to deliver ;-)\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=dyHjRsrF9BaaFFeoY',\n",
              "    'votes': '5'},\n",
              "   {'authors': 'noggin-scratcher',\n",
              "    'comments': [{'authors': 'Yitz',\n",
              "      'comments': [{'authors': 'Elizabeth',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-29T01:46',\n",
              "        'id': 'P5AyoJKCBDd2CzqPB',\n",
              "        'omega_karma': '',\n",
              "        'score': '11',\n",
              "        'text': 'I checked out a bunch and chose inoreader, although I needed to pay to get all the features I wanted.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=P5AyoJKCBDd2CzqPB',\n",
              "        'votes': '5'},\n",
              "       {'authors': 'noggin-scratcher',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-29T23:40',\n",
              "        'id': '4D8pGA5icQgDEcKMn',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'I’m using Inoreader, paying for the \"Pro\" tier of features.\\n\\nI’m getting particular use out of their duplicate filters, regex-based content filters, receiving newsletters as a feed, and automated scraping/\\u200bmonitoring of sites that don’t publish their own feed.\\n\\nHave also used the custom CSS option to productively disagree with some of the choices made when they re-designed the interface. But I think that’s available on the cheaper \"Supporter\" tier too.\\n\\nThere has in the past been a \"buy 18 months for the price of 12\" discount available at least annually (around Black Friday possibly; might have been New Years). Which I’ve used to keep the cost down.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=4D8pGA5icQgDEcKMn',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-03-29T01:44',\n",
              "      'id': 'AwTC5qWZG9CNAwd3n',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'May I ask what software you use for your RSS aggregator?\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=AwTC5qWZG9CNAwd3n',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T10:51',\n",
              "    'id': 'bGxGzJ5KyqhJ7iHTP',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': 'My personal antidote to the \"check lesswrong. check mad investor chaos. work 5 mins. check mad investor chaos. check lesswrong\" problem has been to channel everything I possibly can into an RSS aggregator. No need for *me* to be twitchily refreshing and checking; I have a computer to do that for me.\\nAlso helps, I think, that I’m then removed from the algorithmically-mediated Skinner box of someone else deciding what my news feed is. I just get a simple chronological list of headlines from sites I’ve chosen—nothing that’s being shared or promoted or trending or whatever, and with my own defined rules/\\u200bfilters to remove categories of post I’m not interested in seeing. Also no fear of missing out, because my unread items will still be there later whenever I come back for them.\\nStill occasionally has the problem of turning into an attention-suck by way of being subscribed to too many things, or to sites that produce too many updates. Still need to be alert to whether individual sites are a true benefit to be subscribed to. Still need to keep a lid on feed-reading from consuming all of my time. \\nSo it’s not a solution to \"I read *too much* internet\", but I think it’s at least an improvement over other *ways* of reading the internet.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=bGxGzJ5KyqhJ7iHTP',\n",
              "    'votes': '6'},\n",
              "   {'authors': 'TekhneMakre',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'TekhneMakre',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-04T02:55',\n",
              "        'id': 'kRepe7Mk45Bh9qyPn',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': '\"participation in networks\"? IDK. Is \"social media\" too narrow? I intuitively include LW, blogs, forums, email, as social media. Youtube is a mix; I consider it social media when I’m using it as pica for talking to a person, and I endorse most of my other Youtube use (e.g. videos of natural phenomena, or documentaries, or clever inventions). But yeah I could imagine being seriously attention-sniped in some other unendorsed way.\\n\"attention service usage\"? \"consumption service usage\"? That’s not really clear, though it does have a precise meaning that I think is what you’re trying to point at: services (i.e. computer programs running somewhere else that do some computing task for you) which are attention /\\u200b consumption based (i.e. the thing you’re getting from the service is something you’re going to just directly experience, as opposed to running it through some more computation). Services which are attention-based seem like the central type of technology that induces attention-sniping incentives. (Though it’s not sufficient, e.g. Wikipedia.)\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=kRepe7Mk45Bh9qyPn',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T16:58',\n",
              "      'id': 'w7MYRmHT74vj462k4',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Originally titled \"Do a cost-benefit analysis of your internet usage\", but this makes it sounds like analyzing different internet service provider plans. \"Social media usage\" is too narrow. I’m open to suggestions.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=w7MYRmHT74vj462k4',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T10:32',\n",
              "    'id': 'M7ahy9G4PcT9gwEQG',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': 'Acknowledging that this is how people generally use the word \"technology\", I’d rather reserve that word for things that are involved in tekhne, i.e. tools, machines, devices, programs, components, factories, methods, etc.; things one uses to produce. I think you’re centrally talking about networks and services. Richard M Stallman calls them \"disservices\", as in \"Facebook provides an online social networking disservice\". That it’s even possible to seemingly unwillingly more or less ruin oneself using a thing, is evidence that one isn’t centrally relating to the thing as a technology at all.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=M7ahy9G4PcT9gwEQG',\n",
              "    'votes': '6'},\n",
              "   {'authors': 'Ben Pace',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T19:18',\n",
              "    'id': 'PSgCiQSiKEL9HqpS5',\n",
              "    'omega_karma': '',\n",
              "    'score': '7',\n",
              "    'text': '> When was the last time you were bored and in silence?\\nFor the record, it was 2 days ago.\\n> like blocking all recommendations on YouTube via the Unhook add-on [Chrome, Firefox]\\nWoah — you just gave me agency over YouTube! Thanks so much, this is looking like it will really change my relationship with the site to be much more intentional (e.g. I like how it makes it so I can default to only seeing my subscriptions).\\n> Here’s my main tip to add to the book: *Have well-defined exception handling which you never ever ever have to deviate from… *My procedure was \"If I need to use a forbidden functionality, then I have to write what I did down on a slip of paper and leave it on my girlfriend’s desk ASAP.\"\\nWhen I did 2 weeks of no devices, my procedure (which I remember telling you in a LW PM like 6 months ago) was \"you can do a thing on your device if you wrote it down on a piece of paper yesterday\". That worked well for me while I was in more of a vacation mode.\\n> I write blogposts before then, and I won’t check their reception until the next week (I used to nervously refresh).\\nVery cool to hear you that you do this! Congratulations. For me I don’t check until 24 hours have passed, and never do refreshes. I do like responding to comments faster than 1 week. But yeah, the repeated refresh while your post has no karma and one unhelpful comment is not worth it.\\n> For news, I purchased a digital+print subscription to *The Economist*. Once a month, I can choose to read the four issues for an hour or two.\\nThe one I’ve been meaning to move to is, once a month, check the top-voted stories on HN that month.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=PSgCiQSiKEL9HqpS5',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'Jack R',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'Jack R',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-04T06:52',\n",
              "        'id': 'CJZqhoPKuyLMHvkdM',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': 'Ah — sorry if I missed that in the post, only skimmed\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CJZqhoPKuyLMHvkdM',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T17:15',\n",
              "      'id': 'pBhAAsHvFinuShc8P',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Yup, this is what I did, but I just didn’t have the notebook. I like the bright line.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=pBhAAsHvFinuShc8P',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-29T08:39',\n",
              "    'id': 'PrFBSgKyaK68w6bot',\n",
              "    'omega_karma': '',\n",
              "    'score': '7',\n",
              "    'text': 'Random tip: If you want to restrict apps etc on your iPhone but not know the Screen Time pin, I recommend the following simple system which allows you to not know the password but unlock restrictions easily when needed:\\n\\n - Ask a friend to write a 4 digit pin in a small note book (which is dedicated only for this pin)\\n\\n - Ask them to punch in the pin to your phone when setting the Screen Time password\\n\\n - Keep the notebook in your backpack and never look inside of it, ever\\n\\n - If you ever need your phone unlocked, you can walk up to someone, even a stranger, show them the notebook and ask them to punch in the pin to your phone\\nThe system works because having a dedicated physical object that you commit to never look inside is surprisingly doable, for some reason.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=PrFBSgKyaK68w6bot',\n",
              "    'votes': '5'},\n",
              "   {'authors': 'Trevor1',\n",
              "    'comments': [{'authors': 'hath',\n",
              "      'comments': [{'authors': 'matto',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-29T12:59',\n",
              "        'id': 'YckCweuMjegiSgNrb',\n",
              "        'omega_karma': '',\n",
              "        'score': '3',\n",
              "        'text': 'Postman is a great writer and this is one my favorite books.\\nWhat’s changed between 1985 and today is that human attention has become the scarcest (ie. most valuable) resource. Because of this, the Web is under immense market pressure to turn into a perfected form of cable TV as described by Postman. This is what’s driving platform centralization (ie. Facebook, TikTok, etc.) as well as the one-to-many model where a handful of users (influencers) produce while a great majority merely consume.\\nWe’re not there yet, but we’ve swung strongly in that direction in just a decade with change. My hope is that counter-forces like *Digital Minimalism* as well as the inherent flexibility of the medium of the Web will arrest or even revert this change.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=YckCweuMjegiSgNrb',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-03-29T02:06',\n",
              "      'id': 'ajcqEaE6AJzC6Lsim',\n",
              "      'omega_karma': '',\n",
              "      'score': '9',\n",
              "      'text': 'A book I highly enjoyed on the topic was Neil Postman’s Amusing Ourselves to Death, which was Neil Postman mourning the death of rational discourse from TV in the year 1985. Very highly reccomend.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=ajcqEaE6AJzC6Lsim',\n",
              "      'votes': '4'},\n",
              "     {'authors': 'Logan Riggs',\n",
              "      'comments': [{'authors': 'TurnTrout',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-03T17:14',\n",
              "        'id': 'eGhxZAuXY7SonWiGx',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': ':)\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=eGhxZAuXY7SonWiGx',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-03-29T02:06',\n",
              "      'id': 'DGzNYC4i8xCBdc5MJ',\n",
              "      'omega_karma': '',\n",
              "      'score': '6',\n",
              "      'text': 'I think reading the book and/\\u200bor trying it yourself would be very informative. You have at least until next Sunday when he reads this comment or potentially writes more.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=DGzNYC4i8xCBdc5MJ',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'mingyuan',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T18:50',\n",
              "      'id': 'HZ6zvLCS98k7yL97B',\n",
              "      'omega_karma': '',\n",
              "      'score': '4',\n",
              "      'text': 'You should message Kurt, who’s mentioned in the post as TurnTrout’s inspiration for doing this in the first place. Sounds like TurnTrout isn’t going to be online/\\u200bmessaging much in the near future :)\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=HZ6zvLCS98k7yL97B',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-28T14:02',\n",
              "    'id': '4JEFwRkmZQhxgdB4o',\n",
              "    'omega_karma': '',\n",
              "    'score': '5',\n",
              "    'text': 'Please, please, please make more posts on this issue. I really like what I see here, I’ve found it very helpful, and I need to see more. \\nPlease message me on your thoughts if you ever have anything you’d like to share about this problem, e.g. what works, what doesn’t work, what seems to happen to people, etc.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=4JEFwRkmZQhxgdB4o',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'JonathanMoregard',\n",
              "    'comments': [{'authors': 'Valentine',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-31T15:29',\n",
              "      'id': 'rxFarMyfWdRuZdJwJ',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'That’s native to Facebook now, actually. I don’t remember where, but if you dig around in the settings you can turn off notifications for reactions/\\u200blikes.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=rxFarMyfWdRuZdJwJ',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T11:10',\n",
              "    'id': 'owrLHZ5moA3KN5KCM',\n",
              "    'omega_karma': '',\n",
              "    'score': '5',\n",
              "    'text': 'Does anyone know about an addon to filter facebook notifications? I want to know about comments, but not reactions/\\u200blikes\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=owrLHZ5moA3KN5KCM',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'TurnTrout',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-04-03T17:21',\n",
              "    'id': '7qub738wxkxHB3wZG',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'Update: I had a few relatively anxious days, and decided to relax my music policy slightly. Sometimes I’d be a little too anxious to do work without music. While I fix this problem, I’m going to listen to music more permissively.\\nI think there’s another trade-off to music while working, which is that it makes me more *excited *at the cost of making me *slightly dumber*. Sometimes this is worth it. Marking as something to analyze more later, as I currently (attempt to) refactor my internal systems so that they don’t produce these anxious signals.\\nAlso, added to main post: \"I *never ever use my phone on the toilet. Ever.* This has served me well and seems like a pure win.\"\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=7qub738wxkxHB3wZG',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'ike',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'ike',\n",
              "        'comments': [{'authors': 'TurnTrout',\n",
              "          'comments': [],\n",
              "          'date_published': '2022-04-17T17:27',\n",
              "          'id': 'XTRptRgA7RychPeKi',\n",
              "          'omega_karma': '',\n",
              "          'score': '2',\n",
              "          'text': 'Yay! Keep up the good work :) I bet there’s a way to stick to it better, I’d advise you to keep trying things on that front.\\n',\n",
              "          'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=XTRptRgA7RychPeKi',\n",
              "          'votes': '1'}],\n",
              "        'date_published': '2022-04-10T21:03',\n",
              "        'id': 'tJYzFTgjRSKHFTTn2',\n",
              "        'omega_karma': '',\n",
              "        'score': '10',\n",
              "        'text': 'It’s been hard keeping to it, but I do notice myself being more productive when I do. One thing that has stayed is not having an email tab always open. Hoping that over time I get better at following it strictly; it has such immediate positive effects that I’m not so worried I’ll gradually forget and stop, like happened with other productivity attempts (e.g. making to-do lists.)\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=tJYzFTgjRSKHFTTn2',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-04-03T17:18',\n",
              "      'id': '9JRpANRBaDNMaqhgp',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Interested to hear how this goes.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=9JRpANRBaDNMaqhgp',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-30T16:35',\n",
              "    'id': 'XnijshvYhpNcfHvcv',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'I really liked this post. As a result of reading it, I’m trialling the following:\\n\\nEvery time I go on my computer or phone, I need to specifically have a plan for one specific thing I am going to do. This can be \"check all notifications from X/\\u200bY/\\u200bZ), or \"write this one long email\", or even, \"15 minutes of unstructured time\", but it should always be intentional. If I get the urge to do something else, I need to save it for a future session, which can be immediately afterwards.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=XnijshvYhpNcfHvcv',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'supposedlyfun',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T03:21',\n",
              "    'id': 'CbvugZqy7GLgD5ujX',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'If you can get work done while having Wikipedia not-blocked, you are a better worker than I am. I will absolutely read about irrelevant, flagrantly not-even-wrong Medieval scholastic philosophers instead of doing chores.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CbvugZqy7GLgD5ujX',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'aarongertler',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-05-17T10:18',\n",
              "    'id': 'Ch9nc8ZqDAFnqJq4X',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'This post led me to remove Chrome from my phone, which gave me back a few productive minutes today. Hoping to keep it up and compound those minutes into a couple of solid workdays over the rest of the year. Thanks for the inspiration!\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=Ch9nc8ZqDAFnqJq4X',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Josephm',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-30T19:08',\n",
              "    'id': '6jnDBmBetZiEbLxrD',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': '> I even thought about some identity-politics tweet I saw last week, on my run this morning… why is that garbage in my head? Good riddance.\\nI noticed this when I did a similar ban on technology usage. It’s bizarre how I could still have some YouTube video frequently pop into my thoughts, weeks after I stopped watching YouTube entirely.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=6jnDBmBetZiEbLxrD',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'james.lucassen',\n",
              "    'comments': [{'authors': 'GeneSmith',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T04:45',\n",
              "      'id': '9HTmw9jsmvCdeLP2k',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': 'This post is at least one more data point that Cal Newport’s method worked for someone else.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=9HTmw9jsmvCdeLP2k',\n",
              "      'votes': '2'},\n",
              "     {'authors': 'mingyuan',\n",
              "      'comments': [{'authors': 'james.lucassen',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-30T15:15',\n",
              "        'id': 'GWyuxButNCFwhfj9i',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': 'this is great,thanks!\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=GWyuxButNCFwhfj9i',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-03-29T18:47',\n",
              "      'id': 'puiqvyu2uGEJ2tFv9',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Kurt Brown (mentioned in the post) did an experiment on this, helping residents of CEEALAR (formerly the EA Hotel) do their own Newport-style digital declutter; you can read his preliminary writeup here.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=puiqvyu2uGEJ2tFv9',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T05:23',\n",
              "    'id': 'F4AQaDriJdAkEhEjP',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'What do you think about the effectiveness of the particular method of digital decluttering recommended by Digital Minimalism? What modifications would you recommend? Ideal duration?\\nOne reason I have yet to do a month-long declutter is because I remember thinking something like \"this process sounds like something Cal Newport just kinda made up and didn’t particularly test, my own methods that I think of for me will probably better than Cal’s method he thought of for him\".\\nSo far my own methods have not worked.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=F4AQaDriJdAkEhEjP',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Vika',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-04-05T15:42',\n",
              "    'id': 'd7czHLaBK6SHAKcSM',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'Thanks Alex for the helpful recommendation! I got the book and read the first half. I’d like to do a declutter at some point, still figuring out how to handle non-optional technologies (e.g. work slack tends to be a major distraction for me, which is probably best coordinated with my team as a whole). \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=d7czHLaBK6SHAKcSM',\n",
              "    'votes': '1'},\n",
              "   {'authors': 'SeishinSennin',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-17T17:26',\n",
              "      'id': 'tnBpXMbJ5Fyx9r6dz',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'I just wouldn’t use most apps or websites. By adopting a bright-line whitelist approach with clear, universally applicable exception handling and scheduled eg email checks, I didn’t have constant temptations to rationalize breaking my own rules, like I did when I was *sometimes *allowed to use a service.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=tnBpXMbJ5Fyx9r6dz',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-04-13T00:05',\n",
              "    'id': 'kpgbabkn7fgPHCv4H',\n",
              "    'omega_karma': '',\n",
              "    'score': '1',\n",
              "    'text': 'What apps are you (and commenters) using to enforce declutter/\\u200breduce the System 1 instant refresh urges? I’m looking for phone and computer blockers/\\u200bfilters and other suggestions.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=kpgbabkn7fgPHCv4H',\n",
              "    'votes': '1'}],\n",
              "  'date_published': '2022-03-27T23:09',\n",
              "  'id': 'fri4HdDkwhayCYFaE',\n",
              "  'omega_karma': '',\n",
              "  'score': '172',\n",
              "  'source': 'lesswrong',\n",
              "  'tags': 'Social Media/Practical/Self Improvement/Self-Deception',\n",
              "  'text': 'Contents\\n - Mistake: Motivatedly avoiding thinking about the issue\\n - Digital Minimalism\\n - Time costs\\n - Attentional costs\\n - Implementing the declutter\\n - My declutter rules\\n - Benefits of the declutter\\n - Recommendations\\n - Appendix 1: Declutter advice\\n - Appendix 2: My post-declutter rules\\nIf an unaligned entity invests billions of dollars into an application which you use, where they benefit from wasting your time, and you haven’t at least done a cost-benefit analysis so that your usage minimizes your costs and maximizes your benefits—*You are probably getting fucked over*.\\n# Mistake: Motivatedly avoiding thinking about the issue\\nLast summer, my friend Kurt Brown told me about *Digital Minimalism**.* The modern world is mired in attention-sucking apps which compete to waste as much of your time as possible. The book’s remedy: stepping back from non-essential internet usage, so that you can evaluate what really matters to you. After a month has come and gone, you add back in those digital activities which are worth it to you.\\nUnfortunately, this is the part of the story where we all cringe at my past behavior. I gave Kurt some excuses, demurring from his implicit recommendation that I read the book. I asked more questions, but so that I could learn more about what he’d been up to. I wasn’t going to actually do it. I think it sounded monastic and uncomfortable and *I’m not one of those people who needs it, I already have lots of locks on my devices*.\\nAnd locks I had. I restricted my iPhone with a password only known by a friend, so that I was unable to access *eg* Reddit without wiping my device, or asking my friend for the code. My phone was in black and white to minimize how appealing it would be, I had an outdated model to make using my phone less enjoyable. I didn’t have notifications for anything but phone calls. I *still wasted several hours a day on my phone, although I was always (motivatedly) surprised by this.* I thought I was spending at least 70% of my phone-time productively, by reading LessWrong and Wikipedia, or engaging in work communication. In this scenario, I didn’t want to upend my life for a month in order to save less than an hour a day (even though it still would have been worth it in the long run).\\nThis school year, I’ve had problems focusing and relaxing. I tried exercise, different medication, but nothing hit the spot. I wasn’t reading textbooks like I wanted to, my attention was fractured, I often felt behind my schedule. I was still doing my job and making progress—just not as much as I wanted.\\nCould this have anything to do with my attention problems?This spring, I read a LessWrong post which mentioned *Digital Minimalism*. Luckily, this triggered my \"if several reasonably smart EAs swear by the benefits of X, investigate X\" trigger-action plan.\\n# Digital Minimalism\\nI listened to the first half of the book on Audible in one night. As I wrote above:\\n> If an unaligned entity invests billions of dollars into an application which you use, where they benefit from wasting your time, and you haven’t at least done a cost-benefit analysis so that your usage minimizes your costs and maximizes your benefits—*You are probably getting fucked over*.[1]\\nI was immediately convinced that this thesis is correct, and resolved to start my month-long \"digital declutter\" the next day.\\n## Time costs\\nConsider why you originally bought a cell phone. It was probably to call people, to text people, to take photos, to get GPS navigation. Would you have bought it if you foresaw how you would feel an urge to check it even during a dinner with a friend you hadn’t seen in a long time? Would you have bought it if you knew you would take impatiently take it out of your pocket dozens of times a day, staring at it 2+ hours daily?\\nThe point isn’t \"phone bad, never use phone, quit now.\" My phone provides me with enormous benefits. The point is *where was the cost-benefit analysis, what tf has happened to us?!*\\nNotice the middle stat: **one third of daily waking hours**. I am disgusted that some people try to make this number go up further. From AppAnnie.Readers of this forum are probably better about their usage. Let’s be (too) generous and cut that to a mere two hours wasted daily on your phone, and 0 hours wasted on your other devices. That’s only *one eighth of your waking year,* or 1.5 waking months each year.\\n## Attentional costs\\nBut lost time doesn’t capture everything sucked away by your apps, by your email tics, by YouTube, by Reddit, by Slack, by Discord, by everything else which is after you. *Digital Minimalism* asked:\\n> When was the last time you were bored and in silence?\\nI remember lazy summer childhoods, staring at the ceiling after I ran out of video game time. At my 2018 CFAR workshop, my phone dipped in a stream for several minutes and short-circuited. I was actually glad. I felt free. How strange, to feel *free* from a device I purchased! Perhaps I should have noticed the warning sign.\\nSince then, engagement has been a pocket-grasp away. I’d leave my phone in another room to work, only to find my way back half an hour later. Even now, I look down at my phone on my desk, and I feel it. I feel it calling to me from far away, whispering to me, urging me to check Slack or my email—just one more time.\\nThese compulsions kill deep work in the cradle. My attention was fractured and strewn. I would anxiously procrastinate by flitting through tabs: *Discord. Slack. LessWrong. Gmail.* Even when I cleared time to think, I would periodically check my phone.\\n## Implementing the declutter\\nAt this point, you might be thinking \"OK, but I can’t roam the mountains of Nepal for a month. I have work to do and that requires staying in touch with people.\" Sure. The point of this post is not \"no phone.\" The point of this post is to build a digital life purposefully and carefully, because you reflectively endorse each component. The point of this post is to get people to do *any cost-benefit analysis at all* of the way they spend 1/\\u200b8th–1/\\u200b3rd of their waking hours.\\nMy estimate of the daily costs and benefits for a better-than-average Facebook user (considering Messenger to be distinct from Facebook). In appendix 2, I detail how I extract all of these benefits for 40 minutes a month, instead of 40 minutes a day—a 30x improvement!The declutter goes as follows:\\n\\n - Identify the minimal set of digital affordances required to do your job and the other necessities of life (e.g. paying bills).\\n\\n - Cut out everything else for one month.\\nThe point is that these apps which are out to get you—they’re very good at what they do. It’s not enough to turn off notifications and enable app timers. *Digital Minimalism* argues (and I mostly agree) that you have to *get out of the pond entirely* and catch a breather. After the declutter, you can soberly analyze the costs and benefits of each digital activity you add back in.\\n### My declutter rules\\nI went by a whitelist[2] in order to ensure there wasn’t a way to weasel around the rules. Here’s what I let myself do:\\n\\n - Phone\\n - Voice & video calls\\n\\n - GPS\\n\\n - Audible\\n\\n - Uber/\\u200bLyft\\n\\n - Authenticators/\\u200balarms/\\u200bother boring utilities\\n\\n - Roam/\\u200bnote-taking\\n\\n\\n - iPad\\n - Note-taking\\n\\n - Reading\\n\\n - Drawing\\n\\n\\n - Computer\\n - Anything offline (except music or video games)\\n\\n - Textbooks and Wikipedia and arxiv/\\u200bgoogle scholar\\n\\n - Overleaf for writing papers\\n\\n - Amazon and Upwork (for managing contracted-out labor)\\n\\n - Zoom for weekly meetings\\n\\n - Anki and Roam\\n\\n - Check email at noon on Mondays and Thursdays\\n - I told people to call me if it was important. I didn’t get any calls.\\n\\n - I later let myself send emails without looking at my inbox. I recommend Inbox When Ready, which hides your inbox by default and prevents you from being attention-sniped.\\n\\n\\n - Groceries /\\u200b other mundane things\\n - No Wealthfront—no reason for me to see how my portfolio is doing.\\n\\n\\nThat’s it. No music (see appendix), no messaging, no Facebook, no Twitter, no Slack, no Discord, no anxious email checking, no Youtube, no nothing. I even bought a cheap watch so that I wouldn’t have to check my phone for the time. If I needed an exception, I’d first write a note explaining what I did, to be read by my girlfriend, Emma, who started her declutter soon after.\\nWhy did I choose these rules? I won’t get unhealthily sucked into any of these activities. They all make me stronger. They let me do my work.\\nThe world was not going to end because I stopped reading the news for a month—I understand there’s a war still going on in Ukraine, but that’s about all I know, and I’m not worse off for it. I resolved that if I wanted to build models of that part of the world, I’d do that on purpose. I won’t doomscroll through hyper-optimized interfaces designed to scam me out of my attention and make me anxious. I said to myself, my life is worth more to me than that.\\n**FAQ**\\n> But TurnTrout, my job needs email /\\u200b [other special reason why this doesn’t work for me].\\nI concede that my rules are probably not best for your situation. But have you thought about the issue for five minutes? Could you ask your boss if you can check email once a day and otherwise take phone calls? Maybe you don’t restrict email, but stop looking at websites like Reddit or Hacker News or Marginal Revolution or Facebook or Twitter? Are there other creative solutions waiting to be uncovered? Have you tried?\\nIf your team uses Slack for asynchronous communication, once- or twice-daily checks should be fine. If you use it for synchronous communication, perhaps establish a daily \"office hour\" when you’ll be on Slack, or even coordinate with your team to establish a daily \"Slack hour\" where people are expected to be online. Or something else. The point is to establish the main benefits you reap from each digital affordance, and then find a plan which minimizes the costs you pay for those benefits.\\n> I’m already good about my internet usage.\\nThis might be true! I know exactly one person for whom I’m quite confident this is true (Andrew Critch), and maybe there are more among my friends whom I don’t know about. This might be you if you already use services based on their costs and benefits, often using websites in unintended ways (like blocking all recommendations on YouTube via the Unhook add-on [Chrome, Firefox]), and spending far less time than average (eg only checking email very infrequently).\\nI’d still bet against it. I would have said I was good about my internet usage, and it *was* true—in a relative sense. I think people (motivatedly) underestimate how much time they waste, perhaps because it can feel bad and embarrassing to admit the problem.\\n> But how will I stay in touch with people? I’m already lonely.\\nExcellent question! Reallocate low-quality social time to high-quality social time. Instead of checking if some half-friends liked your FB status, call up a buddy and grab a beer, or go to a meetup, or join a club.\\n# Benefits of the declutter\\n*February 22nd: The First Day.* I went running, and got back to the house 10 minutes earlier than usual. Huh.\\nI called my parents and went on a leisurely walk. Even so, I got my morning routine done 60 minutes ahead of schedule. I read half of a book on ordinary differential equations while lounging in my sunlit room. I did some deep thinking for an hour, safe from my phone’s dopaminergic temptation. I switched contexts and read about electrostatics. Still hours ahead of schedule.\\nThe day yawned and stretched. I wondered if it would ever end. (It did.)\\n*February 23rd: The Second Day.* From my journal:\\n> It’s so relaxing not using my phone, and yet I can still feel my anxiety pulling me to my digital affairs.\\nDid my LW post get lots of upvotes? Are people criticizing me? Did I win a prize in the contest? Am I missing something on the EliezerFic server? I even thought about some identity-politics tweet I saw last week, on my run this morning… why is that garbage in my head? Good riddance.\\nAnd so unrolled the next day, and the next. Time laid itself out before me. With my reclaimed time, I went on walks, I read *The Character of Physical Law*, I read ~three physics textbooks, I tripled my daily Anki workload to 1.5 hours, and I *still had time left over*.\\nLife became leisurely. I wrote letters to my girlfriends—some of them were in French. I even had time to write *poems*. I talked to them more often than before, with nightly phone calls. I also called my family most mornings. *I still had time left over*.\\nInstead of trolling through Discord, I called some labmates at Oregon State and started a weekly dinner. If anything, I felt less lonely than before, when I had the world at my fingertips. I called people when I wanted to talk to them. *I still had time left over.*\\nI listened to a Stephen King book when I couldn’t sleep—I found it reassuring to worry about fortifying a grocery store against eldritch horrors, instead of worrying about fortifying our planet against artificial intelligence. I listened to Dune with Emma, clocking 21 hours over 2.5 weeks. I went on walks with her, and to a hot tub, and I *still had time left over*.\\nI did notice potential withdrawal symptoms (alarming!), mostly via increased baseline anxiety. Other explanations include \"defending my dissertation & moving soon\", so I’m not sure if it was from the declutter.\\nEven assuming this month gave me unusually large benefits, I wouldn’t ever, ever go back. So when the declutter ended, I wasn’t clamoring to check the highest-karma Reddit posts from last month. I still feel the urge, but I resent Reddit now that I see what it takes away from me. That makes it easier to stay away.\\n# Recommendations\\nThis short post may not be convincing enough to try out such a substantial life modification. I’m not asking that you do a declutter right away. I’m recommending that you read the first half of *Digital Minimalism**,* or listen on Audible (cost: a few hours and $14).\\nLet me sweeten the deal with a costly signal. If I’ve met you in real life, and you consume the first half of the book and find it unconvincing /\\u200b try the declutter and it wasn’t at all worth trying in hindsight, message me on LessWrong and I’ll pay you $30.[3]\\nI think many, many people are shooting themselves in the foot, so I will be blunt. *Please stop shooting yourself in the foot.* Please do a cost-benefit analysis. I think many people have serious, serious problems with their internet usage. I did. You might. If so, you are leaving a lot of your life on the table.\\n*Thanks to Meg Tong, Josh Turner, and Kurt Brown for feedback on this post.*\\n# Appendix 1: Declutter advice\\nHere’s my main tip to add to the book: *Have well-defined exception handling which you never ever ever have to deviate from.* When I read about how other people navigated the declutter, their main failure modes looked like \"my dog died and I got really stressed and gave in\" or \"a work emergency came up and I bent my rules and then broke my rules fragrantly.\"\\nPlan for these events. Plan for feeling withdrawal symptoms. Plan for it seeming *so so important* that you check your email* right now*. Plan for emergencies. Plan a way to handle surprising exceptions to your rules. Make the exception handling so good that you never have a legitimate reason to deviate from it.\\nMy procedure was \"If I need to use a forbidden functionality, then I have to write what I did down on a slip of paper and leave it on my girlfriend’s desk ASAP.\" This worked because Emma would understand legitimate exceptions, but would look askance at me if I started flooding her desk with \"and then I checked Reddit\" notes. It’s easier to hold promises to other people, than promises to yourself.\\n# Appendix 2: My post-declutter rules\\n\\n - I only listen to music when:\\n - Only listening to the music, to fully soak it in\\n\\n - Exercising\\n\\n - Reasoning on this point:\\n - I think music generally makes me subtly dumber but feel cooler while I’m listening to it, so I listen to it a lot.\\n\\n - Music imposes its own form on my thoughts. My thinking and mood becomes governed by the song which happens to be playing, and less by the substance of my own thoughts. I don’t want my reasoning to hinge on \"will Spotify shuffle to *Attack on Titan* or *Coldplay* next?\".\\n\\n - See also Gwern’s stub.\\n\\n - I do have Google Home, and often play nature sounds.\\n\\n\\n\\n - I only check LessWrong /\\u200b Discord /\\u200b Slack /\\u200b Messenger /\\u200b my text messages each Sunday at noon.\\n - I write blogposts before then, and I won’t check their reception until the next week (I used to nervously refresh).\\n\\n - I’ve also adblocked the karma elements of the website, because I worry too much about them.\\n\\n\\n - As I currently see it, I’m only logging in to the newsfeed part of Facebook two more times: To share this blog post, and after I receive my PhD.\\n - After that, I’ll check its event page weekly, while blocking the notifications /\\u200b other clutter FB tries to throw at me. This should take less than 10 minutes each week.\\n\\n - Here’s how to use FB more peacefully:\\n - Install FBPurity; you can save time by importing my settings here.\\n\\n - Use UBlock Origin to get rid of the rest; here is my element blocking list for Facebook.\\n - (I also hide the chat sidebar on the main page, which is a FB option)\\n\\n\\n\\n - I could also check a favorite page once a week (with the chat and comment elements blocked), if I need more memes in my bloodstream.\\n\\n - In combination with a monthly Messenger checkin, I’ve extracted my main benefits from Facebook, at a cost of at most 50 minutes each month, instead of 50 minutes each day!\\n - Again, I ***don’t recommend***** **doing small fixes like \"just hide some FB elements.\" These fixes **don’t work** for most people. This advice is aimed at post-declutter usage, which unfolds from your informed cost-benefit analysis.\\n\\n\\nHere’s what my FB news feed looks like now. 😌\\n - For news, I purchased a digital+print subscription to *The Economist*. Once a month, I can choose to read the four issues for an hour or two.\\n - I don’t need to read more than that. I can read about candidates before an election, and there isn’t much else that’s decision-relevant. If eg AI dynamics heat up and geopolitical understanding becomes more important, I’ll tackle that deliberately.\\n\\n - Looking back at my life, I see how often I’ve been hijacked by news websites. It makes me sick.\\n\\n\\n - I’m basically not going to text anymore. I used to check it so, so often.\\n - This was hard at first. One of my partners strongly prefers texting, and I liked texting her, and missed her a lot. With additional thought, we discovered that she really just wanted to asynchronously send me updates on how her day was going. I said she could text me as much as she wanted—but I’d read them during our next phone call.\\n\\n\\n - I can watch movies and play video games if I’ve planned it out at least a few hours in advance.\\n\\n - I can check Reddit for specific question/\\u200banswer threads.\\n\\n - I can check Twitter if I plan the session out in detail one day in advance.\\n - Twitter is toxic for me, even though I originally made an account to promote an alignment paper and only subscribed to AI/\\u200bmath accounts.\\n\\n\\n - My phone will still be in black and white and warm color temperature, to make it even less engaging compared to the rest of my world.\\n\\n - I *never ever use my phone on the toilet. Ever.* This has served me well and seems like a pure win.\\n\\n - ^This is only a sufficient condition; the app need not be the child of a billion-dollar company. For example, I oft ragebaited myself about the culture war via *Marginal Revolution* and *Hacker News*. I even tend to get anxious about *LessWrong* usage, and I know that the team deliberately refrained from attention-hacks like red notifications.\\nEven while using my Notion to edit this post and supervise research, I saw a red \"5 notifications\" marker, which gave me an overwhelming urge to *see what the notifications are*. With great effort, I ignored the impulse, and deleted the element with my adblocker.\\n\\n\\n - ^I just now picked up my phone and stared at it blankly. One month later. Yuck.\\n\\n\\n - ^Limit $300 total.\\n\\n',\n",
              "  'title': 'Do a cost-benefit analysis of your technology usage\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage',\n",
              "  'votes': '86'},\n",
              " {'authors': 'TurnTrout',\n",
              "  'comments': [{'authors': 'Space L Clottey',\n",
              "    'comments': [{'authors': 'Space L Clottey',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-02T09:30',\n",
              "      'id': 'axWHpFKjemHP8WaSk',\n",
              "      'omega_karma': '',\n",
              "      'score': '10',\n",
              "      'text': 'Actually, I want to walk back on this a bit. I was on a plane since this comment and the ten hours of no wifi was really nice and really unique and really focused, and I had absolutely no reason to check my phone because there was absolutely zero chance of their being a notification… I realised that I appreciated digital minimalism at the time because I had just come out of having no wifi forced apon me for a week and finding it really nice and really wanting to maintain it. I think I’ve just forgotten how nice it actually is\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=axWHpFKjemHP8WaSk',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'Tom Lieberum',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-31T09:27',\n",
              "      'id': 'CNuQEK84kCC793Fmr',\n",
              "      'omega_karma': '',\n",
              "      'score': '6',\n",
              "      'text': 'I want to second your first point. Texting frequently with significant others lets me feel be part of their life and vice versa which a weekly call does not accomplish, partly because it is weekly and partly because I am pretty averse to calls. \\nIn one relationship I had, this led to significant misery on my part because my partner was pretty strict on their phone usage, batching messages for the mornings and evenings. For my current primary relationship, I’m convinced that the frequent texting is what kept it alive while being long-distance. \\nTo reconcile the two viewpoints, I think it is still true that superficial relationships via social media likes or retweets are not worth that much if they are all there is to the relationship. But direct text messages are a significant improvement on that. \\nRe your blog post:Maybe that’s me being introverted but there are probably significant differences in whether people feel comfortable/\\u200blike texting or calling. For me, the instantaneousness of calling makes it much more stressful, and I do have a problem with people generalizing either way that one way to interact over distances is superior *in general*. I do cede the point that calling is of course much higher bandwidth, but it also requires more time commitment and coordination. \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CNuQEK84kCC793Fmr',\n",
              "      'votes': '5'},\n",
              "     {'authors': 'TurnTrout',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-03T16:49',\n",
              "      'id': 'ybvZBPx37dCv9k563',\n",
              "      'omega_karma': '',\n",
              "      'score': '4',\n",
              "      'text': 'I don’t remember at this point what digital minimalism advocates, but *I *advocate doing cost-benefit analyses, which are naturally sensitive to the specifics of your situation. The question may become: How can I draw most of the benefits of texting, without checking my phone 40 times a day? \\nAnd I think this question has meaningful answers, from batching responses eg thrice daily, to dedicated synchronous texting periods (like text-based phone calls!).\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=ybvZBPx37dCv9k563',\n",
              "      'votes': '3'}],\n",
              "    'date_published': '2022-03-28T11:13',\n",
              "    'id': 'EfjznyXLDTPyaqTQj',\n",
              "    'omega_karma': '',\n",
              "    'score': '22',\n",
              "    'text': 'I really really enjoyed digital minimalism when I read it, but think it was somewhat harmful to my relationships, given how hard it says that only text-relationships are basically worthless. It took like a year but I happened to meet someone really cool who strongly didn’t like calling and since the only way I could talk to them was texting, I sucked it up and actually found out that it’s not so bad.\\nI think it did help me firm up the things I dislike about texting, and with some agreed about norms I think they can be mitigated. Wrote about it here: Why call? | Space L Clottey (spacelutt.com)\\nThis post did A LOT for me in terms of my phone usage:\\nDistractions are a Nuisance, but Infinity Pools are the Real Problem | by John Zeratsky | Make Time | Medium\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=EfjznyXLDTPyaqTQj',\n",
              "    'votes': '13'},\n",
              "   {'authors': 'aphyer',\n",
              "    'comments': [{'authors': 'Rana Dexsin',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-30T06:00',\n",
              "      'id': 'gZzovr2FojRr8dnLt',\n",
              "      'omega_karma': '',\n",
              "      'score': '8',\n",
              "      'text': 'That in turn is actually dependent on whether having your ambient thoughts occupied by YouTube is better *overall* than having them occupied by nothing for a while. There’s a lot of valuable background processing that I suspect gets starved by constant stimulation. Of course, carving out explicit time for reflection or for a meditation practice or similar is also something one can do.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=gZzovr2FojRr8dnLt',\n",
              "      'votes': '6'},\n",
              "     {'authors': 'TurnTrout',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-03T16:57',\n",
              "      'id': 'F4axmENXiqpp7sfdN',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Pushback against (what seems to me like) an implicit assumption: In all probability, you are not evenly and strategically trading off \"bored time\" for \"entertained time.\" You are trading off huge chunks of your non-bored time, not because you lack virtue, but because Youtube \"wants\" to waste your time. So this is, I think, a dangerous trade to try to make, at least without analyzing it first.\\n> But if this time trades off against *staring at the ceiling being bored*, then Youtube is making my unproductive relaxation time more enjoyable and entertaining, and there is no problem.\\nIs there no problem? Sometimes being \"bored\" lets me focus on what it feels like to be a person, or feel grateful about my life, or just let my thoughts drift. This is pleasant, just like the quoted memory of staring at the ceiling. The sentiment was not \"FML, my boring life sucks\", but rather \"-------- [relaxation].\"\\nI also used to have thoughts race through my head when I turned in for the night, as if some great dam had broken, now that no distractions were occupying my attention. That *seems* to happen less now. Which, in turn, seems good.\\nAnyways—empirically, I have not spend much time bored. So the point seems moot, in that I am not advocating increased \"bored\" time, but reallocation. \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=F4axmENXiqpp7sfdN',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T17:00',\n",
              "    'id': 't8sdiWQbqfdc6jquG',\n",
              "    'omega_karma': '',\n",
              "    'score': '15',\n",
              "    'text': '> I remember lazy summer childhoods, staring at the ceiling after I ran out of video game time. \\nI think this argument points in the opposite direction from your main post. The most salient question for ‘spend less time messing around on the Internet’ is ‘what will that saved time end up being spent on?’\\nSometimes I watch cute Youtube video compilations of pets doing silly things.  \\nIf this time trades off against writing a novel, or learning an interesting skill, or making friends, or exercising, then Youtube is wasting my time on unproductive things and I should try to waste less time.\\nBut if this time trades off against *staring at the ceiling being bored*, then Youtube is making my unproductive relaxation time more enjoyable and entertaining, and there is no problem.\\n(Relevant xkcd).\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=t8sdiWQbqfdc6jquG',\n",
              "    'votes': '14'},\n",
              "   {'authors': 'DanielFilan',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'DanielFilan',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-05-03T18:35',\n",
              "        'id': 'LdzxNwzpmQwqKgQuX',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'Have PM-ed.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=LdzxNwzpmQwqKgQuX',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-05-03T02:21',\n",
              "      'id': 'CZ7LDxP923HRdaHfw',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': 'Strong-upvoted, even though I disagree on the overall argument strength (I think there were some weak arguments but in total the evidence seemed pretty good to me). I look forward to paying out if you want to collect on that.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CZ7LDxP923HRdaHfw',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-04-25T21:59',\n",
              "    'id': 'f5p9eHcTE5LrmWPQv',\n",
              "    'omega_karma': '',\n",
              "    'score': '13',\n",
              "    'text': 'For what it’s worth, I have met TurnTrout in real life, use social media, and was initially skeptical about the Digital Minimalism thesis. After reading this post, and having had it recommended to me by another friend, I read the first half of Digital Minimalism. I found it basically unconvincing. In particular, it seemed like chapter 1 was supposed to provide motivation for why social media was bad for me, but didn’t really deliver—I didn’t think the evidence given distiguished \"social media is designed to be addictive\" with \"social media is designed to be valuable and usable\". For instance, it seems to interpret social media tools that let you interact with your friends in ways that have significance for your relationship (e.g. tagging them in pictures) as a way to addict people, but it seems to me that that’s just a nice feature. In some places it seemed sort of obtuse—the author talks about how the ostensive benefit of FB is letting you see things like friends’ baby pictures, and claims that the like button increases addictiveness but doesn’t help deliver the ostensive benefit. But it seems obvious to me that seeing which posts are ‘liked’ would help FB distinguish between pictures that people want to see (babies, engagement photos) and pictures that they don’t (poorly-lit food photos, boring party pictures).\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=f5p9eHcTE5LrmWPQv',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'Logan Riggs',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'Logan Riggs',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-04T18:32',\n",
              "        'id': 'BrMDCgkbqLTBrZpLX',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'I’m unsure about this now. I think there may generally be way better ways to cope (eg sleeping, walks, reading a book, hanging with friends). \\nA different thought: Clarifying the core thing you don’t like about having media always on (maybe the compulsion that leads to distractedness) may make your idea easier to communicate and look different in actions/\\u200bplans produced. Like I’m fine with watching a movie with a friend or playing a video game with my roommate for an hour. \\nA slightly different thought: setting alarms on my phone if I’m looking at my phone for the time because I have a meeting, or I’m waiting on someone to message me timely information has been helpful. I can set a timer for an hour and check my phone then in case they’ve messaged. Or set the timer 5 minutes before my meeting, so I don’t have to think about it.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=BrMDCgkbqLTBrZpLX',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T17:18',\n",
              "      'id': 'gvpG4DS6yu75KiXQc',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': '(I think everyone should have well-defined exception handling, because some of you *will *have crazy shit happen, like \"someone died\", and that *can *make it hard if you’re pondering \"do I let myself have an allowance now?\". Failing to plan is planning to fail (in not-wholly-improbable worlds).)\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=gvpG4DS6yu75KiXQc',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-29T02:48',\n",
              "    'id': 'AdAndSGrXv963uEyd',\n",
              "    'omega_karma': '',\n",
              "    'score': '10',\n",
              "    'text': 'Sure, I’ll do it as well. For me: \\n\\n - 1pm—Check snaps, messages, emails, discord team messages and accelerating alignment channel, & EAGx messages. Hard limit at 1:30pm (just set two alarms on my phone)\\n\\n - Whitelist—Roam/\\u200b research related searches. Phone calls/\\u200b texts are unblocked from a certain set of people, who I’ve told can reach me there. (I set them in the emergency contact list), but besides that, my iPhone is in \"focus mode\" with all notifications hidden. \\n\\n - Exception handling: I don’t think I’ll need one, but I can let my roommate know and ask for his social support. (Specifically call me out if he sees me on my phone at other times, haha)\\n\\n - I normally journal, so that’ll help with logging. \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=AdAndSGrXv963uEyd',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Heron',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-31T19:19',\n",
              "    'id': 'F3Ho4ukj2nEmxwnDB',\n",
              "    'omega_karma': '',\n",
              "    'score': '9',\n",
              "    'text': 'Thanks for reminding me of my small concern: time-wasting, specifically doom-scrolling on Twitter. I will listen to the book!\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=F3Ho4ukj2nEmxwnDB',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'niplav',\n",
              "    'comments': [{'authors': 'Ben Pace',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T19:48',\n",
              "      'id': '7giz4ArjW7X23PqQ7',\n",
              "      'omega_karma': '',\n",
              "      'score': '5',\n",
              "      'text': '> I have an additional pet peeve about this post: It has the words \"cost-benefit analysis\" in the title, but doesn’t have a cost-benefit analysis in the body (at least not of the juicy expected-value variety)!\\nOh yeah, I feel like a more natural title would be \"PLEASE DO SOME ACTUAL EMPIRICISM\".\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=7giz4ArjW7X23PqQ7',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'niplav',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-06T13:20',\n",
              "        'id': 'SxJqf8mzZPAworJY2',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': '> I have noticed increased anxiety in myself. I think it quite possible I already had most of it before the declutter, and instead wrapped myself in comforting mind-numbing internet usage which obscured it from me. Another person who has done the declutter, reported similar suspicions about themselves.\\n\\n\\nA psyche might start\\ncutting itself, if it is\\nnot dulled each fortnight',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=SxJqf8mzZPAworJY2',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T17:09',\n",
              "      'id': 'SgBPffRmTxKN4cd6j',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': '> I also have experienced increased anxiety, which has persisted (and become slightly stronger) 7.5 months after moving.\\nI have noticed increased anxiety in myself. I think it quite possible I already had most of it before the declutter, and instead wrapped myself in comforting mind-numbing internet usage which obscured it from me. Another person who has done the declutter, reported similar suspicions about themselves.\\n> This has some interesting implications: The worse the problem of wasting time on the internet is for you, the harsher your measures will need to be, and the less you will want to carry them out (except in lucid moments).\\nThis doesn’t ring to my experience. Everything became easier when I said \"*No *reddit\", as opposed to ~\"Reddit if I can find a good enough reason.\" \\n> I have an additional pet peeve about this post: It has the words \"cost-benefit analysis\" in the title, but doesn’t have a cost-benefit analysis in the body (at least not of the juicy expected-value variety)!\\nPlease don’t use those words if you’re not going to deliver ;-)\\nI included eg the Facebook usage meme (which is the real output of a CB analysis), and described the results of other analyses I did. I think the analyses were so lopsided, and the solutions so clean, that assigning numbers would be a distraction. Also, the point of assigning numbers to personal-utility-estimates is, I think, to throw them out after you do the estimate, and do what your updated gut feeling says.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=SgBPffRmTxKN4cd6j',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-29T08:45',\n",
              "    'id': 'dyHjRsrF9BaaFFeoY',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': 'So, I haven’t read Digital Minimalism, but I have been becoming increasingly worried about attention-grabbing systems over the last ~2 years, culminating in me choosing not to have internet at my apartment when I moved last May (getting internet at a local library, with a ~15 minute walk there by foot), after having iterated through many versions of locks & blocks & deleted elements, all pretty much fruitless in the end.\\n\\nSo, yeah, I think already pretty good about my internet usage.\\n\\nThis has resulted in interesting dynamics: I often procrastinate by reading through my downloaded copy of wikipedia, or by weightlifting (!), when I don’t want to do work. I am also much more vulnerable to overindulging when I’m at a place with internet, e.g. when I’m visiting my parents.\\n\\nI have some predictions about your experiment:\\n\\n\\n - You will continue in your current decluttered mode (70%)\\n\\n - You will temporarily fall back into bad habits (50%)\\n\\n - You will make it stricter after some while (60%)\\n\\n\\n\\n - Your initial productivity benefits will experience a regression toward the mean (80%)\\n\\n - The (perceived) benefits will continue outweighting the (perceived) costs (90%)\\n\\n\\n\\n - You will find yourself procrastinating in odd and novel ways, such as reading a lot of fiction, or exercising, or snacking a lot, or reading Wikipedia a lot (40%)\\n\\nI also have experienced increased anxiety, which has persisted (and become slightly stronger) 7.5 months after moving.\\n\\nI don’t necessarily recommend such extreme measures to everyone, but I have the lurking suspicion that people tend to underreact to time & attention lost.\\n\\nI’m unhappy that picoeconomics hasn’t been further investigated on LessWrong, because, aside from the term being very cute, trying to balance the costs of accessing different resources that may be harmful in too large or small quantities seems pretty central to the endeavour of managing (if not defeating) akrasia.\\n\\nA hypothesis could be that while human System 2 does exponential discounting, System 1 performs hyperbolic discounting, and we’d like to increase the cost of accessing e.g. internet services so that for that cost, our hyperbolically discounted value is smaller than the exponentially discounted value (ideas like this being central to picoecon).\\n\\nUnder this model, for myself, the time to remove ublock from my browser addons (or simply install another browser, etc.), which would take around half a minute, the hyperbolically discounted present value was not less than the exponentially discounted value, but the 15 minutes of going to the nearest library (or buying a router and installing it, or paying an additional 10€ for more mobile data (so here, expensive mobile data plans are *better*) *would be*, so I don’t do it.\\n\\nThis has some interesting implications: The worse the problem of wasting time on the internet is for you, the harsher your measures will need to be, and the less you will want to carry them out (except in lucid moments).\\n\\nI have an additional pet peeve about this post: It has the words \"cost-benefit analysis\" in the title, but doesn’t have a cost-benefit analysis in the body (at least not of the juicy expected-value variety)!\\n\\nPlease don’t use those words if you’re not going to deliver ;-)\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=dyHjRsrF9BaaFFeoY',\n",
              "    'votes': '5'},\n",
              "   {'authors': 'noggin-scratcher',\n",
              "    'comments': [{'authors': 'Yitz',\n",
              "      'comments': [{'authors': 'Elizabeth',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-29T01:46',\n",
              "        'id': 'P5AyoJKCBDd2CzqPB',\n",
              "        'omega_karma': '',\n",
              "        'score': '11',\n",
              "        'text': 'I checked out a bunch and chose inoreader, although I needed to pay to get all the features I wanted.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=P5AyoJKCBDd2CzqPB',\n",
              "        'votes': '5'},\n",
              "       {'authors': 'noggin-scratcher',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-29T23:40',\n",
              "        'id': '4D8pGA5icQgDEcKMn',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'I’m using Inoreader, paying for the \"Pro\" tier of features.\\n\\nI’m getting particular use out of their duplicate filters, regex-based content filters, receiving newsletters as a feed, and automated scraping/\\u200bmonitoring of sites that don’t publish their own feed.\\n\\nHave also used the custom CSS option to productively disagree with some of the choices made when they re-designed the interface. But I think that’s available on the cheaper \"Supporter\" tier too.\\n\\nThere has in the past been a \"buy 18 months for the price of 12\" discount available at least annually (around Black Friday possibly; might have been New Years). Which I’ve used to keep the cost down.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=4D8pGA5icQgDEcKMn',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-03-29T01:44',\n",
              "      'id': 'AwTC5qWZG9CNAwd3n',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'May I ask what software you use for your RSS aggregator?\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=AwTC5qWZG9CNAwd3n',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T10:51',\n",
              "    'id': 'bGxGzJ5KyqhJ7iHTP',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': 'My personal antidote to the \"check lesswrong. check mad investor chaos. work 5 mins. check mad investor chaos. check lesswrong\" problem has been to channel everything I possibly can into an RSS aggregator. No need for *me* to be twitchily refreshing and checking; I have a computer to do that for me.\\nAlso helps, I think, that I’m then removed from the algorithmically-mediated Skinner box of someone else deciding what my news feed is. I just get a simple chronological list of headlines from sites I’ve chosen—nothing that’s being shared or promoted or trending or whatever, and with my own defined rules/\\u200bfilters to remove categories of post I’m not interested in seeing. Also no fear of missing out, because my unread items will still be there later whenever I come back for them.\\nStill occasionally has the problem of turning into an attention-suck by way of being subscribed to too many things, or to sites that produce too many updates. Still need to be alert to whether individual sites are a true benefit to be subscribed to. Still need to keep a lid on feed-reading from consuming all of my time. \\nSo it’s not a solution to \"I read *too much* internet\", but I think it’s at least an improvement over other *ways* of reading the internet.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=bGxGzJ5KyqhJ7iHTP',\n",
              "    'votes': '6'},\n",
              "   {'authors': 'TekhneMakre',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'TekhneMakre',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-04T02:55',\n",
              "        'id': 'kRepe7Mk45Bh9qyPn',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': '\"participation in networks\"? IDK. Is \"social media\" too narrow? I intuitively include LW, blogs, forums, email, as social media. Youtube is a mix; I consider it social media when I’m using it as pica for talking to a person, and I endorse most of my other Youtube use (e.g. videos of natural phenomena, or documentaries, or clever inventions). But yeah I could imagine being seriously attention-sniped in some other unendorsed way.\\n\"attention service usage\"? \"consumption service usage\"? That’s not really clear, though it does have a precise meaning that I think is what you’re trying to point at: services (i.e. computer programs running somewhere else that do some computing task for you) which are attention /\\u200b consumption based (i.e. the thing you’re getting from the service is something you’re going to just directly experience, as opposed to running it through some more computation). Services which are attention-based seem like the central type of technology that induces attention-sniping incentives. (Though it’s not sufficient, e.g. Wikipedia.)\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=kRepe7Mk45Bh9qyPn',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T16:58',\n",
              "      'id': 'w7MYRmHT74vj462k4',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Originally titled \"Do a cost-benefit analysis of your internet usage\", but this makes it sounds like analyzing different internet service provider plans. \"Social media usage\" is too narrow. I’m open to suggestions.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=w7MYRmHT74vj462k4',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T10:32',\n",
              "    'id': 'M7ahy9G4PcT9gwEQG',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': 'Acknowledging that this is how people generally use the word \"technology\", I’d rather reserve that word for things that are involved in tekhne, i.e. tools, machines, devices, programs, components, factories, methods, etc.; things one uses to produce. I think you’re centrally talking about networks and services. Richard M Stallman calls them \"disservices\", as in \"Facebook provides an online social networking disservice\". That it’s even possible to seemingly unwillingly more or less ruin oneself using a thing, is evidence that one isn’t centrally relating to the thing as a technology at all.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=M7ahy9G4PcT9gwEQG',\n",
              "    'votes': '6'},\n",
              "   {'authors': 'Ben Pace',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T19:18',\n",
              "    'id': 'PSgCiQSiKEL9HqpS5',\n",
              "    'omega_karma': '',\n",
              "    'score': '7',\n",
              "    'text': '> When was the last time you were bored and in silence?\\nFor the record, it was 2 days ago.\\n> like blocking all recommendations on YouTube via the Unhook add-on [Chrome, Firefox]\\nWoah — you just gave me agency over YouTube! Thanks so much, this is looking like it will really change my relationship with the site to be much more intentional (e.g. I like how it makes it so I can default to only seeing my subscriptions).\\n> Here’s my main tip to add to the book: *Have well-defined exception handling which you never ever ever have to deviate from… *My procedure was \"If I need to use a forbidden functionality, then I have to write what I did down on a slip of paper and leave it on my girlfriend’s desk ASAP.\"\\nWhen I did 2 weeks of no devices, my procedure (which I remember telling you in a LW PM like 6 months ago) was \"you can do a thing on your device if you wrote it down on a piece of paper yesterday\". That worked well for me while I was in more of a vacation mode.\\n> I write blogposts before then, and I won’t check their reception until the next week (I used to nervously refresh).\\nVery cool to hear you that you do this! Congratulations. For me I don’t check until 24 hours have passed, and never do refreshes. I do like responding to comments faster than 1 week. But yeah, the repeated refresh while your post has no karma and one unhelpful comment is not worth it.\\n> For news, I purchased a digital+print subscription to *The Economist*. Once a month, I can choose to read the four issues for an hour or two.\\nThe one I’ve been meaning to move to is, once a month, check the top-voted stories on HN that month.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=PSgCiQSiKEL9HqpS5',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'Jack R',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'Jack R',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-04T06:52',\n",
              "        'id': 'CJZqhoPKuyLMHvkdM',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': 'Ah — sorry if I missed that in the post, only skimmed\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CJZqhoPKuyLMHvkdM',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-04-03T17:15',\n",
              "      'id': 'pBhAAsHvFinuShc8P',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Yup, this is what I did, but I just didn’t have the notebook. I like the bright line.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=pBhAAsHvFinuShc8P',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-29T08:39',\n",
              "    'id': 'PrFBSgKyaK68w6bot',\n",
              "    'omega_karma': '',\n",
              "    'score': '7',\n",
              "    'text': 'Random tip: If you want to restrict apps etc on your iPhone but not know the Screen Time pin, I recommend the following simple system which allows you to not know the password but unlock restrictions easily when needed:\\n\\n - Ask a friend to write a 4 digit pin in a small note book (which is dedicated only for this pin)\\n\\n - Ask them to punch in the pin to your phone when setting the Screen Time password\\n\\n - Keep the notebook in your backpack and never look inside of it, ever\\n\\n - If you ever need your phone unlocked, you can walk up to someone, even a stranger, show them the notebook and ask them to punch in the pin to your phone\\nThe system works because having a dedicated physical object that you commit to never look inside is surprisingly doable, for some reason.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=PrFBSgKyaK68w6bot',\n",
              "    'votes': '5'},\n",
              "   {'authors': 'Trevor1',\n",
              "    'comments': [{'authors': 'hath',\n",
              "      'comments': [{'authors': 'matto',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-29T12:59',\n",
              "        'id': 'YckCweuMjegiSgNrb',\n",
              "        'omega_karma': '',\n",
              "        'score': '3',\n",
              "        'text': 'Postman is a great writer and this is one my favorite books.\\nWhat’s changed between 1985 and today is that human attention has become the scarcest (ie. most valuable) resource. Because of this, the Web is under immense market pressure to turn into a perfected form of cable TV as described by Postman. This is what’s driving platform centralization (ie. Facebook, TikTok, etc.) as well as the one-to-many model where a handful of users (influencers) produce while a great majority merely consume.\\nWe’re not there yet, but we’ve swung strongly in that direction in just a decade with change. My hope is that counter-forces like *Digital Minimalism* as well as the inherent flexibility of the medium of the Web will arrest or even revert this change.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=YckCweuMjegiSgNrb',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-03-29T02:06',\n",
              "      'id': 'ajcqEaE6AJzC6Lsim',\n",
              "      'omega_karma': '',\n",
              "      'score': '9',\n",
              "      'text': 'A book I highly enjoyed on the topic was Neil Postman’s Amusing Ourselves to Death, which was Neil Postman mourning the death of rational discourse from TV in the year 1985. Very highly reccomend.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=ajcqEaE6AJzC6Lsim',\n",
              "      'votes': '4'},\n",
              "     {'authors': 'Logan Riggs',\n",
              "      'comments': [{'authors': 'TurnTrout',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-04-03T17:14',\n",
              "        'id': 'eGhxZAuXY7SonWiGx',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': ':)\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=eGhxZAuXY7SonWiGx',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-03-29T02:06',\n",
              "      'id': 'DGzNYC4i8xCBdc5MJ',\n",
              "      'omega_karma': '',\n",
              "      'score': '6',\n",
              "      'text': 'I think reading the book and/\\u200bor trying it yourself would be very informative. You have at least until next Sunday when he reads this comment or potentially writes more.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=DGzNYC4i8xCBdc5MJ',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'mingyuan',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T18:50',\n",
              "      'id': 'HZ6zvLCS98k7yL97B',\n",
              "      'omega_karma': '',\n",
              "      'score': '4',\n",
              "      'text': 'You should message Kurt, who’s mentioned in the post as TurnTrout’s inspiration for doing this in the first place. Sounds like TurnTrout isn’t going to be online/\\u200bmessaging much in the near future :)\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=HZ6zvLCS98k7yL97B',\n",
              "      'votes': '2'}],\n",
              "    'date_published': '2022-03-28T14:02',\n",
              "    'id': '4JEFwRkmZQhxgdB4o',\n",
              "    'omega_karma': '',\n",
              "    'score': '5',\n",
              "    'text': 'Please, please, please make more posts on this issue. I really like what I see here, I’ve found it very helpful, and I need to see more. \\nPlease message me on your thoughts if you ever have anything you’d like to share about this problem, e.g. what works, what doesn’t work, what seems to happen to people, etc.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=4JEFwRkmZQhxgdB4o',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'JonathanMoregard',\n",
              "    'comments': [{'authors': 'Valentine',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-31T15:29',\n",
              "      'id': 'rxFarMyfWdRuZdJwJ',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'That’s native to Facebook now, actually. I don’t remember where, but if you dig around in the settings you can turn off notifications for reactions/\\u200blikes.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=rxFarMyfWdRuZdJwJ',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T11:10',\n",
              "    'id': 'owrLHZ5moA3KN5KCM',\n",
              "    'omega_karma': '',\n",
              "    'score': '5',\n",
              "    'text': 'Does anyone know about an addon to filter facebook notifications? I want to know about comments, but not reactions/\\u200blikes\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=owrLHZ5moA3KN5KCM',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'TurnTrout',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-04-03T17:21',\n",
              "    'id': '7qub738wxkxHB3wZG',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'Update: I had a few relatively anxious days, and decided to relax my music policy slightly. Sometimes I’d be a little too anxious to do work without music. While I fix this problem, I’m going to listen to music more permissively.\\nI think there’s another trade-off to music while working, which is that it makes me more *excited *at the cost of making me *slightly dumber*. Sometimes this is worth it. Marking as something to analyze more later, as I currently (attempt to) refactor my internal systems so that they don’t produce these anxious signals.\\nAlso, added to main post: \"I *never ever use my phone on the toilet. Ever.* This has served me well and seems like a pure win.\"\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=7qub738wxkxHB3wZG',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'ike',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [{'authors': 'ike',\n",
              "        'comments': [{'authors': 'TurnTrout',\n",
              "          'comments': [],\n",
              "          'date_published': '2022-04-17T17:27',\n",
              "          'id': 'XTRptRgA7RychPeKi',\n",
              "          'omega_karma': '',\n",
              "          'score': '2',\n",
              "          'text': 'Yay! Keep up the good work :) I bet there’s a way to stick to it better, I’d advise you to keep trying things on that front.\\n',\n",
              "          'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=XTRptRgA7RychPeKi',\n",
              "          'votes': '1'}],\n",
              "        'date_published': '2022-04-10T21:03',\n",
              "        'id': 'tJYzFTgjRSKHFTTn2',\n",
              "        'omega_karma': '',\n",
              "        'score': '10',\n",
              "        'text': 'It’s been hard keeping to it, but I do notice myself being more productive when I do. One thing that has stayed is not having an email tab always open. Hoping that over time I get better at following it strictly; it has such immediate positive effects that I’m not so worried I’ll gradually forget and stop, like happened with other productivity attempts (e.g. making to-do lists.)\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=tJYzFTgjRSKHFTTn2',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-04-03T17:18',\n",
              "      'id': '9JRpANRBaDNMaqhgp',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Interested to hear how this goes.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=9JRpANRBaDNMaqhgp',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-30T16:35',\n",
              "    'id': 'XnijshvYhpNcfHvcv',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'I really liked this post. As a result of reading it, I’m trialling the following:\\n\\nEvery time I go on my computer or phone, I need to specifically have a plan for one specific thing I am going to do. This can be \"check all notifications from X/\\u200bY/\\u200bZ), or \"write this one long email\", or even, \"15 minutes of unstructured time\", but it should always be intentional. If I get the urge to do something else, I need to save it for a future session, which can be immediately afterwards.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=XnijshvYhpNcfHvcv',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'supposedlyfun',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-29T03:21',\n",
              "    'id': 'CbvugZqy7GLgD5ujX',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'If you can get work done while having Wikipedia not-blocked, you are a better worker than I am. I will absolutely read about irrelevant, flagrantly not-even-wrong Medieval scholastic philosophers instead of doing chores.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=CbvugZqy7GLgD5ujX',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'aarongertler',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-05-17T10:18',\n",
              "    'id': 'Ch9nc8ZqDAFnqJq4X',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'This post led me to remove Chrome from my phone, which gave me back a few productive minutes today. Hoping to keep it up and compound those minutes into a couple of solid workdays over the rest of the year. Thanks for the inspiration!\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=Ch9nc8ZqDAFnqJq4X',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Josephm',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-30T19:08',\n",
              "    'id': '6jnDBmBetZiEbLxrD',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': '> I even thought about some identity-politics tweet I saw last week, on my run this morning… why is that garbage in my head? Good riddance.\\nI noticed this when I did a similar ban on technology usage. It’s bizarre how I could still have some YouTube video frequently pop into my thoughts, weeks after I stopped watching YouTube entirely.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=6jnDBmBetZiEbLxrD',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'james.lucassen',\n",
              "    'comments': [{'authors': 'GeneSmith',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T04:45',\n",
              "      'id': '9HTmw9jsmvCdeLP2k',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': 'This post is at least one more data point that Cal Newport’s method worked for someone else.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=9HTmw9jsmvCdeLP2k',\n",
              "      'votes': '2'},\n",
              "     {'authors': 'mingyuan',\n",
              "      'comments': [{'authors': 'james.lucassen',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-30T15:15',\n",
              "        'id': 'GWyuxButNCFwhfj9i',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': 'this is great,thanks!\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=GWyuxButNCFwhfj9i',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-03-29T18:47',\n",
              "      'id': 'puiqvyu2uGEJ2tFv9',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'Kurt Brown (mentioned in the post) did an experiment on this, helping residents of CEEALAR (formerly the EA Hotel) do their own Newport-style digital declutter; you can read his preliminary writeup here.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=puiqvyu2uGEJ2tFv9',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-28T05:23',\n",
              "    'id': 'F4AQaDriJdAkEhEjP',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'What do you think about the effectiveness of the particular method of digital decluttering recommended by Digital Minimalism? What modifications would you recommend? Ideal duration?\\nOne reason I have yet to do a month-long declutter is because I remember thinking something like \"this process sounds like something Cal Newport just kinda made up and didn’t particularly test, my own methods that I think of for me will probably better than Cal’s method he thought of for him\".\\nSo far my own methods have not worked.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=F4AQaDriJdAkEhEjP',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Vika',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-04-05T15:42',\n",
              "    'id': 'd7czHLaBK6SHAKcSM',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'Thanks Alex for the helpful recommendation! I got the book and read the first half. I’d like to do a declutter at some point, still figuring out how to handle non-optional technologies (e.g. work slack tends to be a major distraction for me, which is probably best coordinated with my team as a whole). \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=d7czHLaBK6SHAKcSM',\n",
              "    'votes': '1'},\n",
              "   {'authors': 'SeishinSennin',\n",
              "    'comments': [{'authors': 'TurnTrout',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-17T17:26',\n",
              "      'id': 'tnBpXMbJ5Fyx9r6dz',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'I just wouldn’t use most apps or websites. By adopting a bright-line whitelist approach with clear, universally applicable exception handling and scheduled eg email checks, I didn’t have constant temptations to rationalize breaking my own rules, like I did when I was *sometimes *allowed to use a service.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=tnBpXMbJ5Fyx9r6dz',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-04-13T00:05',\n",
              "    'id': 'kpgbabkn7fgPHCv4H',\n",
              "    'omega_karma': '',\n",
              "    'score': '1',\n",
              "    'text': 'What apps are you (and commenters) using to enforce declutter/\\u200breduce the System 1 instant refresh urges? I’m looking for phone and computer blockers/\\u200bfilters and other suggestions.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage?commentId=kpgbabkn7fgPHCv4H',\n",
              "    'votes': '1'}],\n",
              "  'date_published': '2022-03-27T23:09',\n",
              "  'id': 'fri4HdDkwhayCYFaE',\n",
              "  'omega_karma': '',\n",
              "  'score': '172',\n",
              "  'source': 'lesswrong',\n",
              "  'tags': 'Social Media/Practical/Self Improvement/Self-Deception',\n",
              "  'text': 'Contents\\n - Mistake: Motivatedly avoiding thinking about the issue\\n - Digital Minimalism\\n - Time costs\\n - Attentional costs\\n - Implementing the declutter\\n - My declutter rules\\n - Benefits of the declutter\\n - Recommendations\\n - Appendix 1: Declutter advice\\n - Appendix 2: My post-declutter rules\\nIf an unaligned entity invests billions of dollars into an application which you use, where they benefit from wasting your time, and you haven’t at least done a cost-benefit analysis so that your usage minimizes your costs and maximizes your benefits—*You are probably getting fucked over*.\\n# Mistake: Motivatedly avoiding thinking about the issue\\nLast summer, my friend Kurt Brown told me about *Digital Minimalism**.* The modern world is mired in attention-sucking apps which compete to waste as much of your time as possible. The book’s remedy: stepping back from non-essential internet usage, so that you can evaluate what really matters to you. After a month has come and gone, you add back in those digital activities which are worth it to you.\\nUnfortunately, this is the part of the story where we all cringe at my past behavior. I gave Kurt some excuses, demurring from his implicit recommendation that I read the book. I asked more questions, but so that I could learn more about what he’d been up to. I wasn’t going to actually do it. I think it sounded monastic and uncomfortable and *I’m not one of those people who needs it, I already have lots of locks on my devices*.\\nAnd locks I had. I restricted my iPhone with a password only known by a friend, so that I was unable to access *eg* Reddit without wiping my device, or asking my friend for the code. My phone was in black and white to minimize how appealing it would be, I had an outdated model to make using my phone less enjoyable. I didn’t have notifications for anything but phone calls. I *still wasted several hours a day on my phone, although I was always (motivatedly) surprised by this.* I thought I was spending at least 70% of my phone-time productively, by reading LessWrong and Wikipedia, or engaging in work communication. In this scenario, I didn’t want to upend my life for a month in order to save less than an hour a day (even though it still would have been worth it in the long run).\\nThis school year, I’ve had problems focusing and relaxing. I tried exercise, different medication, but nothing hit the spot. I wasn’t reading textbooks like I wanted to, my attention was fractured, I often felt behind my schedule. I was still doing my job and making progress—just not as much as I wanted.\\nCould this have anything to do with my attention problems?This spring, I read a LessWrong post which mentioned *Digital Minimalism*. Luckily, this triggered my \"if several reasonably smart EAs swear by the benefits of X, investigate X\" trigger-action plan.\\n# Digital Minimalism\\nI listened to the first half of the book on Audible in one night. As I wrote above:\\n> If an unaligned entity invests billions of dollars into an application which you use, where they benefit from wasting your time, and you haven’t at least done a cost-benefit analysis so that your usage minimizes your costs and maximizes your benefits—*You are probably getting fucked over*.[1]\\nI was immediately convinced that this thesis is correct, and resolved to start my month-long \"digital declutter\" the next day.\\n## Time costs\\nConsider why you originally bought a cell phone. It was probably to call people, to text people, to take photos, to get GPS navigation. Would you have bought it if you foresaw how you would feel an urge to check it even during a dinner with a friend you hadn’t seen in a long time? Would you have bought it if you knew you would take impatiently take it out of your pocket dozens of times a day, staring at it 2+ hours daily?\\nThe point isn’t \"phone bad, never use phone, quit now.\" My phone provides me with enormous benefits. The point is *where was the cost-benefit analysis, what tf has happened to us?!*\\nNotice the middle stat: **one third of daily waking hours**. I am disgusted that some people try to make this number go up further. From AppAnnie.Readers of this forum are probably better about their usage. Let’s be (too) generous and cut that to a mere two hours wasted daily on your phone, and 0 hours wasted on your other devices. That’s only *one eighth of your waking year,* or 1.5 waking months each year.\\n## Attentional costs\\nBut lost time doesn’t capture everything sucked away by your apps, by your email tics, by YouTube, by Reddit, by Slack, by Discord, by everything else which is after you. *Digital Minimalism* asked:\\n> When was the last time you were bored and in silence?\\nI remember lazy summer childhoods, staring at the ceiling after I ran out of video game time. At my 2018 CFAR workshop, my phone dipped in a stream for several minutes and short-circuited. I was actually glad. I felt free. How strange, to feel *free* from a device I purchased! Perhaps I should have noticed the warning sign.\\nSince then, engagement has been a pocket-grasp away. I’d leave my phone in another room to work, only to find my way back half an hour later. Even now, I look down at my phone on my desk, and I feel it. I feel it calling to me from far away, whispering to me, urging me to check Slack or my email—just one more time.\\nThese compulsions kill deep work in the cradle. My attention was fractured and strewn. I would anxiously procrastinate by flitting through tabs: *Discord. Slack. LessWrong. Gmail.* Even when I cleared time to think, I would periodically check my phone.\\n## Implementing the declutter\\nAt this point, you might be thinking \"OK, but I can’t roam the mountains of Nepal for a month. I have work to do and that requires staying in touch with people.\" Sure. The point of this post is not \"no phone.\" The point of this post is to build a digital life purposefully and carefully, because you reflectively endorse each component. The point of this post is to get people to do *any cost-benefit analysis at all* of the way they spend 1/\\u200b8th–1/\\u200b3rd of their waking hours.\\nMy estimate of the daily costs and benefits for a better-than-average Facebook user (considering Messenger to be distinct from Facebook). In appendix 2, I detail how I extract all of these benefits for 40 minutes a month, instead of 40 minutes a day—a 30x improvement!The declutter goes as follows:\\n\\n - Identify the minimal set of digital affordances required to do your job and the other necessities of life (e.g. paying bills).\\n\\n - Cut out everything else for one month.\\nThe point is that these apps which are out to get you—they’re very good at what they do. It’s not enough to turn off notifications and enable app timers. *Digital Minimalism* argues (and I mostly agree) that you have to *get out of the pond entirely* and catch a breather. After the declutter, you can soberly analyze the costs and benefits of each digital activity you add back in.\\n### My declutter rules\\nI went by a whitelist[2] in order to ensure there wasn’t a way to weasel around the rules. Here’s what I let myself do:\\n\\n - Phone\\n - Voice & video calls\\n\\n - GPS\\n\\n - Audible\\n\\n - Uber/\\u200bLyft\\n\\n - Authenticators/\\u200balarms/\\u200bother boring utilities\\n\\n - Roam/\\u200bnote-taking\\n\\n\\n - iPad\\n - Note-taking\\n\\n - Reading\\n\\n - Drawing\\n\\n\\n - Computer\\n - Anything offline (except music or video games)\\n\\n - Textbooks and Wikipedia and arxiv/\\u200bgoogle scholar\\n\\n - Overleaf for writing papers\\n\\n - Amazon and Upwork (for managing contracted-out labor)\\n\\n - Zoom for weekly meetings\\n\\n - Anki and Roam\\n\\n - Check email at noon on Mondays and Thursdays\\n - I told people to call me if it was important. I didn’t get any calls.\\n\\n - I later let myself send emails without looking at my inbox. I recommend Inbox When Ready, which hides your inbox by default and prevents you from being attention-sniped.\\n\\n\\n - Groceries /\\u200b other mundane things\\n - No Wealthfront—no reason for me to see how my portfolio is doing.\\n\\n\\nThat’s it. No music (see appendix), no messaging, no Facebook, no Twitter, no Slack, no Discord, no anxious email checking, no Youtube, no nothing. I even bought a cheap watch so that I wouldn’t have to check my phone for the time. If I needed an exception, I’d first write a note explaining what I did, to be read by my girlfriend, Emma, who started her declutter soon after.\\nWhy did I choose these rules? I won’t get unhealthily sucked into any of these activities. They all make me stronger. They let me do my work.\\nThe world was not going to end because I stopped reading the news for a month—I understand there’s a war still going on in Ukraine, but that’s about all I know, and I’m not worse off for it. I resolved that if I wanted to build models of that part of the world, I’d do that on purpose. I won’t doomscroll through hyper-optimized interfaces designed to scam me out of my attention and make me anxious. I said to myself, my life is worth more to me than that.\\n**FAQ**\\n> But TurnTrout, my job needs email /\\u200b [other special reason why this doesn’t work for me].\\nI concede that my rules are probably not best for your situation. But have you thought about the issue for five minutes? Could you ask your boss if you can check email once a day and otherwise take phone calls? Maybe you don’t restrict email, but stop looking at websites like Reddit or Hacker News or Marginal Revolution or Facebook or Twitter? Are there other creative solutions waiting to be uncovered? Have you tried?\\nIf your team uses Slack for asynchronous communication, once- or twice-daily checks should be fine. If you use it for synchronous communication, perhaps establish a daily \"office hour\" when you’ll be on Slack, or even coordinate with your team to establish a daily \"Slack hour\" where people are expected to be online. Or something else. The point is to establish the main benefits you reap from each digital affordance, and then find a plan which minimizes the costs you pay for those benefits.\\n> I’m already good about my internet usage.\\nThis might be true! I know exactly one person for whom I’m quite confident this is true (Andrew Critch), and maybe there are more among my friends whom I don’t know about. This might be you if you already use services based on their costs and benefits, often using websites in unintended ways (like blocking all recommendations on YouTube via the Unhook add-on [Chrome, Firefox]), and spending far less time than average (eg only checking email very infrequently).\\nI’d still bet against it. I would have said I was good about my internet usage, and it *was* true—in a relative sense. I think people (motivatedly) underestimate how much time they waste, perhaps because it can feel bad and embarrassing to admit the problem.\\n> But how will I stay in touch with people? I’m already lonely.\\nExcellent question! Reallocate low-quality social time to high-quality social time. Instead of checking if some half-friends liked your FB status, call up a buddy and grab a beer, or go to a meetup, or join a club.\\n# Benefits of the declutter\\n*February 22nd: The First Day.* I went running, and got back to the house 10 minutes earlier than usual. Huh.\\nI called my parents and went on a leisurely walk. Even so, I got my morning routine done 60 minutes ahead of schedule. I read half of a book on ordinary differential equations while lounging in my sunlit room. I did some deep thinking for an hour, safe from my phone’s dopaminergic temptation. I switched contexts and read about electrostatics. Still hours ahead of schedule.\\nThe day yawned and stretched. I wondered if it would ever end. (It did.)\\n*February 23rd: The Second Day.* From my journal:\\n> It’s so relaxing not using my phone, and yet I can still feel my anxiety pulling me to my digital affairs.\\nDid my LW post get lots of upvotes? Are people criticizing me? Did I win a prize in the contest? Am I missing something on the EliezerFic server? I even thought about some identity-politics tweet I saw last week, on my run this morning… why is that garbage in my head? Good riddance.\\nAnd so unrolled the next day, and the next. Time laid itself out before me. With my reclaimed time, I went on walks, I read *The Character of Physical Law*, I read ~three physics textbooks, I tripled my daily Anki workload to 1.5 hours, and I *still had time left over*.\\nLife became leisurely. I wrote letters to my girlfriends—some of them were in French. I even had time to write *poems*. I talked to them more often than before, with nightly phone calls. I also called my family most mornings. *I still had time left over*.\\nInstead of trolling through Discord, I called some labmates at Oregon State and started a weekly dinner. If anything, I felt less lonely than before, when I had the world at my fingertips. I called people when I wanted to talk to them. *I still had time left over.*\\nI listened to a Stephen King book when I couldn’t sleep—I found it reassuring to worry about fortifying a grocery store against eldritch horrors, instead of worrying about fortifying our planet against artificial intelligence. I listened to Dune with Emma, clocking 21 hours over 2.5 weeks. I went on walks with her, and to a hot tub, and I *still had time left over*.\\nI did notice potential withdrawal symptoms (alarming!), mostly via increased baseline anxiety. Other explanations include \"defending my dissertation & moving soon\", so I’m not sure if it was from the declutter.\\nEven assuming this month gave me unusually large benefits, I wouldn’t ever, ever go back. So when the declutter ended, I wasn’t clamoring to check the highest-karma Reddit posts from last month. I still feel the urge, but I resent Reddit now that I see what it takes away from me. That makes it easier to stay away.\\n# Recommendations\\nThis short post may not be convincing enough to try out such a substantial life modification. I’m not asking that you do a declutter right away. I’m recommending that you read the first half of *Digital Minimalism**,* or listen on Audible (cost: a few hours and $14).\\nLet me sweeten the deal with a costly signal. If I’ve met you in real life, and you consume the first half of the book and find it unconvincing /\\u200b try the declutter and it wasn’t at all worth trying in hindsight, message me on LessWrong and I’ll pay you $30.[3]\\nI think many, many people are shooting themselves in the foot, so I will be blunt. *Please stop shooting yourself in the foot.* Please do a cost-benefit analysis. I think many people have serious, serious problems with their internet usage. I did. You might. If so, you are leaving a lot of your life on the table.\\n*Thanks to Meg Tong, Josh Turner, and Kurt Brown for feedback on this post.*\\n# Appendix 1: Declutter advice\\nHere’s my main tip to add to the book: *Have well-defined exception handling which you never ever ever have to deviate from.* When I read about how other people navigated the declutter, their main failure modes looked like \"my dog died and I got really stressed and gave in\" or \"a work emergency came up and I bent my rules and then broke my rules fragrantly.\"\\nPlan for these events. Plan for feeling withdrawal symptoms. Plan for it seeming *so so important* that you check your email* right now*. Plan for emergencies. Plan a way to handle surprising exceptions to your rules. Make the exception handling so good that you never have a legitimate reason to deviate from it.\\nMy procedure was \"If I need to use a forbidden functionality, then I have to write what I did down on a slip of paper and leave it on my girlfriend’s desk ASAP.\" This worked because Emma would understand legitimate exceptions, but would look askance at me if I started flooding her desk with \"and then I checked Reddit\" notes. It’s easier to hold promises to other people, than promises to yourself.\\n# Appendix 2: My post-declutter rules\\n\\n - I only listen to music when:\\n - Only listening to the music, to fully soak it in\\n\\n - Exercising\\n\\n - Reasoning on this point:\\n - I think music generally makes me subtly dumber but feel cooler while I’m listening to it, so I listen to it a lot.\\n\\n - Music imposes its own form on my thoughts. My thinking and mood becomes governed by the song which happens to be playing, and less by the substance of my own thoughts. I don’t want my reasoning to hinge on \"will Spotify shuffle to *Attack on Titan* or *Coldplay* next?\".\\n\\n - See also Gwern’s stub.\\n\\n - I do have Google Home, and often play nature sounds.\\n\\n\\n\\n - I only check LessWrong /\\u200b Discord /\\u200b Slack /\\u200b Messenger /\\u200b my text messages each Sunday at noon.\\n - I write blogposts before then, and I won’t check their reception until the next week (I used to nervously refresh).\\n\\n - I’ve also adblocked the karma elements of the website, because I worry too much about them.\\n\\n\\n - As I currently see it, I’m only logging in to the newsfeed part of Facebook two more times: To share this blog post, and after I receive my PhD.\\n - After that, I’ll check its event page weekly, while blocking the notifications /\\u200b other clutter FB tries to throw at me. This should take less than 10 minutes each week.\\n\\n - Here’s how to use FB more peacefully:\\n - Install FBPurity; you can save time by importing my settings here.\\n\\n - Use UBlock Origin to get rid of the rest; here is my element blocking list for Facebook.\\n - (I also hide the chat sidebar on the main page, which is a FB option)\\n\\n\\n\\n - I could also check a favorite page once a week (with the chat and comment elements blocked), if I need more memes in my bloodstream.\\n\\n - In combination with a monthly Messenger checkin, I’ve extracted my main benefits from Facebook, at a cost of at most 50 minutes each month, instead of 50 minutes each day!\\n - Again, I ***don’t recommend***** **doing small fixes like \"just hide some FB elements.\" These fixes **don’t work** for most people. This advice is aimed at post-declutter usage, which unfolds from your informed cost-benefit analysis.\\n\\n\\nHere’s what my FB news feed looks like now. 😌\\n - For news, I purchased a digital+print subscription to *The Economist*. Once a month, I can choose to read the four issues for an hour or two.\\n - I don’t need to read more than that. I can read about candidates before an election, and there isn’t much else that’s decision-relevant. If eg AI dynamics heat up and geopolitical understanding becomes more important, I’ll tackle that deliberately.\\n\\n - Looking back at my life, I see how often I’ve been hijacked by news websites. It makes me sick.\\n\\n\\n - I’m basically not going to text anymore. I used to check it so, so often.\\n - This was hard at first. One of my partners strongly prefers texting, and I liked texting her, and missed her a lot. With additional thought, we discovered that she really just wanted to asynchronously send me updates on how her day was going. I said she could text me as much as she wanted—but I’d read them during our next phone call.\\n\\n\\n - I can watch movies and play video games if I’ve planned it out at least a few hours in advance.\\n\\n - I can check Reddit for specific question/\\u200banswer threads.\\n\\n - I can check Twitter if I plan the session out in detail one day in advance.\\n - Twitter is toxic for me, even though I originally made an account to promote an alignment paper and only subscribed to AI/\\u200bmath accounts.\\n\\n\\n - My phone will still be in black and white and warm color temperature, to make it even less engaging compared to the rest of my world.\\n\\n - I *never ever use my phone on the toilet. Ever.* This has served me well and seems like a pure win.\\n\\n - ^This is only a sufficient condition; the app need not be the child of a billion-dollar company. For example, I oft ragebaited myself about the culture war via *Marginal Revolution* and *Hacker News*. I even tend to get anxious about *LessWrong* usage, and I know that the team deliberately refrained from attention-hacks like red notifications.\\nEven while using my Notion to edit this post and supervise research, I saw a red \"5 notifications\" marker, which gave me an overwhelming urge to *see what the notifications are*. With great effort, I ignored the impulse, and deleted the element with my adblocker.\\n\\n\\n - ^I just now picked up my phone and stared at it blankly. One month later. Yuck.\\n\\n\\n - ^Limit $300 total.\\n\\n',\n",
              "  'title': 'Do a cost-benefit analysis of your technology usage\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/fri4HdDkwhayCYFaE/do-a-cost-benefit-analysis-of-your-technology-usage',\n",
              "  'votes': '86'},\n",
              " {'authors': 'leogao',\n",
              "  'comments': [{'authors': 'Yonadav Shavit',\n",
              "    'comments': [{'authors': 'leogao',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-29T08:02',\n",
              "      'id': 'Eb9bGCRCv9fHrbCcQ',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'I’m thinking of the entire human+tool system as a consequentialist, and I’m basically arguing that that system fails in the same ways as \"human in the loop oversight\" fails\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/f6ByNdGJYxR3Kwguy/asot-searching-for-consequentialist-structure?commentId=Eb9bGCRCv9fHrbCcQ',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-29T00:12',\n",
              "    'id': 'XjzDiuLQDonn3GFYE',\n",
              "    'omega_karma': '',\n",
              "    'score': '1',\n",
              "    'text': 'I’m confused about your bit on deception within Tool AIs. I generally think of Tool AIs not as consequentialists, and therefore there is no \"long-term utility\" to maximize via short-term deception. What’s the mechanism by which you worry about these tools being deceptive to their users?\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/f6ByNdGJYxR3Kwguy/asot-searching-for-consequentialist-structure?commentId=XjzDiuLQDonn3GFYE',\n",
              "    'votes': '1'}],\n",
              "  'date_published': '2022-03-27T19:09',\n",
              "  'id': 'f6ByNdGJYxR3Kwguy',\n",
              "  'omega_karma': '10',\n",
              "  'score': '24',\n",
              "  'source': 'alignment forum',\n",
              "  'tags': 'Consequentialism/AI',\n",
              "  'text': '*Editor’s note: I’m experimenting with having a lower quality threshold for just posting things even while I’m still confused and unconfident about my conclusions, but with this disclaimer at the top. Thanks to Kyle and Laria for discussions.*\\nIn \"Searching for Bayes Structure\", Eliezer argues that things which arrive at the truth must be doing something Bayes-like somewhere in there, even if it’s extremely inefficient or accidental or filtered through some process that looks very different from the outside. If it has no Bayes structure, it literally cannot arrive at the truth.\\nI think it’s plausible that Bayes is to epistemic rationality as consequentialism is to instrumental rationality. Here, by consequentialism I mean the ability to get to some goal from a broader set of initial states, which is how I understood Elliezer’s use of the term in the dialogues. It does not have to be an EUM/\\u200bVNM-rational. Importantly, to be good at consequentialism comes with all the stuff like instrumental convergence (and consequently self preservation, power seeking, etc). \\nIn other words, there’s some minimal amount of consequentialism you need to achieve a given goal, and there’s no getting around this lower bound. Of course, some agents do a lot more consequentialism than is necessary, but I interpret some people (i.e Eliezer) as arguing that even this lower bound is too much consequentialism for, say, performing a pivotal action, because it’s fundamentally very difficult to do. As an analogy, if your goal is to buy an apple for $1, any plans which fail to collect at least $1 will simply not be able to acquire an apple, and even though there also exist plans which collect $100 (which is more dangerous than collecting $1), if even collecting $1 is too dangerous by default, then even lobotomizing a $100-collecting agent to only collect $1 is scarcely comforting. The main lesson I draw from this is that if we want to do something consequentialist then we have to somehow figure out how to align consequentialists, and that making the agent worse at consequentialism isn’t a solution. I think it also seems productive to figure out where the lower bound of how much consequentialism we need (for, i.e a pivotal action) and the upper bound of how much consequentialism is safe are relative to each other. \\nAs an aside, my intuition for why instrumental convergence is unavoidable for consequentialists: There is some set of plans that achieve your goal with high probability across all universes, and a slightly larger superset that achieves your goal with high probability in across the universes in which you don’t try to stop the system. Among those plans, under some complexity prior or something, the ones that have the safe properties we want (they actually stop when you try to stop them) occupy a very small measure, because this set is very unnatural. Think Nate’s laser analogy: the plans which accomplish the goal in a way robust to many perturbations, but yet are not robust against the perturbations that correspond to us trying to stop the system, is difficult to specify. So to pull out the ones we want requires a bunch of work, which means that by default most plans that achieve our goal will be power seeking and also not corrigible.\\nActually, it gets even worse, because there are also deceptive plans that look corrigible but actually aren’t; it’s really hard to separate these from the actually corrigible ones. So even getting really good at picking out the corrigibility cluster of things isn’t good enough, because there’s a big incentive for deceptive plans to look corrigible. (I think this is vaguely corresponding to outer vs inner alignment but I’m not 100% sure.) Also, there might be self-modification considerations here where non-EUMs and other lobotomized AIs might self modify to EUMs, if you lobotomize them too much, the reason being that if you lobotomize the AI too much then most plans conditioned on success start looking like \"build a non lobotomized AI somehow and then tell that AI to accomplish the thing\".\\n## Tool AI\\nI think there’s also a way in which this applies to tool AI type arguments as well. Ultimately, the reason we want tools is they help us accomplish some goal (for instance, performing a pivotal action). So, we can view the entire human+tool system as an agent that is trying to get to some goal, where there’s some human oversight to ensure that the plans pass muster. This system, to get to goals, will have to do consequentialism. While having the human provide the glue between the model and the real world does add some safety, I would argue that this is approximately as safe as just humans vetting plans from an agent, which is itself not really sufficient because many plans which seem non suspicious to us are actually dangerous in some unforeseen way (diving into whether this is most plans or vanishingly few plans seems like a useful avenue—on the one hand one would think that making a plan sound useful while still doing something bad might require a lot of optimization, on the other hand \"I can’t see anything going wrong with this\" is a hugely lower bar than \"nothing will go wrong with this\" resulting in most plans that satisfy the former not satisfying the latter). \\nWhile the human providing the \"outer loop\" so to speak does allow the human a little bit more control in that they have control over the particular reasoning processes used to arrive at the action, I don’t think this is a very large effect. For one, if the tool is deceptive, it can still manipulate the human by giving them carefully crafted answers to their queries—in the deceptive case this gives almost no protection. Even without deception, if we’re in a universe where \"I can’t see anything going wrong with this\" is much looser than \"nothing goes wrong\" (which, for what it’s worth, I think is highly likely to be true), you end up with the exact same problem again. Because there’s some minimal amount of consequentialism you need to do no matter what to accomplish your goal, you also need to do some minimal amount of optimizing against your ability to see things wrong with plans, and in the universe where most ok-looking plans suck, this optimization quickly goodharts your ability to tell whether a plan is good. \\nThis seems to suggest the human’s ability to pick good plans with extremely high precision (i.e definitely not accepting any dangerous plans, though possibly rejecting some safe plans) as a core difficulty. This particular subproblem has also popped up in discussions about other parts of alignment, so I think it seems like something pretty important.\\n(Also, tools are economically uncompetitive anyways.) \\n',\n",
              "  'title': '[ASoT] Searching for consequentialist structure\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/f6ByNdGJYxR3Kwguy/asot-searching-for-consequentialist-structure',\n",
              "  'votes': '11'},\n",
              " {'authors': 'Capybasilisk',\n",
              "  'comments': [{'authors': 'pixx',\n",
              "    'comments': [{'authors': \"Dumbledore's Army\",\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-27T18:19',\n",
              "      'id': 'WnohTviF7XLbwqsgE',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': 'Thanks, I hadn’t seen that before, and now I have a new concept to play with :-) \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=WnohTviF7XLbwqsgE',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'Brandon Kin Man Lee',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-04T11:06',\n",
              "      'id': 'EL2Rumrjuuv7tYJMp',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'I can also think of \"MOPs\" as a possible term, but that is more of a cultural class approach than a developmental skill approach https://\\u200b\\u200bmeaningness.com/\\u200b\\u200bgeeks-mops-sociopaths\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=EL2Rumrjuuv7tYJMp',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-27T17:26',\n",
              "    'id': 'iXFkFLqsrhxJoNDM6',\n",
              "    'omega_karma': '',\n",
              "    'score': '12',\n",
              "    'text': 'Sort of related, everything studies wrote this essay in 2017 and now \"wamb\" is a term that my friends and I use all the time.\\n\\nhttps://\\u200b\\u200beverythingstudies.com/\\u200b\\u200b2017/\\u200b\\u200b11/\\u200b\\u200b07/\\u200b\\u200bthe-nerd-as-the-norm/\\u200b\\u200b\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=iXFkFLqsrhxJoNDM6',\n",
              "    'votes': '9'},\n",
              "   {'authors': 'Steven Byrnes',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-27T15:50',\n",
              "    'id': 'YNAxmNjmqYwvrj9Zd',\n",
              "    'omega_karma': '',\n",
              "    'score': '7',\n",
              "    'text': 'I have a proposed answer here\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=YNAxmNjmqYwvrj9Zd',\n",
              "    'votes': '7'},\n",
              "   {'authors': 'waveman',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-28T03:15',\n",
              "    'id': 'xeYEtZbh6gYCAEYTb',\n",
              "    'omega_karma': '',\n",
              "    'score': '6',\n",
              "    'text': 'Actually non-autistic people are quite extreme in many ways when you look at it closely. Here is my spoof DSM6 entry as illustrationFrom DSM-VI: Hyper-Social (Allistic)  Spectrum DisorderHSSD is a syndrome in which there is an over-focus on social phenomena at the expense of other aspects of the world. Contrast with Autistic Spectrum Disorder, which is in many ways the opposite.\\nDiagnosis: Any 5 of the following are present:\\nInability to express self clearly; use of ambiguous and vague language; discomfort with clear languageObsessive interest in knowing personal details of acquaintances or strangers e.g. celebrities, or even fictional charactersUnfounded belief in being able to read other people’s minds, in particular to know if someone is lying or not.Difficulty in thinking in a systematic logical way, e.g. to do math or program computersTendency to try to bend and stretch rules for no obvious reason. Discomfort with accurately following instructions and processes.Forms beliefs based on the opinions of others rather than on facts and evidenceTendency to affiliate with groups and to align all opinions to the groupFrequently lies for social conveniencePreoccupied with social status and \"looking the part\"Focus on status symbols, and symbols of virtue and group affiliationFocus on appearances more than underlying realityIntolerance of diversity of opinionIntolerance towards people who do not have HSSDSpends large amounts of time on shallow \"social\" activities with little actual content. May lead to destructive activities such as substance abuse e.g. alcohol, and over-eating.Lack of interest in mastering difficult, especially technical, subjects in depthTendency to stare into people’s eyes, and to believe that this gives great insight into the other person’s mind. Usually unaware that this can create discomfort in the other person.Tendency to think that staring into people’s eyes demonstrates trustworthiness \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=xeYEtZbh6gYCAEYTb',\n",
              "    'votes': '5'},\n",
              "   {'authors': 'Mitchell_Porter',\n",
              "    'comments': [{'authors': 'Brandon Kin Man Lee',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-04T10:46',\n",
              "      'id': '8Mc5k3pjoZcdHfmgH',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'Looks like the same empathizing vs systematizing (same goes for bipolar being psychosis-adjacent). What about cluster B and ADHD? Autism seems like Cluster C, whilst bipolar-adjacent empathic types seems like Cluster A. If this works, it seems that there is a tri-factor model of psychopathology?\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=8Mc5k3pjoZcdHfmgH',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-27T22:55',\n",
              "    'id': 'qPtMEaavP8R7nSw9f',\n",
              "    'omega_karma': '',\n",
              "    'score': '4',\n",
              "    'text': 'The \"diametric model\" of Crespi et al says psychosis /\\u200b schizophrenia /\\u200b schizotypy is the opposite of autism. \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=qPtMEaavP8R7nSw9f',\n",
              "    'votes': '3'},\n",
              "   {'authors': 'hawkebia',\n",
              "    'comments': [{'authors': 'Capybasilisk',\n",
              "      'comments': [{'authors': 'hawkebia',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-28T07:15',\n",
              "        'id': '7Yf79bniAs3EnfLAG',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'Interesting. Though I think extremes represent fewer degrees of freedom; where certain traits/\\u200bcharacteristics dominate, and heuristics can better model behaviour. The \"typical\" person has all the different traits pushing/\\u200bpulling, and so fewer variables you can ignore. i.e. the typical person might be more representative of hard-mode.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=7Yf79bniAs3EnfLAG',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-03-27T17:31',\n",
              "      'id': 'zy4HBZFGRK6MgWMqq',\n",
              "      'omega_karma': '',\n",
              "      'score': '2',\n",
              "      'text': 'My assumption is that, for people with ASD, modelling human minds that are as far from their own as possible is playing the game on hard-mode. Manage that, and modelling average humans becomes relatively simple.   \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=zy4HBZFGRK6MgWMqq',\n",
              "      'votes': '2'},\n",
              "     {'authors': 'Brandon Kin Man Lee',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-04T11:03',\n",
              "      'id': 'qWp4iGDdGH2BeMwKj',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'Sympathy vs Systematics as a 2x2 grid would be good, as cooperation vs competition, or voting and coalitional theory vs economics and zero-sum games. Might want to take a look at intelligence, \"verbal tilt\" and \"dark core of personality\" as they seem related in this context.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=qWp4iGDdGH2BeMwKj',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-27T16:20',\n",
              "    'id': '5z88XTroQCngiGNJ2',\n",
              "    'omega_karma': '',\n",
              "    'score': '3',\n",
              "    'text': 'I think identifying the blind spots of the typical AI engineer/\\u200barchitect is an interesting and potentially important goal. Though I’m not sure I follow the reasoning behind identifying the opposite as the path to \"modeling the desires of the typical person.\"?\\n> I think investigating this would be of interest to people working in AI alignment and whose ultimate goal and whose ultimate goal is improving the condition of humanity in general. Understanding the needs and wants of the subset of humans most unlike themselves would likely help in modeling the desires of the typical person.\\nIsn’t that better and more easily accomplished by identifying the median person i.e. in what way is the typical AI engineer different from the general population, and adjusting for that?\\nAlternatively, one could find what is **complementary** to autism rather than the **opposite** of autism; assuming those are not necessarily the same. People who may be attracted to and good at roles/\\u200bprofessions like people management, team sports, therapists etc.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=5z88XTroQCngiGNJ2',\n",
              "    'votes': '2'},\n",
              "   {'authors': 'Slider',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-28T00:19',\n",
              "    'id': 'rZNLyNEBdbGXzAgMa',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'I would not be surprised if the negative stereotype of a \"blonde\" would be people socially recognising the undesirability of anti-autism. Also a trope about approaching homework to bully or bribe people to make them for you and approach to tests as trying to copy the right answers makes one resistant to extracting knowledge from education. And while it is great to defer to experts on areas you are not an expert in it would be grand if there were something you are yourself an expert on. If an employee only delegates and never does or is capable of doing work that could be a setup with all mortar and no brick.\\nTreating autism as a degree of emphathy is a little simplistic and might be a error-mode in these kind of analyses.\\nWhat I have found that autist have social competence with practising and thinking out social situations. Their models are explicit. Non-autists usually don’t have great theorethical insight to their social competence. its as if they can’t modify or customise it because it is a black box that doesn’t hiccup. So I have come to think that the implicit vs explicit modelling is way more apt for the difference.\\nWith neural networks we have a problem of interpretability that we can have a competent network where we don’t have a good idea how it does its thing. It is intriguing to me to think that some people have models that have like 10 million factors and some that have only 1000. Social interaction might be a field where approaches that weakly update on a lot of different signals can naturally do well. The shortcomings of autistic people often look like being too formulaic, having a heuristic that doesn’t have a lot of caveats or adaptability. Rules that the person is explicitly thinking via auditory memory. The challenges that is typical for non-autistics is murkyness, having to say a thing multiple times before it sinks (say having to say \"no\" three times. Reading the manual and still calling the helpline to integrate information that actually is in the manual), being confused by mixed signals and having trouble giving priority to some level (if you say \"no\" calmy it might just induce confusion, verbal level alone being too weak a signal to process)\\nI would also like to point out that if you live with people that sahre your cognitive makeup means you don’t have to think about psychology but can just get interpersonal interoperability by symmetry or identicalness. If you are a neurominority then you will use signficant resources to try to figure out what is a working way to interface with other people. So I consider autists to be veterans about trying to interface, even if it by neccecity. \\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=rZNLyNEBdbGXzAgMa',\n",
              "    'votes': '1'},\n",
              "   {'authors': 'tailcalled',\n",
              "    'comments': [{'authors': 'Brandon Kin Man Lee',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-04-04T11:00',\n",
              "      'id': 'ZCqksLCGd8gQAiqfx',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'Let’s take a look at cognitive vs non-cognitive traits first and foremost. Autism has cognitive and risky behavior bias, Bipolar has non-cognitive and longevity bias, but both are positively correlated to SES, Openness and Emotional Stability. Within this bias problem, we can see that Non-cognitive tilt is correlated to Conscientiousness, Extraversion, Agreeableness. https://\\u200b\\u200bwww.nature.com/\\u200b\\u200barticles/\\u200b\\u200bs41588-020-00754-2 \\nThis for some reason feels similar to Emil Kirkegaard’s Verbal Tilt theory, and how autism is non-verbal tilt and intelligence, bipolar is verbal tilt and sentimentality. It is common knowledge that most dark traits are correlated to low IQ and/\\u200bor SES, however its relation to tilts and highly educated counter-conjectures is not known. https://\\u200b\\u200bemilkirkegaard.dk/\\u200b\\u200ben/\\u200b\\u200b2020/\\u200b\\u200b05/\\u200b\\u200bthe-verbal-tilt-model/\\u200b\\u200b \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=ZCqksLCGd8gQAiqfx',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-27T18:37',\n",
              "    'id': 'FBc9MgcccJ3uvHptE',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'I feel like if one wanted to know what would happen if one took the \"autism\" dialed and turned it all the way to far-negative values, one should look for traits that are negatively genetically correlated with autism. I don’t know what those traits would be, though; I had trouble finding any good studies of that.\\nHowever, I don’t know whether this is necessarily the group of people that autistic people would most struggle to understand, or where their understanding of other people would be most improved if they learned to understand that group. After all, the group might have its own oddities that aren’t related to autism.\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=FBc9MgcccJ3uvHptE',\n",
              "    'votes': '1'},\n",
              "   {'authors': 'CronoDAS',\n",
              "    'comments': [{'authors': 'Capybasilisk',\n",
              "      'comments': [],\n",
              "      'date_published': '2022-03-27T17:27',\n",
              "      'id': 'ytJNDAKuadvMWJnSy',\n",
              "      'omega_karma': '',\n",
              "      'score': '4',\n",
              "      'text': 'Williams Syndrome seems to me to just be the opposite of paranoia, rather than autism, where the individual creates a fictional account of another human’s mental state that’s positive rather than negative. \\nThat’s to say, their ability to infer the mental states of other humans is *worse* than that of the typical human. \\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=ytJNDAKuadvMWJnSy',\n",
              "      'votes': '3'}],\n",
              "    'date_published': '2022-03-27T17:09',\n",
              "    'id': 'iCdRzDvEvLGTJNWev',\n",
              "    'omega_karma': '',\n",
              "    'score': '2',\n",
              "    'text': 'Williams syndrome?\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism?commentId=iCdRzDvEvLGTJNWev',\n",
              "    'votes': '1'}],\n",
              "  'date_published': '2022-03-27T15:30',\n",
              "  'id': '4zuFpLi7bYbwmEhoX',\n",
              "  'omega_karma': '',\n",
              "  'score': '8',\n",
              "  'source': 'lesswrong',\n",
              "  'tags': 'Psychology/Autism',\n",
              "  'text': 'It’s probably not presuming too much to guess that many around here have personal experience with the autism spectrum, if not in relation to themselves, then with close family. I say this because the kinds of subjects discussed around here are exactly the type that would appeal to those of an autistic persuasion, e.g. technical systems, logic, and (arguably) utilitarian philosophy. Many here probably have backgrounds in STEM, and those fields tend to have a significant over-representation of people on the spectrum.\\n\\nAn issue that often comes up in software design (a field with high ASD representation) is programmers not being able to properly model the wants and needs of non-technical end-users. I bring this up because I see AI alignment as being a scaled-up version of this problem. The kind of people who have a strong interest in AI/\\u200bmachine learning will likely have a greatly disproportional impact on the future of human civilization. This might be a problem as not only is this subset of humans highly atypical in cognitive style, but the very mental architecture which underlies their interest in technical systems restricts their ability to model the minds of typical humans!\\n\\nThe hardest humans for ASD types to model would be those with minds that are the diametric opposite of their own. Call this condition anti-autism. It would consist of...well I’m not exactly sure. It’s hard for me to imagine the mental lives of these people. I’ve heard the phrase \"people vs things\" thrown around, implying that ASD types are drawn to inanimate objects, and humans who are on the opposite side of this condition would be drawn to people. I’m not so sure. I think that plenty of people with ASD have an obsessive interest in categorizing humans and other living things.\\n\\nWhile there’s been a great amount of study behind autism, there’s a curious lack of interest in what a condition with its exact opposite traits looks like, or even the fact of its existence. Simon Baron-Cohen, one the most famous autism researchers and creator of the systemizer-emphathizer scale [0], argued that it doesn’t come up because it’s not actually a problem. Basically, a human who is system-blind but extremely skilled at reading other humans (hyper-empathy, in his terms) can get by perfectly well [1]:\\n\\n\\n> Scientists have never got up close to these individuals. It is a bit like positing the existence of a new animal on theoretical grounds, and then setting out to discover if it is really found in nature.\\n\\n\\n\\n> [W]hat would such people look like? Their empathizing ability would be average or significantly better than that of other people in the general population, but their systemizing would be impaired. So these would be people who have difficulty understanding math or physics or machines or chemistry, as systems. But they could be extremely accurate at tuning in to others’ feelings and thoughts.\\n\\n\\n\\n> Would such a profile carry any necessary disability? Hyperempathizing could be a great asset, and poor systemizing may not be too crippling.\\n\\n\\n\\n> Fortunately, in our society there is considerable tolerance for such individuals. For example, if you were a child who was systemblind, your teachers might simply allow you to drop mathematics and science at the earliest possible stage, and encourage you to pursue your stronger subjects.\\n\\nIf you were a systemblind adult and your car didn’t work, you could just call the mechanic (who is likely to be at least a Type S). If your computer needs putting together, and you can’t work out which lead goes into which socket, there are phone numbers that you can ring for technical support. And in evolutionary terms, there were likely equivalent people that a systemblind person could turn to for help when that person’s home was destroyed in strong winds, or when their spear broke.\\n\\n\\nBaron-Cohen dismisses paranoia as being anti-autism because such people don’t infer the mental states of other humans, but rather create a fictional account of them:\\n\\n\\n> If someone is over-attributing intentions, or has become preoccupied by their own emotions, then by definition they are not exhibiting hyperempathy. Hyperempathy is the ability to ascertain the mental states of others to an unusually accurate and sensitive degree, and it can only occur if one is appropriately tuned in to the other person’s feelings. A paranoid person, or someone who is easily inflamed into aggression by suspecting that others are hostile, has a problem. But their problem is not hyperempathy.\\n\\n\\nSo again, it’s not simple to guess what people with \"the opposite of autism\" are like, as they’re generally not available for clinical study.\\n\\nI think investigating this would be of interest to people working in AI alignment and whose ultimate goal is improving the condition of humanity in general. Understanding the needs and wants of the subset of humans most unlike themselves would likely help in modeling the desires of the typical person.\\n\\nAs an aside, Baron-Cohen’s sytemizers vs empathizers framework reminded me a lot of Asimov’s Foundation books [2]. The First Foundation, with it’s technicians and natural scientists, and the Second Foundation, with its psychologists, who ultimately needed each other to survive.\\n\\n\\n[0] https://\\u200b\\u200bwww.ncbi.nlm.nih.gov/\\u200b\\u200bpmc/\\u200b\\u200barticles/\\u200b\\u200bPMC1693117/\\u200b\\u200b\\n\\n[1] Baron-Cohen, Simon, *The Essential Difference* (2003)\\n\\n[2] https://\\u200b\\u200ben.wikipedia.org/\\u200b\\u200bwiki/\\u200b\\u200bFoundation_series\\n',\n",
              "  'title': 'The Opposite Of Autism\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/4zuFpLi7bYbwmEhoX/the-opposite-of-autism',\n",
              "  'votes': '5'},\n",
              " {'authors': 'Chris van Merwijk',\n",
              "  'comments': [{'authors': 'MakoYass',\n",
              "    'comments': [],\n",
              "    'date_published': '2022-03-28T01:46',\n",
              "    'id': 'KCL3Z4jrjfBnHkRZ6',\n",
              "    'omega_karma': '',\n",
              "    'score': '8',\n",
              "    'text': '> Research that makes the case for AGI x-risk clearer\\nI ended up going into detail on this, in the process of making an entry to the FLI’s aspirational worldbuilding contest. So, it’ll be posted in full about a month from now. But for now, I’ll summarize:\\n\\n - We should prepare stuff in advance for identifying and directly manipulating the components of an AGI that engage in ruminative thought. This should be possible, there are certain structures of questions and answers that will reliably emerge, \"what is the big blank blue thing at the top of the image\" \"it’s probably the sky\", and such. We wont know how to read or speak its mentalese, at first, but we will be able to learn it by looking for known claims and going from there.\\n\\n - Once we have AGI, we should use this stuff to query the AGI’s own internal beliefs about whether certain catastrophic outcomes would come about, under the condition that it had been given internet access.\\n\\n - If the queries return true, then we have clear evidence of the presence of immense danger. We have a *Demonstration of Cataclysmic Trajectory*. This is going to be much more likely to get the world to take notice and react, than the loads of abstract reasoning about fundamental patterns of rational agency or whatever, that we’ve offered them so far. (Normal people don’t trust abstract reasoning, and they mostly shouldn’t! It’s tricksy!)\\n\\n - From there, national funding for a global collaboration for alignment, and a means to convince security-minded parts of the government to implement the pretty tough global security policies required, so that the alignment project will no longer need to solve the problem in 5 years, and can instead take, say, 30.\\n(And then we solve the symbol grounding problem, and then we figure out value learning, and then we learn how best to aggregate the learned values, and then we’ll have solved the alignment problem)\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/5RMARxzSeMYoj7nFQ/manhattan-project-for-aligned-ai?commentId=KCL3Z4jrjfBnHkRZ6',\n",
              "    'votes': '4'},\n",
              "   {'authors': 'Yitz',\n",
              "    'comments': [{'authors': 'sanxiyn',\n",
              "      'comments': [{'authors': 'Chris van Merwijk',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-28T12:25',\n",
              "        'id': 'W89ctgbwqZAL2W6y5',\n",
              "        'omega_karma': '',\n",
              "        'score': '2',\n",
              "        'text': 'tangential comment: Regarding \"I will define success as producing fission weapons before the end of war in Europe\". I’m not sure if this is the right criterion for success for the purpose of analogizing to AGI. It seems to me that \"producing fission weapons before an Axis power does\" is more appropriate.And this seems overwhelmingly the case, yes: \"theory of atomic bomb was considerably more advanced at the beginning of Manhattan project compared to our understanding of theory of aligned AGI\"\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/5RMARxzSeMYoj7nFQ/manhattan-project-for-aligned-ai?commentId=W89ctgbwqZAL2W6y5',\n",
              "        'votes': '2'}],\n",
              "      'date_published': '2022-03-28T11:53',\n",
              "      'id': '8vHM8dupGqgKJQeho',\n",
              "      'omega_karma': '',\n",
              "      'score': '3',\n",
              "      'text': 'As I understand, theory of atomic bomb was considerably more advanced at the beginning of Manhattan project compared to our understanding of theory of aligned AGI.\\nTo somewhat simplify, there were two unknown parameters. The critical mass of uranium-235, and the rate of uranium isotope separation. Given these two parameters, you could calculate how long it would take by simple division. Remember Little Boy was not tested at all: theory was that solid. Success was basically guaranteed if you had enough time, although success in 100 years would have been rightfully considered failure.\\nWhat about nuclear reactor, plutonium, and implosion device? Those were gambles to speed things up, because they thought it would take too long. (They were right: war in Europe ended first.) But Manhattan project would have succeeded without them, in the sense of producing fission weapons.\\nAnother thing they tried to speed things up was better isotope separation. Electromagnetic separation was well understood and basically worked as designed. They gambled on developing gaseous diffusion, and it ended up more efficient, but development took too long so it didn’t shorten the timeline at all.\\nIn retrospect, they should have gambled on centrifuges, which is the current preferred method. What was missing was a clever innovation, not an advanced material or other things of that nature. Manhattan project could have been finished a lot faster if only they had known about Zippe centrifuge.\\nIn fact there is an alternate history novel based on this, The Berlin Project by Gregory Benford (recommended). The author’s estimate, which seemed reasonable to me, is that centrifuge would have shorten the timeline by one year, finishing in 1944. As a result, as the title suggests, atomic bomb is dropped on Berlin.\\nSo, let me answer the question. I will define success as producing fission weapons before the end of war in Europe. (This is reasonable interpretation of statements by scientists who worked on Manhattan project.) The real world Manhattan project failed.\\nNo one could predict anything before the necessary experiments were done to figure out the critical mass. Rough estimates varied by one order of magnitude, implying one to ten years. Once critical mass was figured out, electromagnetic separation implied three years (1942~1945), which was felt to be about 50% success rate based on guesses about how war would progress. They tried hard to speed things up and shorten the timeline, but they failed. Choosing centrifuge would have led to success in 1944 but there was no reasonable way to know that and unlucky choice was made.\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/5RMARxzSeMYoj7nFQ/manhattan-project-for-aligned-ai?commentId=8vHM8dupGqgKJQeho',\n",
              "      'votes': '3'},\n",
              "     {'authors': 'Chris van Merwijk',\n",
              "      'comments': [{'authors': 'Yitz',\n",
              "        'comments': [],\n",
              "        'date_published': '2022-03-28T15:03',\n",
              "        'id': 'ajfedvrDwYicKwNEC',\n",
              "        'omega_karma': '',\n",
              "        'score': '1',\n",
              "        'text': 'I’m asking to try to imagine yourself as an atomic theorist who has access to the state of knowledge of atomic theory in 1942. Obviously that can’t be done perfectly, but my thought was that by modeling what you would have predicted vs what actually happened, some insight can be had about how \"unknown unknowns\" effect projects of that scale.\\n',\n",
              "        'url': 'https://www.lesswrong.com/posts/5RMARxzSeMYoj7nFQ/manhattan-project-for-aligned-ai?commentId=ajfedvrDwYicKwNEC',\n",
              "        'votes': '1'}],\n",
              "      'date_published': '2022-03-28T05:17',\n",
              "      'id': '2PcYiHWDNhwT5t8GL',\n",
              "      'omega_karma': '',\n",
              "      'score': '1',\n",
              "      'text': 'I’m not sure I understand the motivation behind question. How much of my modern knowledge am I supposed to throw away? Note I am not in fact an atomic theorist who has the state of knowledge of atomic theory in 1942 so it’s hard to know what I’d think, but I can imagine assigning somewhere between 5% and 95% depending on how informed of an atomic theorist I actually was and what it was actually like in 1942. Maybe I could give a better answer if you clarify the motivation behind the question?\\n',\n",
              "      'url': 'https://www.lesswrong.com/posts/5RMARxzSeMYoj7nFQ/manhattan-project-for-aligned-ai?commentId=2PcYiHWDNhwT5t8GL',\n",
              "      'votes': '1'}],\n",
              "    'date_published': '2022-03-27T18:34',\n",
              "    'id': '8Fhv9eGC4ahBhhudA',\n",
              "    'omega_karma': '',\n",
              "    'score': '5',\n",
              "    'text': 'Here’s a question—if you were a researcher of atomic theory right before the Manhattan project began, would you have predicted it would be successful? Conditional on success, how long would you have expected it to take given the budget they had?\\n',\n",
              "    'url': 'https://www.lesswrong.com/posts/5RMARxzSeMYoj7nFQ/manhattan-project-for-aligned-ai?commentId=8Fhv9eGC4ahBhhudA',\n",
              "    'votes': '4'}],\n",
              "  'date_published': '2022-03-27T11:41',\n",
              "  'id': '5RMARxzSeMYoj7nFQ',\n",
              "  'omega_karma': '',\n",
              "  'score': '34',\n",
              "  'source': 'lesswrong',\n",
              "  'tags': 'AI',\n",
              "  'text': 'One possible thing that I imagine might happen, conditional on an existential catastrophe not occurring, is a Manhattan project for aligned AGI. I don’t want to argue that this is particularly likely or desirable. The point of this post is to sketch the scenario, and briefly discuss some implications for what is needed from current research.\\nImagine the following scenario: It is only late that top AI scientists take the existential risk of AGI seriously, and there hasn’t yet been a significant change in the effort put into AI safety relative to our current trajectory. At some point, there is a recognition among AI scientists and relevant decision-makers that AGI will be developed soon by one AI lab or another (within a few months/\\u200byears), and that without explicit effort there is a large probability of catastrophic results. A project is started to develop AGI:\\n\\n - It has an XX B$ or XXX B$ budget.\\n\\n - Dozens of the top AI scientists are part of the project, and many more assistants. People you might recognize or know from top papers and AI labs join the project.\\n\\n - A fairly constrained set of concepts, theories and tools are available that give a broad roadmap for building aligned AGI. \\n\\n - There is a consensus understanding among management and the research team that without this project, AGI will plausibly be developed relatively soon, and that without explicitly understanding how to build the system safely it will pose an existential risk.\\nIt seems to me that it is useful to backchain from this scenario to see what is needed, assuming that this kind of alignment Manhattan project is indeed what should happen.\\nFirstly, my view is that if this Manhattan project would start in intellectual conditions similar to today’s, there wouldn’t be very many top AI scientists significantly motivated to work on the problem, and it would not be taken seriously. Even very large sums of money would not suffice, since there wouldn’t be enough of a common understanding about what the problem is for it to work. \\nSecondly, it seems to me that there isn’t enough of a roadmap for building aligned AGI for such a project to succeed in a short time-frame of months to years. I expect some people to disagree with this, but looking at current rates of progress in our understanding of AI safety, and my model of the practical parallelizability of conceptual progress, I am skeptical that the problem can be solved in a few years even by a group of 40 highly motivated and financed top AI scientists. It is plausible that this will look different closer to the finish line, but I am skeptical.\\nOn this model, I have in mind basically two kinds of work that contribute to good outcomes. This is not a significant change relative to my prior view, but in my mind it constrains the motivation behind such work to some degree:\\n\\n - Research that makes the case for AGI x-risk clearer, and constrains how we believe the problem occurs, in order to make it eventually easier to convince top AI scientists that working in such an alignment Manhattan project is reasonable, and to make sure there is a team that’s on the same page as to what the problem is.\\n\\n - Research that constrains the roadmap for building aligned AGI. I’m thinking mostly of conceptual/\\u200btheoretical/\\u200bempirical work that helps us converge to an approach that can then be developed/\\u200brefined and scaled by a large effort over a short time period.\\nI suspect this mostly shouldn’t change my general picture of what needs to be done, but it does shift my emphasis somewhat.\\n',\n",
              "  'title': 'Manhattan project for aligned AI\\n',\n",
              "  'url': 'https://www.lesswrong.com/posts/5RMARxzSeMYoj7nFQ/manhattan-project-for-aligned-ai',\n",
              "  'votes': '18'}]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open(\"af_lw_forum_question_reply.jsonl\", \"w\") as writer:\n",
        "    with jsonlines.open(\"alignment_texts.jsonl\") as reader:\n",
        "        for line in reader:\n",
        "            try:\n",
        "                if line[\"source\"] == \"alignment forum\" or line[\"source\"] == \"lesswrong\":\n",
        "                    writer.write(line)\n",
        "            except:\n",
        "                pass"
      ],
      "metadata": {
        "id": "l0bhsX0LtPkb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clearning and Chunking Functions\n",
        "\n",
        "Functions for preparing the data into chunks that can fit into GPT."
      ],
      "metadata": {
        "id": "IWi2WcqKH_cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python create_finetune_csv.py \"af_lw_forums.jsonl\" \"af_lw\" --normalize-with-ftfy --min-unique-tokens=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2oCbGImXtEr",
        "outputId": "0e94526a-fd62-4884-ba53-3c594250dbf8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 0.99M/0.99M [00:00<00:00, 10.1MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 5.73MB/s]\n",
            "Downloading: 100% 1.29M/1.29M [00:00<00:00, 8.18MB/s]\n",
            "Downloading: 100% 665/665 [00:00<00:00, 317kB/s]\n",
            "reading/tokenizing files: 100% 30391/30391 [06:31<00:00, 77.55it/s]\n",
            "enforce_min_unique_tokens: 100% 39422/39422 [00:01<00:00, 23743.33it/s]\n",
            "39422\n",
            "1000\n",
            "dropped 357 tokens of trailing data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Testing Dataset Creation"
      ],
      "metadata": {
        "id": "jUCZYOMp49Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "eFp7LJUKJ4Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv\n",
        "\n",
        "# i = 0\n",
        "# texts = []\n",
        "# with jsonlines.open(\"alignment_texts.jsonl\") as reader:\n",
        "#     for line in reader:\n",
        "#         text = line[\"text\"]\n",
        "#         texts.append(text)\n",
        "#         if i > 3:\n",
        "#             break\n",
        "#         # try:\n",
        "#         if text != \"\":\n",
        "#             print(text)\n",
        "#             print(len(text.split()))\n",
        "#             encoding = tokenizer(text)\n",
        "#             total_len = len(encoding.tokens())\n",
        "#             tokens = encoding.tokens()\n",
        "#             # print(tokens)\n",
        "#             print(tokenizer.decode(encoding.input_ids))\n",
        "#         # if total_len > 1024:\n",
        "#         #     break\n",
        "#         i += 1\n",
        "#         # except:\n",
        "#         #     pass"
      ],
      "metadata": {
        "id": "XYyFaGPBJTIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60UIFTAY1N2l"
      },
      "source": [
        "## Training Splits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alignment_texts = pd.read_csv(\"alignment_texts_7288.csv\")"
      ],
      "metadata": {
        "id": "KAKD-owCehsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alignment_texts = list(alignment_texts)\n",
        "alignment_texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "PGRhi7-Ee0YE",
        "outputId": "7c38e00a-31bf-4682-8101-843a071526e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|endoftext|> I\\'ll be running an Ask Me Anything on this post from Friday (April 30) to Saturday (May 1).\\nIf you want to ask something just post a top-level comment; I\\'ll spend at least a day answering questions.\\nYou can find some background about me here.\\n<|endoftext|>**I—Meanings**\\nNow that we have some more concrete thinking under our belt, it\\'s time to circle back on Goodhart\\'s law for value learners. What sorts of bad behavior are we imagining from future value-learning AI? What makes those behaviors plausible, and what makes them bad?\\nLet\\'s start with that last point first. Judgments of goodness or badness get contextualized by models, so our framing of Goodhart\\'s law depends on what models of humans we tolerate. When I say \"I like dancing,\" this is a different use of the word \\'like,\\' backed by a different model of myself, than when I say \"I like tasting sugar.\" The model that comes to mind for dancing treats it as one of the chunks of my day, like \"playing computer games\" or \"taking the bus.\" I can know what state I\\'m in (the inference function of the model) based on seeing and hearing short scenes. Meanwhile, my model that has the taste of sugar in it has states like \"feeling sandpaper\" or \"stretching my back.\" States are more like short-term sensations, and the described world is tightly focused on my body and the things touching it.\\nOther models work too! That\\'s fine, there\\'s plenty to go around.The meta-model that talks about me having preferences in both of these models is the framing of competent preferences. If someone or something is observing humans, it looks for human preferences by seeing what the preferences are in \"agent-shaped\" models that are powerful for their size.\\n(At least, up to some finite amount of shuffling that\\'s like a choice of prior or universal Turing machine. Also note that the details of the definition of \"agent-shaped\" matter—we\\'ll come back to this under the umbrella meta-preferences.)\\nSo when we call certain behavior \"bad,\" the usage of that word might carry with it the implication of what way of thinking about the world that judgment is situated in, like how \"I like dancing\" makes sense when situated in a model of chunks of my day. There\\'s not one True Model in which the True Meaning of the word \"bad\" is expressed, though there can still be regularities among the different notions of badness.\\n**II—Mergers**\\nWhat were the patterns that stood out from my previous discussions of what humans think of as bad behavior in value learning?\\nThe most common type of failure, especially in modern day AI, is when humans are actively wrong about what\\'s going to happen. They have something specific in mind when designing an AI, like training a boat to win the race, but then they run it and don\\'t get what they wanted. The boat crashes and is on fire. We could make the boat racing game more of a value learning problem by training on human demonstrations rather than the score, and crashing and being on fire would *still *be bad behavior.\\nFor simple systems where humans are good at understanding the state space and picturing what they want, this is the only standard you need, but for more complicated systems (e.g. our galaxy) humans can only understand small parts or simple properties of the whole system, and we apply our preferences to those parts we can understand. From the inside, it can be hard to feel the distinction! We want things about tic-tac-toe or about the galaxy with the same set of emotions. What makes deciding what to do with the galaxy different is that we have these scattered preferences about different parts and patterns, and the different parts don\\'t stay neatly separate from each other. They can interact or overlap in ways that bring our preferences into conflict.\\nThis is a key point. Inter-preference conflicts aren\\'t an issue that ever comes up if you think of humans as having a utility function, but they\\'re almost *unavoidable *if you think of humans as a physical systems with different possible models. The nail in the coffin is that we humans can\\'t fit the whole galaxy into our heads, nor could evolution fit it into our genes, and so out of necessity we have to use simple heuristics that work well pragmatically but don\\'t fit together perfectly. If humans don\\'t resolve their preference conflicts well, this can lead to bad behavior like thinking the grass is always greener on the other side of the decision tree.\\nBad preference aggregation can also lead to new-ish bad behavior on the part of a value learner. This bad behavior can look like encountering a situation where humans are conflicted or inconsistent, and then resolving that conflict using a method <|endoftext|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T54RFVmS1NRv"
      },
      "source": [
        "train, val = train_test_split(musk_tweets, test_size=0.2)\n",
        "test, val = train_test_split(val, test_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oy37CKxfmK7",
        "outputId": "efcf5d88-1c83-4c26-f5e9-2ae996e41874"
      },
      "source": [
        "print(\"Number of Train examples: \" + str(len(train)))\n",
        "print(\"Number of Val examples: \" + str(len(val)))\n",
        "print(\"Number of Test examples: \" + str(len(test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Train examples: 27148\n",
            "Number of Val examples: 3394\n",
            "Number of Test examples: 3393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCoTxXg81quI"
      },
      "source": [
        "train_path = f'{directory}' + 'train.csv'\n",
        "val_path = f'{directory}' + 'val.csv'\n",
        "test_path = f'{directory}' + 'test.csv'\n",
        "\n",
        "train.to_csv(train_path, index=False)\n",
        "val.to_csv(val_path, index=False)\n",
        "test.to_csv(test_path, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ZvyvZyerDT"
      },
      "source": [
        "# Fine-Tuning GPT-2\n",
        "\n",
        "If we're looking to fine-tune models which are found on the HuggingFace model hub, then it becomes much easier to fine-tune the models since HuggingFace provides us with scripts.\n",
        "\n",
        "From the `transformers` repo:\n",
        "\n",
        "> There are two sets of scripts provided. The first set leverages the Trainer API. The second set with no_trainer in the suffix uses a custom training loop and leverages the 🤗 Accelerate library. Both sets use the 🤗 Datasets library. You can easily customize them to your needs if you need extra processing on your datasets.\n",
        "\n",
        "You can learn more about it here: https://github.com/huggingface/transformers/tree/master/examples/pytorch/language-modeling\n",
        "\n",
        "We will be using the script that leveraged the Trainer API. We can download the script by running:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty4g9WUhfMz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6559a1-e000-4f8f-fc50-25e2a08111a7"
      },
      "source": [
        "if not os.path.exists('/gpt-2/run_clm.py'):\n",
        "    !wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/language-modeling/run_clm.py -P gpt-2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-02 21:00:52--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/pytorch/language-modeling/run_clm.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25025 (24K) [text/plain]\n",
            "Saving to: ‘gpt-2/run_clm.py.1’\n",
            "\n",
            "\rrun_clm.py.1          0%[                    ]       0  --.-KB/s               \rrun_clm.py.1        100%[===================>]  24.44K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-07-02 21:00:52 (7.72 MB/s) - ‘gpt-2/run_clm.py.1’ saved [25025/25025]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXvm0wpQxS10"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "RV6nEm50t2Fk",
        "outputId": "8d023eb7-5d23-4934-ecc5-5a580aeebd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-2/run_clm.py \\\n",
        "    --model_name_or_path \"gpt-2/tmp/alignment-texts-clm\" \\\n",
        "    --train_file alignment_texts_7288.csv \\\n",
        "    --do_train \\\n",
        "    --fp16=True \\\n",
        "    --overwrite_cache=True \\\n",
        "    --per_device_train_batch_size=2 \\\n",
        "    --output_dir gpt-2/tmp/alignment-forum \\\n",
        "    --overwrite_output_dir=\"no\" \\\n",
        "    --save_total_limit=1 \\\n",
        "    --gradient_accumulation_steps=8 \\\n",
        "    --warmup_steps=10 \\\n",
        "    --learning_rate=3e-5 \\\n",
        "    --weight_decay=0.1 \\\n",
        "    --report_to=\"wandb\" \\\n",
        "    --run_name=\"gpt-2-alignment-forum-20220703\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7om5uFvezPsg",
        "outputId": "a9463ebb-c276-4610-c84f-0084efbcc156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "07/04/2022 01:24:36 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "07/04/2022 01:24:36 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=8,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=gpt-2/tmp/alignment-forum/runs/Jul04_01-24-35_4c6c040081fd,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "output_dir=gpt-2/tmp/alignment-forum,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=2,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=gpt-2-alignment-forum-20220703,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=10,\n",
            "weight_decay=0.1,\n",
            "xpu_backend=None,\n",
            ")\n",
            "07/04/2022 01:24:37 - WARNING - datasets.builder - Using custom data configuration default-81baadd93982b6f6\n",
            "07/04/2022 01:24:37 - INFO - datasets.builder - Generating dataset csv (/root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 3318.28it/s]\n",
            "07/04/2022 01:24:37 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "07/04/2022 01:24:37 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 101.98it/s]\n",
            "07/04/2022 01:24:37 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "07/04/2022 01:24:37 - INFO - datasets.builder - Generating train split\n",
            "07/04/2022 01:24:38 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 715.87it/s]\n",
            "07/04/2022 01:24:38 - WARNING - datasets.builder - Using custom data configuration default-81baadd93982b6f6\n",
            "07/04/2022 01:24:38 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "07/04/2022 01:24:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58\n",
            "07/04/2022 01:24:38 - WARNING - datasets.builder - Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
            "07/04/2022 01:24:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58\n",
            "07/04/2022 01:24:39 - WARNING - datasets.builder - Using custom data configuration default-81baadd93982b6f6\n",
            "07/04/2022 01:24:39 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "07/04/2022 01:24:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58\n",
            "07/04/2022 01:24:39 - WARNING - datasets.builder - Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
            "07/04/2022 01:24:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58\n",
            "[INFO|configuration_utils.py:662] 2022-07-04 01:24:39,760 >> loading configuration file gpt-2/tmp/alignment-texts-clm/config.json\n",
            "[INFO|configuration_utils.py:713] 2022-07-04 01:24:39,761 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt-2/tmp/alignment-texts-clm\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1721] 2022-07-04 01:24:39,765 >> Didn't find file gpt-2/tmp/alignment-texts-clm/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-07-04 01:24:39,767 >> loading file gpt-2/tmp/alignment-texts-clm/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-07-04 01:24:39,767 >> loading file gpt-2/tmp/alignment-texts-clm/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-07-04 01:24:39,767 >> loading file gpt-2/tmp/alignment-texts-clm/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-07-04 01:24:39,767 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-07-04 01:24:39,767 >> loading file gpt-2/tmp/alignment-texts-clm/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1799] 2022-07-04 01:24:39,767 >> loading file gpt-2/tmp/alignment-texts-clm/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:1997] 2022-07-04 01:24:41,752 >> loading weights file gpt-2/tmp/alignment-texts-clm/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2389] 2022-07-04 01:24:43,610 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:2398] 2022-07-04 01:24:43,610 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt-2/tmp/alignment-texts-clm.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "07/04/2022 01:24:43 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.tokenize_function at 0x7fd7549b4710> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "Running tokenizer on dataset:   0% 0/7 [00:00<?, ?ba/s]07/04/2022 01:24:44 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1c80317fa3b1799d.arrow\n",
            "Running tokenizer on dataset: 100% 7/7 [00:07<00:00,  1.02s/ba]\n",
            "07/04/2022 01:24:50 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.tokenize_function at 0x7fd7549b4830> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n",
            "Running tokenizer on dataset:   0% 0/1 [00:00<?, ?ba/s]07/04/2022 01:24:51 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bdd640fb06671ad1.arrow\n",
            "Running tokenizer on dataset: 100% 1/1 [00:00<00:00,  2.75ba/s]\n",
            "07/04/2022 01:24:51 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.group_texts at 0x7fd7549b4950> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n",
            "Grouping texts in chunks of 1024:   0% 0/7 [00:00<?, ?ba/s]07/04/2022 01:24:51 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-3eb13b9046685257.arrow\n",
            "Grouping texts in chunks of 1024: 100% 7/7 [00:06<00:00,  1.03ba/s]\n",
            "07/04/2022 01:24:58 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.group_texts at 0x7fd7549b4710> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n",
            "Grouping texts in chunks of 1024:   0% 0/1 [00:00<?, ?ba/s]07/04/2022 01:24:58 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-81baadd93982b6f6/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-23b8c1e9392456de.arrow\n",
            "Grouping texts in chunks of 1024: 100% 1/1 [00:00<00:00,  2.83ba/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[INFO|trainer.py:533] 2022-07-04 01:25:02,222 >> Using cuda_amp half precision backend\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1521] 2022-07-04 01:25:02,230 >> ***** Running training *****\n",
            "[INFO|trainer.py:1522] 2022-07-04 01:25:02,230 >>   Num examples = 6784\n",
            "[INFO|trainer.py:1523] 2022-07-04 01:25:02,230 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1524] 2022-07-04 01:25:02,230 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:1525] 2022-07-04 01:25:02,230 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:1526] 2022-07-04 01:25:02,230 >>   Gradient Accumulation steps = 8\n",
            "[INFO|trainer.py:1527] 2022-07-04 01:25:02,230 >>   Total optimization steps = 1272\n",
            "[INFO|integrations.py:580] 2022-07-04 01:25:02,231 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjacquesthibs\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/data/ai-alignment-dataset/wandb/run-20220704_012502-p0ms9nyq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgpt-2-alignment-forum-20220703\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jacquesthibs/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jacquesthibs/huggingface/runs/p0ms9nyq\u001b[0m\n",
            "{'loss': 2.9184, 'learning_rate': 1.8351822503961967e-05, 'epoch': 1.18}\n",
            " 39% 500/1272 [26:20<42:12,  3.28s/it][INFO|trainer.py:2510] 2022-07-04 01:51:24,315 >> Saving model checkpoint to gpt-2/tmp/alignment-forum/checkpoint-500\n",
            "[INFO|configuration_utils.py:451] 2022-07-04 01:51:24,321 >> Configuration saved in gpt-2/tmp/alignment-forum/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:1550] 2022-07-04 01:51:25,718 >> Model weights saved in gpt-2/tmp/alignment-forum/checkpoint-500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2143] 2022-07-04 01:51:25,722 >> tokenizer config file saved in gpt-2/tmp/alignment-forum/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2150] 2022-07-04 01:51:25,726 >> Special tokens file saved in gpt-2/tmp/alignment-forum/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 2.8483, 'learning_rate': 6.465927099841522e-06, 'epoch': 2.36}\n",
            " 79% 1000/1272 [52:45<14:50,  3.27s/it][INFO|trainer.py:2510] 2022-07-04 02:17:49,778 >> Saving model checkpoint to gpt-2/tmp/alignment-forum/checkpoint-1000\n",
            "[INFO|configuration_utils.py:451] 2022-07-04 02:17:49,783 >> Configuration saved in gpt-2/tmp/alignment-forum/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:1550] 2022-07-04 02:17:51,168 >> Model weights saved in gpt-2/tmp/alignment-forum/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2143] 2022-07-04 02:17:51,172 >> tokenizer config file saved in gpt-2/tmp/alignment-forum/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2150] 2022-07-04 02:17:51,175 >> Special tokens file saved in gpt-2/tmp/alignment-forum/checkpoint-1000/special_tokens_map.json\n",
            "[INFO|trainer.py:2588] 2022-07-04 02:17:55,989 >> Deleting older checkpoint [gpt-2/tmp/alignment-forum/checkpoint-500] due to args.save_total_limit\n",
            "100% 1272/1272 [1:07:10<00:00,  3.15s/it][INFO|trainer.py:1766] 2022-07-04 02:32:14,888 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 4032.6582, 'train_samples_per_second': 5.047, 'train_steps_per_second': 0.315, 'train_loss': 2.8758605861064024, 'epoch': 3.0}\n",
            "100% 1272/1272 [1:07:10<00:00,  3.17s/it]\n",
            "[INFO|trainer.py:2510] 2022-07-04 02:32:14,890 >> Saving model checkpoint to gpt-2/tmp/alignment-forum\n",
            "[INFO|configuration_utils.py:451] 2022-07-04 02:32:14,896 >> Configuration saved in gpt-2/tmp/alignment-forum/config.json\n",
            "[INFO|modeling_utils.py:1550] 2022-07-04 02:32:16,440 >> Model weights saved in gpt-2/tmp/alignment-forum/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2143] 2022-07-04 02:32:16,444 >> tokenizer config file saved in gpt-2/tmp/alignment-forum/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2150] 2022-07-04 02:32:16,448 >> Special tokens file saved in gpt-2/tmp/alignment-forum/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     2.8759\n",
            "  train_runtime            = 1:07:12.65\n",
            "  train_samples            =       6784\n",
            "  train_samples_per_second =      5.047\n",
            "  train_steps_per_second   =      0.315\n",
            "[INFO|modelcard.py:460] 2022-07-04 02:32:18,480 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 3.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1272\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 2.8483\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.0635630870528e+16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 2.87586\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 4032.6582\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 5.047\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.315\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgpt-2-alignment-forum-20220703\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/jacquesthibs/huggingface/runs/p0ms9nyq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220704_012502-p0ms9nyq/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOtpCx8KfVYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd641563-7ae1-4580-b699-41859fbd439b"
      },
      "source": [
        "# !python gpt-2/run_clm.py \\\n",
        "#     --model_name_or_path gpt2 \\\n",
        "#     --train_file alignment_texts_87606.csv \\\n",
        "#     --do_train \\\n",
        "#     --fp16=True \\\n",
        "#     --overwrite_cache=True \\\n",
        "#     --per_device_train_batch_size=2 \\\n",
        "#     --output_dir gpt-2/tmp/alignment-texts-clm \\\n",
        "#     --overwrite_output_dir=\"yes\" \\\n",
        "#     --save_total_limit=3 \\\n",
        "#     --save_steps=10000 \\\n",
        "#     --gradient_accumulation_steps=32 \\\n",
        "#     --warmup_steps=100 \\\n",
        "#     --learning_rate=3e-5 \\\n",
        "#     --weight_decay=0.1 \\\n",
        "#     --report_to=\"wandb\" \\\n",
        "#     --run_name=\"gpt-2-alignment-20220702\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "07/02/2022 21:08:15 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "07/02/2022 21:08:15 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=32,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=gpt-2/tmp/alignment-texts-clm/runs/Jul02_21-08-14_2ef82b3c19b8,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_hf,\n",
            "output_dir=gpt-2/tmp/alignment-texts-clm,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=2,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=gpt-2-alignment-20220702,\n",
            "save_on_each_node=False,\n",
            "save_steps=10000,\n",
            "save_strategy=steps,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=100,\n",
            "weight_decay=0.1,\n",
            "xpu_backend=None,\n",
            ")\n",
            "07/02/2022 21:08:15 - WARNING - datasets.builder - Using custom data configuration default-7180ffe1010b33d0\n",
            "07/02/2022 21:08:15 - INFO - datasets.builder - Generating dataset csv (/root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 3539.50it/s]\n",
            "07/02/2022 21:08:15 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "07/02/2022 21:08:16 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 23.19it/s]\n",
            "07/02/2022 21:08:17 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "07/02/2022 21:08:17 - INFO - datasets.builder - Generating train split\n",
            "07/02/2022 21:08:22 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 530.99it/s]\n",
            "07/02/2022 21:08:23 - WARNING - datasets.builder - Using custom data configuration default-7180ffe1010b33d0\n",
            "07/02/2022 21:08:23 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "07/02/2022 21:08:23 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58\n",
            "07/02/2022 21:08:23 - WARNING - datasets.builder - Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
            "07/02/2022 21:08:23 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58\n",
            "07/02/2022 21:08:23 - WARNING - datasets.builder - Using custom data configuration default-7180ffe1010b33d0\n",
            "07/02/2022 21:08:23 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "07/02/2022 21:08:23 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58\n",
            "07/02/2022 21:08:23 - WARNING - datasets.builder - Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
            "07/02/2022 21:08:23 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58\n",
            "[INFO|hub.py:592] 2022-07-02 21:08:23,835 >> https://huggingface.co/gpt2/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpn2sbjbwt\n",
            "Downloading: 100% 665/665 [00:00<00:00, 824kB/s]\n",
            "[INFO|hub.py:596] 2022-07-02 21:08:24,129 >> storing https://huggingface.co/gpt2/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|hub.py:604] 2022-07-02 21:08:24,129 >> creating metadata file for /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:664] 2022-07-02 21:08:24,130 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:713] 2022-07-02 21:08:24,131 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.21.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:396] 2022-07-02 21:08:24,404 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:664] 2022-07-02 21:08:24,679 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:713] 2022-07-02 21:08:24,680 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.21.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|hub.py:592] 2022-07-02 21:08:25,231 >> https://huggingface.co/gpt2/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpjkg5dn_3\n",
            "Downloading: 100% 0.99M/0.99M [00:00<00:00, 3.27MB/s]\n",
            "[INFO|hub.py:596] 2022-07-02 21:08:25,903 >> storing https://huggingface.co/gpt2/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|hub.py:604] 2022-07-02 21:08:25,903 >> creating metadata file for /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|hub.py:592] 2022-07-02 21:08:26,172 >> https://huggingface.co/gpt2/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpfl2zwp65\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 1.46MB/s]\n",
            "[INFO|hub.py:596] 2022-07-02 21:08:26,773 >> storing https://huggingface.co/gpt2/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|hub.py:604] 2022-07-02 21:08:26,773 >> creating metadata file for /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|hub.py:592] 2022-07-02 21:08:27,044 >> https://huggingface.co/gpt2/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp6462b8_1\n",
            "Downloading: 100% 1.29M/1.29M [00:00<00:00, 3.54MB/s]\n",
            "[INFO|hub.py:596] 2022-07-02 21:08:27,760 >> storing https://huggingface.co/gpt2/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|hub.py:604] 2022-07-02 21:08:27,760 >> creating metadata file for /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1801] 2022-07-02 21:08:28,605 >> loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|tokenization_utils_base.py:1801] 2022-07-02 21:08:28,605 >> loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1801] 2022-07-02 21:08:28,605 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1801] 2022-07-02 21:08:28,605 >> loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1801] 2022-07-02 21:08:28,605 >> loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1801] 2022-07-02 21:08:28,605 >> loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:664] 2022-07-02 21:08:28,884 >> loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "[INFO|configuration_utils.py:713] 2022-07-02 21:08:28,885 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.21.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|hub.py:592] 2022-07-02 21:08:29,232 >> https://huggingface.co/gpt2/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp82azmds6\n",
            "Downloading: 100% 523M/523M [00:10<00:00, 52.7MB/s]\n",
            "[INFO|hub.py:596] 2022-07-02 21:08:39,735 >> storing https://huggingface.co/gpt2/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|hub.py:604] 2022-07-02 21:08:39,735 >> creating metadata file for /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|modeling_utils.py:1999] 2022-07-02 21:08:39,736 >> loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "[INFO|modeling_utils.py:2389] 2022-07-02 21:08:41,618 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:2398] 2022-07-02 21:08:41,618 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "07/02/2022 21:08:41 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.tokenize_function at 0x7fbca2405200> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "Running tokenizer on dataset:   0% 0/84 [00:00<?, ?ba/s]07/02/2022 21:08:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1c80317fa3b1799d.arrow\n",
            "Running tokenizer on dataset: 100% 84/84 [01:44<00:00,  1.25s/ba]\n",
            "07/02/2022 21:10:26 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.tokenize_function at 0x7fbdede284d0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n",
            "Running tokenizer on dataset:   0% 0/5 [00:00<?, ?ba/s]07/02/2022 21:10:27 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bdd640fb06671ad1.arrow\n",
            "Running tokenizer on dataset: 100% 5/5 [00:05<00:00,  1.13s/ba]\n",
            "07/02/2022 21:10:32 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.group_texts at 0x7fbdede285f0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n",
            "Grouping texts in chunks of 1024:   0% 0/84 [00:00<?, ?ba/s]07/02/2022 21:10:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-3eb13b9046685257.arrow\n",
            "Grouping texts in chunks of 1024: 100% 84/84 [01:30<00:00,  1.08s/ba]\n",
            "07/02/2022 21:12:02 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.group_texts at 0x7fbdede284d0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n",
            "Grouping texts in chunks of 1024:   0% 0/5 [00:00<?, ?ba/s]07/02/2022 21:12:03 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/csv/default-7180ffe1010b33d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-23b8c1e9392456de.arrow\n",
            "Grouping texts in chunks of 1024: 100% 5/5 [00:04<00:00,  1.04ba/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[INFO|trainer.py:533] 2022-07-02 21:12:23,741 >> Using cuda_amp half precision backend\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1521] 2022-07-02 21:12:23,754 >> ***** Running training *****\n",
            "[INFO|trainer.py:1522] 2022-07-02 21:12:23,754 >>   Num examples = 81521\n",
            "[INFO|trainer.py:1523] 2022-07-02 21:12:23,754 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1524] 2022-07-02 21:12:23,754 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:1525] 2022-07-02 21:12:23,754 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "[INFO|trainer.py:1526] 2022-07-02 21:12:23,754 >>   Gradient Accumulation steps = 32\n",
            "[INFO|trainer.py:1527] 2022-07-02 21:12:23,754 >>   Total optimization steps = 3819\n",
            "[INFO|integrations.py:580] 2022-07-02 21:12:23,756 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjacquesthibs\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/data/ai-alignment-dataset/wandb/run-20220702_211223-3cbz2m0o\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgpt-2-alignment-20220702\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jacquesthibs/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jacquesthibs/huggingface/runs/3cbz2m0o\u001b[0m\n",
            "{'loss': 3.0409, 'learning_rate': 2.677332616294703e-05, 'epoch': 0.39}\n",
            "{'loss': 2.9125, 'learning_rate': 2.2739983866630816e-05, 'epoch': 0.79}\n",
            "{'loss': 2.875, 'learning_rate': 1.87066415703146e-05, 'epoch': 1.18}\n",
            " 52% 2000/3819 [6:59:09<6:24:59, 12.70s/it]{'loss': 2.8497, 'learning_rate': 1.4673299273998387e-05, 'epoch': 1.57}\n",
            " 65% 2500/3819 [8:44:03<4:39:12, 12.70s/it]{'loss': 2.834, 'learning_rate': 1.0639956977682173e-05, 'epoch': 1.96}\n",
            "{'loss': 2.8204, 'learning_rate': 6.606614681365959e-06, 'epoch': 2.36}\n",
            "{'loss': 2.8061, 'learning_rate': 2.5732723850497446e-06, 'epoch': 2.75}\n",
            "100% 3819/3819 [13:21:05<00:00, 12.58s/it]{'train_runtime': 48067.5043, 'train_samples_per_second': 5.088, 'train_steps_per_second': 0.079, 'train_loss': 2.8716601671177417, 'epoch': 3.0}\n",
            "[INFO|trainer.py:1766] 2022-07-03 10:33:31,258 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "100% 3819/3819 [13:21:05<00:00, 12.59s/it]\n",
            "[INFO|trainer.py:2510] 2022-07-03 10:33:31,261 >> Saving model checkpoint to gpt-2/tmp/alignment-texts-clm\n",
            "[INFO|configuration_utils.py:451] 2022-07-03 10:33:31,268 >> Configuration saved in gpt-2/tmp/alignment-texts-clm/config.json\n",
            "[INFO|modeling_utils.py:1550] 2022-07-03 10:33:32,888 >> Model weights saved in gpt-2/tmp/alignment-texts-clm/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2143] 2022-07-03 10:33:32,894 >> tokenizer config file saved in gpt-2/tmp/alignment-texts-clm/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2150] 2022-07-03 10:33:32,898 >> Special tokens file saved in gpt-2/tmp/alignment-texts-clm/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =         3.0\n",
            "  train_loss               =      2.8717\n",
            "  train_runtime            = 13:21:07.50\n",
            "  train_samples            =       81521\n",
            "  train_samples_per_second =       5.088\n",
            "  train_steps_per_second   =       0.079\n",
            "[INFO|modelcard.py:460] 2022-07-03 10:33:33,339 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▂▃▄▅▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▂▃▄▅▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate █▇▆▄▃▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▄▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 3.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 3819\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 2.8061\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.27779119824896e+17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 2.87166\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 48067.5043\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 5.088\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.079\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgpt-2-alignment-20220702\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/jacquesthibs/huggingface/runs/3cbz2m0o\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220702_211223-3cbz2m0o/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "oAS6ifGEym3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7q0Q066UWo-"
      },
      "source": [
        "# Let's use the model!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"gpt-2/tmp/alignment-texts-clm\"\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(OUTPUT_DIR)\n",
        "model = GPT2LMHeadModel.from_pretrained(OUTPUT_DIR)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "C2S7xaafWosb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdIAGG1a27xX"
      },
      "source": [
        "NUM_COMPLETIONS = 1\n",
        "\n",
        "def generate(input_str, length=50, n=NUM_COMPLETIONS):\n",
        "  cur_ids = torch.tensor(tokenizer.encode(input_str)).unsqueeze(0).long().to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for i in range(length):\n",
        "      outputs = model(cur_ids[:, -1024:], labels=cur_ids[:, -1024:])\n",
        "      loss, logits = outputs[:2]\n",
        "      softmax_logits = torch.softmax(logits[0,-1], dim=0)\n",
        "      next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), n=n)\n",
        "      cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim=1)\n",
        "    output_list = list(cur_ids.squeeze().to('cpu').numpy())\n",
        "    output_text = tokenizer.decode(output_list)\n",
        "    return output_text.replace(\"<|endoftext|>\", \"\")\n",
        "\n",
        "def choose_from_top(probs, n=NUM_COMPLETIONS):\n",
        "    ind = np.argpartition(probs, -n)[-n:]\n",
        "    top_prob = probs[ind]\n",
        "    top_prob = top_prob / np.sum(top_prob) # Normalize\n",
        "    choice = np.random.choice(n, 1, p = top_prob)\n",
        "    token_id = ind[choice][0]\n",
        "    return int(token_id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF05N8SmVIIr",
        "outputId": "92d7c1ca-e30b-47fd-f86f-7b5fe8d873a9"
      },
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "generated_text = generate(\"\"\"What is the justification behind the concept of a decisive strategic advantage? Why do we think that a superintelligence can do extraordinary things (hack human minds, invent nanotechnology, conquer the world, kill everyone in the same instant) when nations and corporations can't do those things?\n",
        "\n",
        "The key points from the last paragraph are\"\"\")\n",
        "end = time.time()\n",
        "print(generated_text)\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the justification behind the concept of a decisive strategic advantage? Why do we think that a superintelligence can do extraordinary things (hack human minds, invent nanotechnology, conquer the world, kill everyone in the same instant) when nations and corporations can't do those things?\n",
            "\n",
            "The key points from the last paragraph are:\n",
            "\n",
            "\n",
            " - The superintelligence is not a \"superintelligence\" but a \"superintelligence\" that can do extraordinary things.\n",
            "\n",
            " - The superintelligence is not a \"superintelligence\" but a \"superintelligence\" that can do extraordinary things.\n",
            "0.925572395324707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as NUM_COMPLETIONS\n",
        "\n",
        "np.e**(-.82)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKPeMnlUksZ1",
        "outputId": "a13d0f36-8d18-4978-db15-2cc9911095eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4404316545059993"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "gpt2 = AutoModelForCausalLM.from_pretrained(\"gpt2\", return_dict_in_generate=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "input_ids = tokenizer(\"Today is a nice day\", return_tensors=\"pt\").input_ids\n",
        "\n",
        "generated_outputs = gpt2.generate(input_ids, do_sample=True, num_return_sequences=3, output_scores=True)\n",
        "\n",
        "# only use id's that were generated\n",
        "# gen_sequences has shape [3, 15]\n",
        "gen_sequences = generated_outputs.sequences[:, input_ids.shape[-1]:]\n",
        "\n",
        "# let's stack the logits generated at each step to a tensor and transform\n",
        "# logits to probs\n",
        "probs = torch.stack(generated_outputs.scores, dim=1).softmax(-1)  # -> shape [3, 15, vocab_size]\n",
        "\n",
        "# now we need to collect the probability of the generated token\n",
        "# we need to add a dummy dim in the end to make gather work\n",
        "gen_probs = torch.gather(probs, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
        "\n",
        "# now we can do all kinds of things with the probs\n",
        "\n",
        "# 1) the probs that exactly those sequences are generated again\n",
        "# those are normally going to be very small\n",
        "unique_prob_per_sequence = gen_probs.prod(-1)\n",
        "\n",
        "# 2) normalize the probs over the three sequences\n",
        "normed_gen_probs = gen_probs / gen_probs.sum(0)\n",
        "assert normed_gen_probs[:, 0].sum() == 1.0, \"probs should be normalized, rerun in case it's a floating point error\"\n",
        "\n",
        "# 3) compare normalized probs to each other like in 1)\n",
        "unique_normed_prob_per_sequence = normed_gen_probs.prod(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeBW1wj6saZO",
        "outputId": "a0776f39-21ad-46d9-87d0-c2ca678651a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_log_probs = torch.stack(generated_outputs.scores, dim=1)\n",
        "log_probs = torch.gather(all_log_probs, 2, gen_sequences[:, :, None]).squeeze(-1)\n",
        "mean_log_probs = torch.mean(log_probs)"
      ],
      "metadata": {
        "id": "2CCducl0Rdh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(generated_outputs.scores[0])\n",
        "print(log_probs.sum(1))\n",
        "# print(tokenizer.decode(gen_sequences[0]))\n",
        "# print(generated_outputs.scores)\n",
        "# print(probs)\n",
        "# print(gen_probs)\n",
        "# print(unique_prob_per_sequence)\n",
        "# print(normed_gen_probs)\n",
        "# print(unique_normed_prob_per_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip1kkEDuY3xn",
        "outputId": "9f4cd69a-8cec-481e-e74b-4930104d10d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1439.7550, -1560.0505, -1675.6975])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.prod([0.2158, 0.1008, 0.3531, 0.3138, 0.2799, 0.3295, 0.6937, 0.2309, 0.0479, 0.0648, 0.1682, 0.1356, 0.2393, 0.8083, 0.0352])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX4Vqe5JLyty",
        "outputId": "097448f6-73dd-4861-b729-7eddb9fbeff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7162111343988786e-11"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kzOlqi8eMys"
      },
      "source": [
        "# Compressing the Model\n",
        "\n",
        "Let's save the model as a `tar.gz` file so that we can save it in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOmuQ4tUVei9"
      },
      "source": [
        "!tar -czf gpt-2-elon-tweets.tar.gz gpt-2/tuned-models/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}